---
layout: post
title:  "一种基于潜在语义分析的问答系统答案定位方法"
date:   2018-05-04
desc: "一种基于潜在语义分析的问答系统答案定位方法"
keywords: "潜在语义分析, 问答系统, 答案定位"
categories: [Deeplearning]
tags: [潜在语义分析, 问答系统, 答案定位]
icon: icon-html
---

# **0 前言**

在上一篇博文[《一种基于模糊依存关系匹配的问答模型构建方法》](https://zhoum1118.github.io/deeplearning/2018/04/30/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%A8%A1%E7%B3%8A%E4%BE%9D%E5%AD%98%E5%85%B3%E7%B3%BB%E5%8C%B9%E9%85%8D%E7%9A%84%E9%97%AE%E7%AD%94%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95.html)我们分析了基于模糊依存关系匹配的问答模型构建，其基本思想是通过模糊匹配问题（question）和包含候选答案的句子（Sentence）间的依存关系来定位问题的答案，**依存关系主要反映的是句子中核心词和依存词之间的语义关系**，这种分析方法也可能为传统机器学习方法的特征工程提供一些思路，还是出于构建特征工程需要的考虑，受余正涛教授的《基于潜在语义分析的汉语问答系统答案提取》的启发，我们继续挖掘问题（question）和包含候选答案的句子（Sentence）中词与词之间的潜在语义关系，并基于此利用潜在语义分析（Latent Semantic Analysis，LSA）思想来定位答案所在的句子。

# **1 背景**

在[《一种基于模糊依存关系匹配的问答模型构建方法》](https://zhoum1118.github.io/deeplearning/2018/04/30/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%A8%A1%E7%B3%8A%E4%BE%9D%E5%AD%98%E5%85%B3%E7%B3%BB%E5%8C%B9%E9%85%8D%E7%9A%84%E9%97%AE%E7%AD%94%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95.html)中我们介绍了传统问答系统定位答案的过程，在其中第二步，还可以在细分为，提取包含答案的句子，然后再从句子中提取答案。由此可见定位答案所在的句子是答案更细粒度的一种表示，而《基于潜在语义分析的汉语问答系统答案提取》便是针对事实简单陈述问题的答案句子的提取。

不难发现，定位答案所在的句子，即计算问题（question）和文档各个句子的相似度，相似度最高的句子即为答案。问题转化为计算两个句子的相似度，相似度传统的计算方法为关键词匹配方法，在[《一种基于模糊依存关系匹配的问答模型构建方法》](https://zhoum1118.github.io/deeplearning/2018/04/30/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%A8%A1%E7%B3%8A%E4%BE%9D%E5%AD%98%E5%85%B3%E7%B3%BB%E5%8C%B9%E9%85%8D%E7%9A%84%E9%97%AE%E7%AD%94%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95.html)一文中有提到，即通过统计两个句子中拥有共同关键词的数量来确定两者的相似程度。**但这种方法过于简单，且对于中文问答系统，句子中的词存在同义或多义现象。**所以如果不考虑关键词所在的上下文信息和关键词的词性，那么对于基于关键词匹配方法，句子中出现词同义而又过于追求词匹配，则可能导致漏掉包含正确答案的句子。比如，问题Q1：北京奥运会开幕时间是什么时候？关键词是“北京奥运会”和“开幕时间”，那么对于“北京奥运会于2008年8月8日晚上8时开始”或“北京奥运会2008年8月8日晚上8时整于中华人民共和国首都北京举办”等包含正确答案的句子将可能被漏掉。如果句子中出现词多义的情况，比如“代表”，其可作为名词和动词，那么基于关键词匹配方法就很可能出现把错误的句子定位成正确的。

基于关键词匹配方法的不足，出现了一种基于LSA的答案定位方法。**LSA的基本思想是通过统计分析文档中词与词之间的某种语义结构，消除词同义和多义的影响。**这是对传统向量空间技术的一种改良，在信息检索、信息过滤、文档分类、自动摘要以及文旦系统等领域都有较好的应用效果。基于潜在语义分析的问答系统答案定位方法使用LSA思想，通过统计分析构造了一个词-句子的语义空间，以此来消除词之间的相关性，然后基于词-句子的语义空间计算问题（question）和句子之间的相似度，最终定位答案所在的句子，在一定程度上提高了答案定位的准确率。

# **2 基于潜在语义分析的问答系统答案定位方法**

## **2.1 LSA**

首先，定义一个 `m * n` 的词-文档矩阵`A`：

<img title="一种基于潜在语义分析的问答系统答案定位方法_" 图片1="" src="https://img.mukewang.com/5aebb7990001a91b08000088.png" alt="图片描述" style="display:block; margin:auto; width:50%">

其中，`a_ij`表示第`i`个词在第`j`个文档中出现的次数，`m`表示关键词的个数，`n`表示文档树。

经过矩阵奇异值分解后：

<img title="一种基于潜在语义分析的问答系统答案定位方法_" 图片1="" src="https://img.mukewang.com/5aebb7b9000174bb07300086.png" alt="图片描述" style="display:block; margin:auto; width:50%">

其中，`U`为 `m * m` 的正交矩阵，<img title="一种基于潜在语义分析的问答系统答案定位方法_" 图片1="" src="https://img.mukewang.com/5aebb7cc0001d6ea00620056.png" alt="图片描述" style="width:3%">为 `m * n` 的对角矩阵，`V`为 `n * n` 的正交矩阵。

分析易得，`m`一般对大于`n`，且每个关键词只会出现在少量的文档中，所以`A`一般为高阶稀疏矩阵，而这里进行**奇异值分解的意义**在于：

> 奇异值往往对应着矩阵中隐含的重要信息，且重要性和奇异值大小正相关。每个矩阵A都可以表示为一系列秩为1的“小矩阵”之和，而奇异值则衡量了这些“小矩阵”对于A的权重。

为了在降低计算复杂度的前提下，最大程度的构建包含丰富潜在语义的向量空间，我们假设经过奇异值分解后的`A`的秩为`r`，存在一个`k`，`k <= r`，且`k << min(m, n)`，则`A`的`k`秩近似矩阵`A_k`为：

<img title="一种基于潜在语义分析的问答系统答案定位方法_" 图片1="" src="https://img.mukewang.com/5aebb7e600010f0707400086.png" alt="图片描述" style="display:block; margin:auto; width:50%">

其中，`U_k`为 `m * k` 的矩阵，由`U`的前`k`列组成；<img title="一种基于潜在语义分析的问答系统答案定位方法_" 图片1="" src="https://img.mukewang.com/5aebb7f900018c5e00560056.png" alt="图片描述" style="width:3%">是 `k * k` 的矩阵，由<img title="一种基于潜在语义分析的问答系统答案定位方法_" 图片1="" src="https://img.mukewang.com/5aebb8060001d6ea00620056.png" alt="图片描述" style="width:3%">的前`k`行、前`k`列组成；`V_k`是 `k * n` 的矩阵，由`V`的前`k`行组成。

`A_k`近似保存了词与文档之间的潜在语义关系，且去除了大量因词汇同义或多义产生的“噪点”，也就是说，**那些经常出现在相似的上下文中的词，在`A_k`的`k`维词空间中的距离也就比较小**。

**潜在语义空间转换是一个降维过程，具体降多少维视任务情况而定，如果`k`过大，接近标准向量空间，也就失去表示词相依性的能力，且存在大量噪点，计算复杂度也大；`k`过小，也无法表示丰富的语义结构，模型也就毫无意义。**一般来说`k`值在`100~300`之间。

## **2.2 相似度计算方法**

**2.2.1 向量空间模型（Vector Space Model，VSM）**

问题（question）向量表示为`q=(q_1, q_2, …, q_i, …, q_n)`，其中`n`表示语料库中所有关键词的数量，`q_i`表示第`i`个关键词在问题中出现的次数；同样的，候选答案句子`S`可表示为`S=(s_1, s_2, …, s_i, …, s_n)`，计算两个向量的余弦值作为两者相似度的一个度量：

<img title="一种基于潜在语义分析的问答系统答案定位方法_" 图片1="" src="https://img.mukewang.com/5aebb8200001435009040258.png" alt="图片描述" style="display:block; margin:auto; width:50%">

其中，`n`为问题中包含关键词的总个数，`tf_i`为问题的第`i`个关键词在问题`q`和候选答案句子`S`中出现的频率，`idf_i`为问题的第`i`个关键词的倒排频率，`Sentence_Length`为候选答案句子所包含词（这里应该是全部的词）的个数，`Sentence_length_avg`表示语料库所有句子包含词个数的平均值。

从计算过程可以看出，**这种方法仅仅考察的是问题与候选答案句子中关键词的词频信息，而没有考虑词在上下文的语义信息，所以具有一定的局限性，但从特征工程的角度看，这或许可以作为其中特征之一来构建模型。**

**2.2.2 基于LSA的问题与候选答案句子相似度计算**

首先，如2.1所述，构造一个 `m * n` 的关键词-句子矩阵`A`，其中每个关键词`t_i`在句子`s_j`中的权重`a_ij`定义为：

<img title="一种基于潜在语义分析的问答系统答案定位方法_" 图片1="" src="https://img.mukewang.com/5aebb86b00017f4408340252.png" alt="图片描述" style="display:block; margin:auto; width:50%">

其中，`tf_ij`为词`t_i`在句子`s_j`中的词频，`N`为语料库中句子总数，`nt_i`为语料库句子中出现关键词`t_i`的句子数，分母为其归一化因子。

然后经过矩阵奇异值分解并降维后得到一个潜在词-句子的语义空间`A_k`，将问题向量`q`和候选答案句子向量`S`映射到这个语义空间，向量表示方法和2.2.1一致，映射公式如下所示：

<img title="一种基于潜在语义分析的问答系统答案定位方法_" 图片1="" src="https://img.mukewang.com/5aebb88500016ed409400076.png" alt="图片描述" style="display:block; margin:auto; width:50%">

其中，<img title="一种基于潜在语义分析的问答系统答案定位方法_" 图片1="" src="https://img.mukewang.com/5aebb8950001072800800056.png" alt="图片描述" style="width:4%">是<img title="一种基于潜在语义分析的问答系统答案定位方法_" 图片1="" src="https://img.mukewang.com/5aebb8a000018c5e00560056.png" alt="图片描述" style="width:3%">的逆矩阵，`X`为映射前的向量。

**通常映射前的向量`X`中大部分元素为0，在映射后0元素基本没有，即经过语义空间转换的向量不在是简单的关键词词频组成的，而是包含了其在上下文语义关系的权值信息，反映了关键词之间的一定的相关性**，此时相似度计算公式为：

<img title="一种基于潜在语义分析的问答系统答案定位方法_" 图片1="" src="https://img.mukewang.com/5aebb8b40001098708860268.png" alt="图片描述" style="display:block; margin:auto; width:50%">

其中，`q~*`为问题语义向量，`s_j`为第`j`个候选答案句子向量，`k`为语义空间的维数，`q_m`和`s_jm`分别为问题语义向量和候选答案句子向量中第`m`维权值。