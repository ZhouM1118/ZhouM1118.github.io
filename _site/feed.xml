<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>周明的技术博客</title>
    <description>Jack's blog,use Jekyll and github pages.</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 04 May 2018 10:08:04 +0800</pubDate>
    <lastBuildDate>Fri, 04 May 2018 10:08:04 +0800</lastBuildDate>
    <generator>Jekyll v3.4.3</generator>
    
      <item>
        <title>一种基于潜在语义分析的问答系统答案定位方法</title>
        <description>&lt;h1 id=&quot;0-前言&quot;&gt;&lt;strong&gt;0 前言&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;在上一篇博文&lt;a href=&quot;https://zhoum1118.github.io/deeplearning/2018/04/30/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%A8%A1%E7%B3%8A%E4%BE%9D%E5%AD%98%E5%85%B3%E7%B3%BB%E5%8C%B9%E9%85%8D%E7%9A%84%E9%97%AE%E7%AD%94%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95.html&quot;&gt;《一种基于模糊依存关系匹配的问答模型构建方法》&lt;/a&gt;我们分析了基于模糊依存关系匹配的问答模型构建，其基本思想是通过模糊匹配问题（question）和包含候选答案的句子（Sentence）间的依存关系来定位问题的答案，&lt;strong&gt;依存关系主要反映的是句子中核心词和依存词之间的语义关系&lt;/strong&gt;，这种分析方法也可能为传统机器学习方法的特征工程提供一些思路，还是出于构建特征工程需要的考虑，受余正涛教授的《基于潜在语义分析的汉语问答系统答案提取》的启发，我们继续挖掘问题（question）和包含候选答案的句子（Sentence）中词与词之间的潜在语义关系，并基于此利用潜在语义分析（Latent Semantic Analysis，LSA）思想来定位答案所在的句子。&lt;/p&gt;

&lt;h1 id=&quot;1-背景&quot;&gt;&lt;strong&gt;1 背景&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;在&lt;a href=&quot;https://zhoum1118.github.io/deeplearning/2018/04/30/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%A8%A1%E7%B3%8A%E4%BE%9D%E5%AD%98%E5%85%B3%E7%B3%BB%E5%8C%B9%E9%85%8D%E7%9A%84%E9%97%AE%E7%AD%94%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95.html&quot;&gt;《一种基于模糊依存关系匹配的问答模型构建方法》&lt;/a&gt;中我们介绍了传统问答系统定位答案的过程，在其中第二步，还可以在细分为，提取包含答案的句子，然后再从句子中提取答案。由此可见定位答案所在的句子是答案更细粒度的一种表示，而《基于潜在语义分析的汉语问答系统答案提取》便是针对事实简单陈述问题的答案句子的提取。&lt;/p&gt;

&lt;p&gt;不难发现，定位答案所在的句子，即计算问题（question）和文档各个句子的相似度，相似度最高的句子即为答案。问题转化为计算两个句子的相似度，相似度传统的计算方法为关键词匹配方法，在&lt;a href=&quot;https://zhoum1118.github.io/deeplearning/2018/04/30/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%A8%A1%E7%B3%8A%E4%BE%9D%E5%AD%98%E5%85%B3%E7%B3%BB%E5%8C%B9%E9%85%8D%E7%9A%84%E9%97%AE%E7%AD%94%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95.html&quot;&gt;《一种基于模糊依存关系匹配的问答模型构建方法》&lt;/a&gt;一文中有提到，即通过统计两个句子中拥有共同关键词的数量来确定两者的相似程度。&lt;strong&gt;但这种方法过于简单，且对于中文问答系统，句子中的词存在同义或多义现象。&lt;/strong&gt;所以如果不考虑关键词所在的上下文信息和关键词的词性，那么对于基于关键词匹配方法，句子中出现词同义而又过于追求词匹配，则可能导致漏掉包含正确答案的句子。比如，问题Q1：北京奥运会开幕时间是什么时候？关键词是“北京奥运会”和“开幕时间”，那么对于“北京奥运会于2008年8月8日晚上8时开始”或“北京奥运会2008年8月8日晚上8时整于中华人民共和国首都北京举办”等包含正确答案的句子将可能被漏掉。如果句子中出现词多义的情况，比如“代表”，其可作为名词和动词，那么基于关键词匹配方法就很可能出现把错误的句子定位成正确的。&lt;/p&gt;

&lt;p&gt;基于关键词匹配方法的不足，出现了一种基于LSA的答案定位方法。&lt;strong&gt;LSA的基本思想是通过统计分析文档中词与词之间的某种语义结构，消除词同义和多义的影响。&lt;/strong&gt;这是对传统向量空间技术的一种改良，在信息检索、信息过滤、文档分类、自动摘要以及文旦系统等领域都有较好的应用效果。基于潜在语义分析的问答系统答案定位方法使用LSA思想，通过统计分析构造了一个词-句子的语义空间，以此来消除词之间的相关性，然后基于词-句子的语义空间计算问题（question）和句子之间的相似度，最终定位答案所在的句子，在一定程度上提高了答案定位的准确率。&lt;/p&gt;

&lt;h1 id=&quot;2-基于潜在语义分析的问答系统答案定位方法&quot;&gt;&lt;strong&gt;2 基于潜在语义分析的问答系统答案定位方法&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;21-lsa&quot;&gt;&lt;strong&gt;2.1 LSA&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;首先，定义一个 &lt;code class=&quot;highlighter-rouge&quot;&gt;m * n&lt;/code&gt; 的词-文档矩阵&lt;code class=&quot;highlighter-rouge&quot;&gt;A&lt;/code&gt;：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;一种基于潜在语义分析的问答系统答案定位方法_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5aebb7990001a91b08000088.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中，&lt;code class=&quot;highlighter-rouge&quot;&gt;a_ij&lt;/code&gt;表示第&lt;code class=&quot;highlighter-rouge&quot;&gt;i&lt;/code&gt;个词在第&lt;code class=&quot;highlighter-rouge&quot;&gt;j&lt;/code&gt;个文档中出现的次数，&lt;code class=&quot;highlighter-rouge&quot;&gt;m&lt;/code&gt;表示关键词的个数，&lt;code class=&quot;highlighter-rouge&quot;&gt;n&lt;/code&gt;表示文档树。&lt;/p&gt;

&lt;p&gt;经过矩阵奇异值分解后：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;一种基于潜在语义分析的问答系统答案定位方法_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5aebb7b9000174bb07300086.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中，&lt;code class=&quot;highlighter-rouge&quot;&gt;U&lt;/code&gt;为 &lt;code class=&quot;highlighter-rouge&quot;&gt;m * m&lt;/code&gt; 的正交矩阵，&lt;img title=&quot;一种基于潜在语义分析的问答系统答案定位方法_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5aebb7cc0001d6ea00620056.png&quot; alt=&quot;图片描述&quot; style=&quot;width:3%&quot; /&gt;为 &lt;code class=&quot;highlighter-rouge&quot;&gt;m * n&lt;/code&gt; 的对角矩阵，&lt;code class=&quot;highlighter-rouge&quot;&gt;V&lt;/code&gt;为 &lt;code class=&quot;highlighter-rouge&quot;&gt;n * n&lt;/code&gt; 的正交矩阵。&lt;/p&gt;

&lt;p&gt;分析易得，&lt;code class=&quot;highlighter-rouge&quot;&gt;m&lt;/code&gt;一般对大于&lt;code class=&quot;highlighter-rouge&quot;&gt;n&lt;/code&gt;，且每个关键词只会出现在少量的文档中，所以&lt;code class=&quot;highlighter-rouge&quot;&gt;A&lt;/code&gt;一般为高阶稀疏矩阵，而这里进行&lt;strong&gt;奇异值分解的意义&lt;/strong&gt;在于：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;奇异值往往对应着矩阵中隐含的重要信息，且重要性和奇异值大小正相关。每个矩阵A都可以表示为一系列秩为1的“小矩阵”之和，而奇异值则衡量了这些“小矩阵”对于A的权重。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;为了在降低计算复杂度的前提下，最大程度的构建包含丰富潜在语义的向量空间，我们假设经过奇异值分解后的&lt;code class=&quot;highlighter-rouge&quot;&gt;A&lt;/code&gt;的秩为&lt;code class=&quot;highlighter-rouge&quot;&gt;r&lt;/code&gt;，存在一个&lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;k &amp;lt;= r&lt;/code&gt;，且&lt;code class=&quot;highlighter-rouge&quot;&gt;k &amp;lt;&amp;lt; min(m, n)&lt;/code&gt;，则&lt;code class=&quot;highlighter-rouge&quot;&gt;A&lt;/code&gt;的&lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt;秩近似矩阵&lt;code class=&quot;highlighter-rouge&quot;&gt;A_k&lt;/code&gt;为：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;一种基于潜在语义分析的问答系统答案定位方法_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5aebb7e600010f0707400086.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中，&lt;code class=&quot;highlighter-rouge&quot;&gt;U_k&lt;/code&gt;为 &lt;code class=&quot;highlighter-rouge&quot;&gt;m * k&lt;/code&gt; 的矩阵，由&lt;code class=&quot;highlighter-rouge&quot;&gt;U&lt;/code&gt;的前&lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt;列组成；&lt;img title=&quot;一种基于潜在语义分析的问答系统答案定位方法_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5aebb7f900018c5e00560056.png&quot; alt=&quot;图片描述&quot; style=&quot;width:3%&quot; /&gt;是 &lt;code class=&quot;highlighter-rouge&quot;&gt;k * k&lt;/code&gt; 的矩阵，由&lt;img title=&quot;一种基于潜在语义分析的问答系统答案定位方法_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5aebb8060001d6ea00620056.png&quot; alt=&quot;图片描述&quot; style=&quot;width:3%&quot; /&gt;的前&lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt;行、前&lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt;列组成；&lt;code class=&quot;highlighter-rouge&quot;&gt;V_k&lt;/code&gt;是 &lt;code class=&quot;highlighter-rouge&quot;&gt;k * n&lt;/code&gt; 的矩阵，由&lt;code class=&quot;highlighter-rouge&quot;&gt;V&lt;/code&gt;的前&lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt;行组成。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;A_k&lt;/code&gt;近似保存了词与文档之间的潜在语义关系，且去除了大量因词汇同义或多义产生的“噪点”，也就是说，&lt;strong&gt;那些经常出现在相似的上下文中的词，在&lt;code class=&quot;highlighter-rouge&quot;&gt;A_k&lt;/code&gt;的&lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt;维词空间中的距离也就比较小&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;潜在语义空间转换是一个降维过程，具体降多少维视任务情况而定，如果&lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt;过大，接近标准向量空间，也就失去表示词相依性的能力，且存在大量噪点，计算复杂度也大；&lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt;过小，也无法表示丰富的语义结构，模型也就毫无意义。&lt;/strong&gt;一般来说&lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt;值在&lt;code class=&quot;highlighter-rouge&quot;&gt;100~300&lt;/code&gt;之间。&lt;/p&gt;

&lt;h2 id=&quot;22-相似度计算方法&quot;&gt;&lt;strong&gt;2.2 相似度计算方法&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;2.2.1 向量空间模型（Vector Space Model，VSM）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;问题（question）向量表示为&lt;code class=&quot;highlighter-rouge&quot;&gt;q=(q_1, q_2, …, q_i, …, q_n)&lt;/code&gt;，其中&lt;code class=&quot;highlighter-rouge&quot;&gt;n&lt;/code&gt;表示语料库中所有关键词的数量，&lt;code class=&quot;highlighter-rouge&quot;&gt;q_i&lt;/code&gt;表示第&lt;code class=&quot;highlighter-rouge&quot;&gt;i&lt;/code&gt;个关键词在问题中出现的次数；同样的，候选答案句子&lt;code class=&quot;highlighter-rouge&quot;&gt;S&lt;/code&gt;可表示为&lt;code class=&quot;highlighter-rouge&quot;&gt;S=(s_1, s_2, …, s_i, …, s_n)&lt;/code&gt;，计算两个向量的余弦值作为两者相似度的一个度量：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;一种基于潜在语义分析的问答系统答案定位方法_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5aebb8200001435009040258.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中，&lt;code class=&quot;highlighter-rouge&quot;&gt;n&lt;/code&gt;为问题中包含关键词的总个数，&lt;code class=&quot;highlighter-rouge&quot;&gt;tf_i&lt;/code&gt;为问题的第&lt;code class=&quot;highlighter-rouge&quot;&gt;i&lt;/code&gt;个关键词在问题&lt;code class=&quot;highlighter-rouge&quot;&gt;q&lt;/code&gt;和候选答案句子&lt;code class=&quot;highlighter-rouge&quot;&gt;S&lt;/code&gt;中出现的频率，&lt;code class=&quot;highlighter-rouge&quot;&gt;idf_i&lt;/code&gt;为问题的第&lt;code class=&quot;highlighter-rouge&quot;&gt;i&lt;/code&gt;个关键词的倒排频率，&lt;code class=&quot;highlighter-rouge&quot;&gt;Sentence_Length&lt;/code&gt;为候选答案句子所包含词（这里应该是全部的词）的个数，&lt;code class=&quot;highlighter-rouge&quot;&gt;Sentence_length_avg&lt;/code&gt;表示语料库所有句子包含词个数的平均值。&lt;/p&gt;

&lt;p&gt;从计算过程可以看出，&lt;strong&gt;这种方法仅仅考察的是问题与候选答案句子中关键词的词频信息，而没有考虑词在上下文的语义信息，所以具有一定的局限性，但从特征工程的角度看，这或许可以作为其中特征之一来构建模型。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.2.2 基于LSA的问题与候选答案句子相似度计算&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;首先，如2.1所述，构造一个 &lt;code class=&quot;highlighter-rouge&quot;&gt;m * n&lt;/code&gt; 的关键词-句子矩阵&lt;code class=&quot;highlighter-rouge&quot;&gt;A&lt;/code&gt;，其中每个关键词&lt;code class=&quot;highlighter-rouge&quot;&gt;t_i&lt;/code&gt;在句子&lt;code class=&quot;highlighter-rouge&quot;&gt;s_j&lt;/code&gt;中的权重&lt;code class=&quot;highlighter-rouge&quot;&gt;a_ij&lt;/code&gt;定义为：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;一种基于潜在语义分析的问答系统答案定位方法_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5aebb86b00017f4408340252.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中，&lt;code class=&quot;highlighter-rouge&quot;&gt;tf_ij&lt;/code&gt;为词&lt;code class=&quot;highlighter-rouge&quot;&gt;t_i&lt;/code&gt;在句子&lt;code class=&quot;highlighter-rouge&quot;&gt;s_j&lt;/code&gt;中的词频，&lt;code class=&quot;highlighter-rouge&quot;&gt;N&lt;/code&gt;为语料库中句子总数，&lt;code class=&quot;highlighter-rouge&quot;&gt;nt_i&lt;/code&gt;为语料库句子中出现关键词&lt;code class=&quot;highlighter-rouge&quot;&gt;t_i&lt;/code&gt;的句子数，分母为其归一化因子。&lt;/p&gt;

&lt;p&gt;然后经过矩阵奇异值分解并降维后得到一个潜在词-句子的语义空间&lt;code class=&quot;highlighter-rouge&quot;&gt;A_k&lt;/code&gt;，将问题向量&lt;code class=&quot;highlighter-rouge&quot;&gt;q&lt;/code&gt;和候选答案句子向量&lt;code class=&quot;highlighter-rouge&quot;&gt;S&lt;/code&gt;映射到这个语义空间，向量表示方法和2.2.1一致，映射公式如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;一种基于潜在语义分析的问答系统答案定位方法_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5aebb88500016ed409400076.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中，&lt;img title=&quot;一种基于潜在语义分析的问答系统答案定位方法_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5aebb8950001072800800056.png&quot; alt=&quot;图片描述&quot; style=&quot;width:4%&quot; /&gt;是&lt;img title=&quot;一种基于潜在语义分析的问答系统答案定位方法_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5aebb8a000018c5e00560056.png&quot; alt=&quot;图片描述&quot; style=&quot;width:3%&quot; /&gt;的逆矩阵，&lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt;为映射前的向量。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;通常映射前的向量&lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt;中大部分元素为0，在映射后0元素基本没有，即经过语义空间转换的向量不在是简单的关键词词频组成的，而是包含了其在上下文语义关系的权值信息，反映了关键词之间的一定的相关性&lt;/strong&gt;，此时相似度计算公式为：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;一种基于潜在语义分析的问答系统答案定位方法_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5aebb8b40001098708860268.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中，&lt;code class=&quot;highlighter-rouge&quot;&gt;q~*&lt;/code&gt;为问题语义向量，&lt;code class=&quot;highlighter-rouge&quot;&gt;s_j&lt;/code&gt;为第&lt;code class=&quot;highlighter-rouge&quot;&gt;j&lt;/code&gt;个候选答案句子向量，&lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt;为语义空间的维数，&lt;code class=&quot;highlighter-rouge&quot;&gt;q_m&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;s_jm&lt;/code&gt;分别为问题语义向量和候选答案句子向量中第&lt;code class=&quot;highlighter-rouge&quot;&gt;m&lt;/code&gt;维权值。&lt;/p&gt;
</description>
        <pubDate>Fri, 04 May 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deeplearning/2018/05/04/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%BD%9C%E5%9C%A8%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90%E7%9A%84%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F%E7%AD%94%E6%A1%88%E5%AE%9A%E4%BD%8D%E6%96%B9%E6%B3%95.html</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2018/05/04/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%BD%9C%E5%9C%A8%E8%AF%AD%E4%B9%89%E5%88%86%E6%9E%90%E7%9A%84%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F%E7%AD%94%E6%A1%88%E5%AE%9A%E4%BD%8D%E6%96%B9%E6%B3%95.html</guid>
        
        <category>潜在语义分析</category>
        
        <category>问答系统</category>
        
        <category>答案定位</category>
        
        
        <category>Deeplearning</category>
        
      </item>
    
      <item>
        <title>一种基于模糊依存关系匹配的问答模型构建方法</title>
        <description>&lt;h1 id=&quot;0-前言&quot;&gt;&lt;strong&gt;0 前言&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;基于传统机器学习方法构建问答模型的主要工作是构建适合当前任务的特征工程，在&lt;a href=&quot;https://zhoum1118.github.io/deeplearning/2018/04/28/%E4%B8%AD%E6%96%87%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%BB%BA%E6%A8%A1%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B.html&quot;&gt;《中文自然语言处理建模过程中的特征工程》&lt;/a&gt;一文中，我们介绍了很多可提取的特征以及提取方法，主要的特征集中在句法分析上。我们都知道，&lt;strong&gt;句法分析是NLP中的关键底层技术之一，也是构建特征工程时经常用到的，其基本目标是确定句子的句法结构或者句子中词汇之间的依存关系。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;句法分析分为&lt;strong&gt;句法结构分析&lt;/strong&gt;（syntactic structure parsing）和&lt;strong&gt;依存关系分析&lt;/strong&gt;（dependency parsing）。句法结构分析以其目的不同分为&lt;strong&gt;成分结构分析&lt;/strong&gt;（constituent structure parsing）或者&lt;strong&gt;短语结构分析&lt;/strong&gt;（phrase structure parsing），成分结构分析以获取整个句子的句法结构为目的，而短语结构分析以获取完全短语结构为目的；&lt;strong&gt;依存关系分析&lt;/strong&gt;则以获取局部成分之间的依存关系为目的。&lt;/p&gt;

&lt;p&gt;《Question Answering Passage Retrieval Using Dependency Relations》中通过&lt;strong&gt;对问题（question）和包含候选答案的句子（Sentence）间的依存关系的分析，提出了一种基于模糊依存关系匹配的问答模型的构建方法&lt;/strong&gt;。实验模型在不同数据集下，相比基于词匹配和基于严格依存关系的模型效果要更好。分析这篇论文发现，&lt;strong&gt;在某些任务中，模糊依存关系可以作为特征工程的一部分，所以记录下来，以便未来建模需要。&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;1-背景&quot;&gt;&lt;strong&gt;1 背景&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;传统问答系统定位答案的过程&lt;/strong&gt;：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;定位相关的文档&lt;/li&gt;
  &lt;li&gt;定位文档中答案可能所在的段落&lt;/li&gt;
  &lt;li&gt;在备选段落中精确定位，找到答案&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这种传统问答系统定位答案的方法并非一蹴而就，而是在不断缩小答案可能所在的范围。在这个过程中需要每一步都准确无误，否则一步错而步步错。但段落的定位是而这种方法的重点和难点，如果连可能包含答案的段落都找错了，那肯定不会找到正确的答案了。相反如果段落定位准确，即使答案的精确定位错误也不影响大局（可直接返回段落作为答案），因为有研究表明，&lt;strong&gt;一个段落足以包含回答问题所需要的信息&lt;/strong&gt;，且用户也更倾向于模型给出的答案是一个段落，理由是一个段落可以提供完整的答案上下文，有助于理解答案的含义。当然研究肯定不是只止步于此，精确地回答问题依旧是问答系统或机器阅读理解的最终目的。&lt;/p&gt;

&lt;p&gt;在基于依存关系匹配来回答问题之前，就出现了&lt;strong&gt;基于词匹配来回答问题&lt;/strong&gt;。这种方法通过分析问题句与候选答案句之间词汇来定位答案所在句子，这种方法过于追求句子间词汇的匹配而忽视了词之间的依存关系，比如，图1展示了一个问题和四个候选答案句，其中&lt;code class=&quot;highlighter-rouge&quot;&gt;S1&lt;/code&gt;为正确答案句，但分析这四个句子可发现，词匹配最多的并不是&lt;code class=&quot;highlighter-rouge&quot;&gt;S1&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;一种基于模糊依存关系匹配的问答模型构建方法_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ae6d22a0001366d08980492.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 1 基于词匹配方法的例子&lt;/p&gt;

&lt;p&gt;还有一种方法是&lt;strong&gt;基于依存关系匹配方法，但是匹配要求较为严格&lt;/strong&gt;，对于语义相同但表述不同的情况也视为匹配失败。但在实际应用中，在问题句和答案句的句法分析树中，核心词之间相似的关系往往有不同的表述方式，严格匹配容易把正确的当成错误的，即模型召回率低。&lt;/p&gt;

&lt;h1 id=&quot;2-基于模糊依存关系匹配的问答模型构建方法&quot;&gt;&lt;strong&gt;2 基于模糊依存关系匹配的问答模型构建方法&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;我们首先介绍了如何从依存关系树中提取关系路径并对其进行配对。然后计算两条关系路径的匹配分数，匹配分数包含了两条路径中单个关系的映射分数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.1 依存关系的提取-依存关系树&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;依存关系树的构建工具有很多，详情可见&lt;a href=&quot;https://zhoum1118.github.io/deeplearning/2018/04/26/%E4%BD%A0%E9%9C%80%E8%A6%81%E7%9F%A5%E9%81%93%E7%9A%84%E5%87%A0%E4%B8%AA%E5%A5%BD%E7%94%A8%E7%9A%84%E4%B8%AD%E6%96%87%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7.html&quot;&gt;《你需要知道的几个好用的中文词法分析工具》&lt;/a&gt;。《Question Answering Passage Retrieval Using Dependency Relations》使用了&lt;code class=&quot;highlighter-rouge&quot;&gt;Minipar&lt;/code&gt;来构建依存关系树，图2展示了在图1中问题句和答案句&lt;code class=&quot;highlighter-rouge&quot;&gt;S1&lt;/code&gt;的依存关系树。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;一种基于模糊依存关系匹配的问答模型构建方法_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ae6d2410001583806860562.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 2 依存关系树&lt;/p&gt;

&lt;p&gt;在提取两个句子的依存关系时，需注意以下几点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;虽然依赖关系是有向链接，但我们忽略了关系的方向；&lt;/li&gt;
  &lt;li&gt;路径长度不能超过预定义的阈值（7），其目的是排除异常长的路径，因为&lt;code class=&quot;highlighter-rouge&quot;&gt;Minipar&lt;/code&gt;只能可靠地解决附近的依赖关系；&lt;/li&gt;
  &lt;li&gt;如果两个词属于相同的块(通常是名词短语或动词短语)，我们忽略了它们之间的关系路径（这是由&lt;code class=&quot;highlighter-rouge&quot;&gt;MiniPar&lt;/code&gt;确定的），比如&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;‘28’和‘28 percent’
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;为了确定依赖关系的相关性，对于两个句子，提取出主要节点（node），并匹配它们在两个句子中的依赖关系，node的类型一般为&lt;strong&gt;名词、动词和形容词&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在依存关系树中，我们可以提取出主要节点的依存路径，如图3所示。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;一种基于模糊依存关系匹配的问答模型构建方法_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ae6d25000012c2c09080496.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 3 主要节点的依存路径&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Minipar&lt;/code&gt;有42个主要的依存关系，比如&lt;code class=&quot;highlighter-rouge&quot;&gt;subj (subjective)&lt;/code&gt; 表示主观关系；&lt;code class=&quot;highlighter-rouge&quot;&gt;mod (modifying)&lt;/code&gt; 表示修饰关系；&lt;code class=&quot;highlighter-rouge&quot;&gt;pcomp-n (nominal complement of a preposition)&lt;/code&gt; 表示介词的名词补充。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.2 模糊依存关系匹配分数计算&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;以图3为例，我们需要计算问题句&lt;code class=&quot;highlighter-rouge&quot;&gt;question&lt;/code&gt;的依存关系路径&lt;code class=&quot;highlighter-rouge&quot;&gt;（&amp;lt;subj&amp;gt;-&amp;lt;head, whn, prep, pcomp-n&amp;gt;-&amp;lt;gen&amp;gt;）&lt;/code&gt;和答案句&lt;code class=&quot;highlighter-rouge&quot;&gt;S1&lt;/code&gt;的依存关系路径&lt;code class=&quot;highlighter-rouge&quot;&gt;（&amp;lt;pcomp-n, mod, i&amp;gt;-&amp;lt;obj, mod, pcomp-n&amp;gt;-&amp;lt;gen&amp;gt;）&lt;/code&gt;间的匹配分数，注意到这里的node是一样的。&lt;/p&gt;

&lt;p&gt;我们&lt;strong&gt;将候选答案句子的关系路径的匹配分数看作是从问题句中的对应路径转换到候选答案句的关系路径的概率&lt;/strong&gt;。计算公式如下。（这里有个小思考：&lt;strong&gt;两个关系路径的最小编辑距离应该也可以作为模型特征工程的一部分&lt;/strong&gt;）&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;一种基于模糊依存关系匹配的问答模型构建方法_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ae6d25f0001973307260104.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中，&lt;code class=&quot;highlighter-rouge&quot;&gt;P_s&lt;/code&gt;表示候选答案句的依存关系路径，其长度为&lt;code class=&quot;highlighter-rouge&quot;&gt;n&lt;/code&gt;；&lt;code class=&quot;highlighter-rouge&quot;&gt;P_Q&lt;/code&gt;表示问题句的依存关系路径，其长度为&lt;code class=&quot;highlighter-rouge&quot;&gt;m&lt;/code&gt;；&lt;code class=&quot;highlighter-rouge&quot;&gt;Rel_(s)_i&lt;/code&gt;表示&lt;code class=&quot;highlighter-rouge&quot;&gt;P_s&lt;/code&gt;中第&lt;code class=&quot;highlighter-rouge&quot;&gt;i&lt;/code&gt;个关系，&lt;code class=&quot;highlighter-rouge&quot;&gt;Rel_(Q)_ai&lt;/code&gt;则为在&lt;code class=&quot;highlighter-rouge&quot;&gt;P_Q&lt;/code&gt;中对应的关系；&lt;code class=&quot;highlighter-rouge&quot;&gt;P_t(Rel_(s)_i | Rel_(Q)_j)&lt;/code&gt;表示两种依存关系转换的概率。这里假设每一种关系都可以转换成另一种关系，所以&lt;code class=&quot;highlighter-rouge&quot;&gt;P_t(Rel_(s)_i | Rel_(Q)_j)&lt;/code&gt;是大于0，小于等于1的值，当&lt;code class=&quot;highlighter-rouge&quot;&gt;P_t(Rel_(s)_i | Rel_(Q)_j)=1&lt;/code&gt;时，表示&lt;code class=&quot;highlighter-rouge&quot;&gt;Rel_(s)_i&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;Rel_(Q)_j&lt;/code&gt;是一样的，那么自己匹配自己时，其匹配概率是100%。&lt;/p&gt;

&lt;p&gt;分析语料库，在实际依存关系匹配中，&lt;strong&gt;我们不需要匹配两个句子所有的依存关系路径，而是只要从关系路径中的每个关系中找到对应路径中最可能映射的关系来计算匹配分数即可&lt;/strong&gt;。于是公式可简化为：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;一种基于模糊依存关系匹配的问答模型构建方法_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ae6d26c0001714f05380080.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中，&lt;code class=&quot;highlighter-rouge&quot;&gt;A_i&lt;/code&gt;表示最有可能映射的关系组合。&lt;/p&gt;

&lt;p&gt;最终的匹配分数计算公式为：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;一种基于模糊依存关系匹配的问答模型构建方法_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ae6d2780001239105840156.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;到这，我们只需要得到&lt;code class=&quot;highlighter-rouge&quot;&gt;P_t(Rel_(s)_i | Rel_(Q)_j)&lt;/code&gt;就能计算最终的匹配分数，两种依存关系的相关性通过依存关系路径的双向共现量&lt;code class=&quot;highlighter-rouge&quot;&gt;（bipartite co-occurrences）&lt;/code&gt;来测量，计算公式如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;一种基于模糊依存关系匹配的问答模型构建方法_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ae6d2860001e69106560104.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中，&lt;img title=&quot;一种基于模糊依存关系匹配的问答模型构建方法_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ae6d29100015ddb02260042.png&quot; alt=&quot;图片描述&quot; style=&quot;width:20%&quot; /&gt;为一个分段函数，当依存关系&lt;code class=&quot;highlighter-rouge&quot;&gt;Rel_(Q)_j&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;Rel_(S)_i&lt;/code&gt;在依存关系路径中都出现了，那么其值为&lt;code class=&quot;highlighter-rouge&quot;&gt;1&lt;/code&gt;，否则为&lt;code class=&quot;highlighter-rouge&quot;&gt;0&lt;/code&gt;；&lt;code class=&quot;highlighter-rouge&quot;&gt;γ&lt;/code&gt;是两条依存关系路径长度之和的倒数。&lt;code class=&quot;highlighter-rouge&quot;&gt;|Rel_(Q)_j|&lt;/code&gt;为所有问题句的依存关系路径中包含依存关系&lt;code class=&quot;highlighter-rouge&quot;&gt;Rel_(Q)_j&lt;/code&gt;的个数；&lt;code class=&quot;highlighter-rouge&quot;&gt;|Rel_(S)_i|&lt;/code&gt;为所有答案句的依存关系路径中包含依存关系&lt;code class=&quot;highlighter-rouge&quot;&gt;Rel_(S)_i&lt;/code&gt;的个数。&lt;/p&gt;

&lt;p&gt;从计算过程中，我们可以看出，&lt;strong&gt;如果问题句的长度越长，依存关系路径也可能越长，那么在一定程度上其包含的信息越多，得到正确答案的概率就越大&lt;/strong&gt;。&lt;/p&gt;
</description>
        <pubDate>Mon, 30 Apr 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deeplearning/2018/04/30/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%A8%A1%E7%B3%8A%E4%BE%9D%E5%AD%98%E5%85%B3%E7%B3%BB%E5%8C%B9%E9%85%8D%E7%9A%84%E9%97%AE%E7%AD%94%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95.html</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2018/04/30/%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%A8%A1%E7%B3%8A%E4%BE%9D%E5%AD%98%E5%85%B3%E7%B3%BB%E5%8C%B9%E9%85%8D%E7%9A%84%E9%97%AE%E7%AD%94%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95.html</guid>
        
        <category>依存关系</category>
        
        <category>模糊匹配</category>
        
        <category>问答模型</category>
        
        
        <category>Deeplearning</category>
        
      </item>
    
      <item>
        <title>中文自然语言处理建模过程中的特征工程</title>
        <description>&lt;p&gt;近来在尝试用传统机器学习方法来做一个中文问答系统，传统机器学习方法建模其实&lt;strong&gt;主要的工作在于模型的特征工程&lt;/strong&gt;，本文主要受哈工大的《中文语义角色标注的特征工程》及其参考文献的启发，分析及总结了在中文的自然语言处理任务的特征工程中可能用到的特征，以及特征提取的方法。&lt;/p&gt;

&lt;p&gt;其实在&lt;a href=&quot;https://zhoum1118.github.io/deeplearning/2018/04/25/%E5%9F%BA%E4%BA%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E7%9A%84%E4%B8%AD%E6%96%87%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E6%A8%A1%E5%9E%8B.html&quot;&gt;《基于最大熵的中文阅读理解模型》&lt;/a&gt;中我们分析了词层面和句法层面的特征及提取，对于词层面的特征提取，通常需要进行&lt;strong&gt;分词、词性标注以及命名实体（NE）识别&lt;/strong&gt;。在《你需要知道的几个好用的中文词法分析工具》中调研了几个常用的中文自然语言处理工具，通过调用接口、jar包等方式，我们可以很方便地使用这些工具来完成分词、词性标注以及命名实体标注等基本功能。&lt;/p&gt;

&lt;p&gt;1、在对句子进行&lt;strong&gt;分词、词性标注和命名实体标注&lt;/strong&gt;后，我们可以统计句子中词频，各类型词性个数以及句子中命名实体的种类和数量，并将其转化为特征；&lt;/p&gt;

&lt;p&gt;2、&lt;strong&gt;中心词及其词性特征及提取&lt;/strong&gt;：中心词是指在句子中具有重要意义的成分，中心词可以挖掘动词与施事者、受事者之间的关系。通过分析实验的语料库并统计中心词的词频，提取适合当前任务的中心词词典，图1展示了《Shallow Semantic Parsing of Chinese》中前20个中心词。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;中文自然语言处理建模过程中的特征工程_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ae3c72c000107d807780446.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图1 《Shallow Semantic Parsing of Chinese》中前20个中心词&lt;/p&gt;

&lt;p&gt;3、&lt;strong&gt;句法分析树&lt;/strong&gt;：在&lt;a href=&quot;https://zhoum1118.github.io/deeplearning/2018/04/26/%E4%BD%A0%E9%9C%80%E8%A6%81%E7%9F%A5%E9%81%93%E7%9A%84%E5%87%A0%E4%B8%AA%E5%A5%BD%E7%94%A8%E7%9A%84%E4%B8%AD%E6%96%87%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7.html&quot;&gt;《你需要知道的几个好用的中文词法分析工具》&lt;/a&gt;中我们也介绍了一些句法分析树构造工具，将句子转化成如图2所示的句法分析树，以此提取句法分析树特征。句法分析树特征可包含：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;句法分析树中&lt;strong&gt;左、右兄弟句法成分的短语类型&lt;/strong&gt;；&lt;/li&gt;
  &lt;li&gt;由谓语动词的父节点、谓语动词本身以及谓语动词子节点构成&lt;strong&gt;子类框架&lt;/strong&gt;（如图2中的“通过”的子类框架为：&lt;code class=&quot;highlighter-rouge&quot;&gt;VP-VV-(NP-OBJ)&lt;/code&gt;）；&lt;/li&gt;
  &lt;li&gt;句法分析树中&lt;strong&gt;当前句法成分到谓语动词的句法路径&lt;/strong&gt;（“委员会”的句法路径为：&lt;code class=&quot;highlighter-rouge&quot;&gt;(NP-SBJ)-IP-VP-VP-VV&lt;/code&gt;）；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;部分路径&lt;/strong&gt;，当前句法成分到它和当前谓语动词的最近共同父节点的句法路径（“委员会”的部分路径为：&lt;code class=&quot;highlighter-rouge&quot;&gt;(NP-SBJ)-IP-VP&lt;/code&gt;）；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;位置特征&lt;/strong&gt;，句法成分在谓语动词的前面还是后面；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;句法框架特征&lt;/strong&gt;，包含句子的谓语动词和围绕谓语动词的名词短语。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img title=&quot;中文自然语言处理建模过程中的特征工程_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ae3c7450001a15908480586.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:50%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图2 句法分析树&lt;/p&gt;

&lt;p&gt;4、&lt;strong&gt;谓语动词的类别信息&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;5、&lt;strong&gt;语义角色类型&lt;/strong&gt;：IO（简接宾语）、OBJ（直接宾语）、SBJ（主语）等，这些功能标记暗示着语义角色类型。Chinese Proposition Bank（CPB）语料库手工标记了语义角色类型。通过语义角色类型，我们可以进一步分析不同句法成分之间的关系，包含主谓关系，动宾关系等。图3展示了《基于句法模式识别的中文关系抽取方法研究与实现》中论元和关系词抽取流程。图 4 展示了句法成分的依存关系。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;中文自然语言处理建模过程中的特征工程_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ae3c75600013bcd08441316.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:50%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 3 论元和关系词抽取流程&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;中文自然语言处理建模过程中的特征工程_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ae3c7650001ef0413500180.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图4 句法成分的依存关系&lt;/p&gt;

&lt;p&gt;6、&lt;strong&gt;句子包含的子句数&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;7、&lt;strong&gt;句法成分与谓语动词的相对位置&lt;/strong&gt;：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;是否有兄弟节点关系；&lt;/li&gt;
  &lt;li&gt;是否有相同动词短语的子节点；&lt;/li&gt;
  &lt;li&gt;是否属于相同子句或短语的子节点。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;刘怀军, 车万翔, 刘挺. 中文语义角色标注的特征工程[J]. 中文信息学报, 2007, 21(1):79-84.&lt;/li&gt;
  &lt;li&gt;Sun H, Jurafsky D. Shallow Semantic Parsing of Chinese[J].
Proceedings of Naacl, 2004.&lt;/li&gt;
  &lt;li&gt;郝博. 基于句法模式识别的中文关系抽取方法研究与实现[D].电子科技大学,2017.&lt;/li&gt;
  &lt;li&gt;潘苏. 中文语义角色标注研究及系统实现[D].苏州大学,2017&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Sat, 28 Apr 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deeplearning/2018/04/28/%E4%B8%AD%E6%96%87%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%BB%BA%E6%A8%A1%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B.html</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2018/04/28/%E4%B8%AD%E6%96%87%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%BB%BA%E6%A8%A1%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B.html</guid>
        
        <category>自然语言处理</category>
        
        <category>建模</category>
        
        <category>特征工程</category>
        
        
        <category>Deeplearning</category>
        
      </item>
    
      <item>
        <title>你需要知道的几个好用的中文词法分析工具</title>
        <description>&lt;h1 id=&quot;1stanford-corenlp&quot;&gt;&lt;strong&gt;1、Stanford CoreNLP&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;Stanford CoreNLP是&lt;strong&gt;斯坦福大学自然语言处理小组&lt;/strong&gt;开发的自然语言分析工具集，包含&lt;strong&gt;分句，分词，词性标注，命名实体识别，句法分析，指代消解，情感分析&lt;/strong&gt;等功能，这些工具采用流式(pipeline)集成方式，各功能模块之间相互解耦，提供单独的包下载，高度灵活且可扩展性强。Stanford CoreNLP支持&lt;strong&gt;英文、阿拉伯文、中文、法文、德文以及西班牙文&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Stanford CoreNLP工具采用Java语言开发&lt;/strong&gt;，支持Java 8+。提供jar包下载，便于集成到Java代码中，同时也支持C#，Node.js，PHP，Python等语言调用。&lt;/p&gt;

&lt;p&gt;Stanford CoreNLP的分词和命名实体识别工具是基于条件随机场模型实现的，而词性标注则是基于双向依存网络模型。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;官网介绍地址&lt;/strong&gt;：https://stanfordnlp.github.io/CoreNLP/index.html；&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;论文地址&lt;/strong&gt;：https://nlp.stanford.edu/pubs/StanfordCoreNlp2014.pdf；&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;中文文本处理工具下载地址&lt;/strong&gt;：http://nlp.stanford.edu/software/stanford-chinese-corenlp-2018-02-27-models.jar。&lt;/p&gt;

&lt;h1 id=&quot;2语言技术平台language-technology-platforltp&quot;&gt;&lt;strong&gt;2、语言技术平台（Language Technology Platfor，LTP）&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;LTP是&lt;strong&gt;哈尔滨大学社会计算与信息检索研究中心&lt;/strong&gt;发布的一套中文自然语言处理工具集，包含&lt;strong&gt;分句，分词，词性标注，命名实体识别，依存句法分析，语义角色标注，语义依存分析（树、图结构）&lt;/strong&gt;等工具。LTP同样采用流式集成方式，支持各功能模块单独调用。其中分词和词性标注等功能是基于&lt;strong&gt;1998年人民日报和微博语料&lt;/strong&gt;进行训练，命名实体标注则是基于1998年人民日报语料进行训练。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;LTP采用C++语言开发&lt;/strong&gt;，提供静态、动态库，可方便集成在C，C++和Java程序中。&lt;/p&gt;

&lt;p&gt;LTP的分词、词性标注以及命名实体识别工具是基于结构化感知器实现的。&lt;/p&gt;

&lt;p&gt;LTP的使用非常简单，只需要&lt;strong&gt;根据 API 参数构造 HTTP 请求即可在线获得分析结果&lt;/strong&gt;，而无需下载 SDK 、无需购买高性能的机器，同时支持跨平台、跨语言编程等。如果你需要使用LTP，则先在LTP上注册一个帐号，相关信息审核通过后，系统会给你发送API_KEY，并告知每个月的流量额度，初始是每月20G的免费流量。&lt;/p&gt;

&lt;p&gt;语言云服务的API参数集如下表所示：&lt;/p&gt;

&lt;table class=&quot;table table-bordered&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;参数名&lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;api_key&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;用户注册语言云服务后获得的认证标识&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;text&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;待分析的文本。&lt;/td&gt;
&lt;td&gt;请以UTF-8格式编码，GET方式最大10K，POST方式最大20K&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;pattern&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;用以指定分析模式，可选值包括&lt;code&gt;ws&lt;/code&gt;(分词)，&lt;code&gt;pos&lt;/code&gt;(词性标注)，&lt;code&gt;ner&lt;/code&gt;(命名实体识别)，&lt;code&gt;dp&lt;/code&gt;(依存句法分析)，&lt;code&gt;sdp&lt;/code&gt;(语义依存(树)分析)，&lt;code&gt;sdb_graph&lt;/code&gt;(语义依存图分析)&lt;code&gt;srl&lt;/code&gt;(语义角色标注),&lt;code&gt;all&lt;/code&gt;(全部任务)&lt;/td&gt;
&lt;td&gt;plain格式中不允许指定全部任务&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;format&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;用以指定结果格式类型，可选值包括&lt;code&gt;xml&lt;/code&gt;(XML格式)，&lt;code&gt;json&lt;/code&gt;(JSON格式)，&lt;code&gt;conll&lt;/code&gt;(CONLL格式)，&lt;code&gt;plain&lt;/code&gt;(简洁文本格式)&lt;/td&gt;
&lt;td&gt;在指定pattern为all条件下，指定format为xml或json，返回结果将包含sdp结果，但conll格式不会包含sdp结果；&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;xml_input&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;用以指定输入text是否是xml格式，可选值为&lt;code&gt;false&lt;/code&gt;(默认值),&lt;code&gt;true&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;仅限POST方式&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;has_key&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;用以指定json结果中是否含有键值，可选值包括&lt;code&gt;true&lt;/code&gt;(含有键值，默认)，&lt;code&gt;false&lt;/code&gt;(不含有键值)&lt;/td&gt;
&lt;td&gt;配合format=json使用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;only_ner&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;用以指定plain格式中是否只需要ner列表，可选值包括&lt;code&gt;false&lt;/code&gt;(默认值)和&lt;code&gt;true&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;配合pattern=ner&amp;amp;format=plain使用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;callback&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;用以指定JavaScript调用中所使用的回调函数名称&lt;/td&gt;
&lt;td&gt;配合format=json使用&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Python调用demo&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# -*- coding:utf8 -*-
if __name__ == '__main__':
    url_get_base = &quot;http://api.ltp-cloud.com/analysis/&quot;
    args = { 
        'api_key' : 'YourApiKey',
        'text' : '我是中国人。',
        'pattern' : 'dp',
        'format' : 'plain'
    }
    result = urllib.urlopen(url_get_base, urllib.urlencode(args)) # POST method
    content = result.read().strip()
    print content
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;官网介绍地址&lt;/strong&gt;：http://www.ltp-cloud.com/intro/&lt;/p&gt;

&lt;h1 id=&quot;3清华大学词法分析器thu-lexical-analyzer-for-chinesethulac&quot;&gt;&lt;strong&gt;3、清华大学词法分析器（THU Lexical Analyzer for Chinese，THULAC）&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;THULAC由&lt;strong&gt;清华大学自然语言处理与社会人文计算实验室&lt;/strong&gt;研制推出的一套中文词法分析工具包，具有&lt;strong&gt;中文分词和词性标注&lt;/strong&gt;功能。THULAC工具包随包附带的分词模型Model_1以及分词和词性标注模型Model_2是由&lt;strong&gt;人民日报语料库&lt;/strong&gt;训练得到的，所以支持单独调用分词接口，但不能单独调用词性标注接口。&lt;strong&gt;语料库包含已标注的字数约为五千八百万字&lt;/strong&gt;，你可以填写申请表来得到全部语料库。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;THULAC完全开源，公布了算法源代码、算法模型甚至语料库&lt;/strong&gt;。在Python中，可通过 import thulac 来引用，同时还提供C++接口使用和按照命令格式运行可执行jar包完成分词和词性标注。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C++版&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./thulac [-t2s] [-seg_only] [-deli delimeter] [-user userword.txt] 从命令行输入输出
./thulac [-t2s] [-seg_only] [-deli delimeter] [-user userword.txt] outputfile 利用重定向从文本文件输入输出（注意均为UTF8文本）
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;java版&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;java -jar THULAC_lite_java_run.jar [-t2s] [-seg_only] [-deli delimeter] [-user userword.txt] 从命令行输入输出
java -jar THULAC_lite_java_run.jar [-t2s] [-seg_only] [-deli delimeter] [-user userword.txt] -input input_file -output output_file 从文本文件输入输出（注意均为UTF8文本）
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;python版（兼容python2.x和python3.x）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;通过python程序&lt;code class=&quot;highlighter-rouge&quot;&gt;import thulac&lt;/code&gt;，新建thulac.thulac(args)类，其中args为程序的参数。之后可以通过调用thulac.cut()进行单句分词。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;官网介绍地址&lt;/strong&gt;：http://thulac.thunlp.org/&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;相关论文地址&lt;/strong&gt;：https://dl.acm.org/citation.cfm?id=1667988.1667992&lt;/p&gt;

&lt;h1 id=&quot;4fudannlp&quot;&gt;&lt;strong&gt;4、FudanNLP&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;FudanNLP是&lt;strong&gt;复旦大学自然语言处理实验室&lt;/strong&gt;开发的中文自然语言处理工具包，包含信息检索： &lt;strong&gt;文本分类、新闻聚类；中文处理： 中文分词、词性标注、实体名识别、关键词抽取、依存句法分析、时间短语识别；结构化学习： 在线学习、层次分类、聚类&lt;/strong&gt;。FNLP也是开源的，其中包含了实现这些功能的机器学习算法和数据集。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;FNLP采用Java语言开发，可通过命令行方式调用，也可公布了jar包以便集成到各个Java项目中。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;命令行方式调用分词功能&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;java -Xmx1024m -Dfile.encoding=UTF-8 -classpath &quot;fnlp-core/target/fnlp-core-2.1-SNAPSHOT.jar:libs/trove4j-3.0.3.jar:libs/commons-cli-1.2.jar&quot; org.fnlp.nlp.cn.tag.CWSTagger -s models/seg.m &quot;自然语言是人类交流和思维的主要工具，是人类智慧的结晶。&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;参数&lt;code class=&quot;highlighter-rouge&quot;&gt;“-Xmx1024m”&lt;/code&gt;设置Java虚拟机的可用内存为1024M。FNLP载入语言模型所需内存较大，因此可以利用此参数修改可用内存量。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;结果：&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;自然 语言 是 人类 交流 和 思维 的 主要 工具 ， 是 人类 智慧 的 结晶 。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;命令行方式调用中文词性标注功能&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;java -Xmx1024m -Dfile.encoding=UTF-8 -classpath &quot;fnlp-core/target/fnlp-core-2.1-SNAPSHOT.jar:libs/trove4j-3.0.3.jar:libs/commons-cli-1.2.jar&quot; org.fnlp.nlp.cn.tag.POSTagger -s models/seg.m models/pos.m &quot;周杰伦出生于台湾，生日为79年1月18日，他曾经的绯闻女友是蔡依林。&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;结果：&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;周杰伦/人名 出生/动词 于/介词 台湾/地名 ，/标点 生日/名词 为/介词 79年/时间短语 1月/时间短语 18日/时间短语 ，/标点
他/人称代词 曾经/副词 的/结构助词 绯闻/名词 女友/名词 是/动词 蔡依林/人名 。/标点&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;命令行方式调用实体名识别功能&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;java -Xmx1024m -Dfile.encoding=UTF-8 -classpath &quot;fnlp-core/target/fnlp-core-2.1-SNAPSHOT.jar:libs/trove4j-3.0.3.jar:libs/commons-cli-1.2.jar&quot; org.fnlp.nlp.cn.tag.NERTagger -s models/seg.m models/pos.m &quot;詹姆斯·默多克和丽贝卡·布鲁克斯 鲁珀特·默多克旗下的美国小报《纽约邮报》的职员被公司律师告知，保存任何也许与电话窃听及贿赂有关的文件。&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;结果：&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;{詹姆斯·默多克=人名, 鲁珀特·默多克旗=人名, 丽贝卡·布鲁克斯=人名, 纽约=地名, 美国=地名}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;FudanNLP gitbub地址（包含wiki）&lt;/strong&gt;：https://github.com/FudanNLP/fnlp&lt;/p&gt;
</description>
        <pubDate>Thu, 26 Apr 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deeplearning/2018/04/26/%E4%BD%A0%E9%9C%80%E8%A6%81%E7%9F%A5%E9%81%93%E7%9A%84%E5%87%A0%E4%B8%AA%E5%A5%BD%E7%94%A8%E7%9A%84%E4%B8%AD%E6%96%87%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7.html</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2018/04/26/%E4%BD%A0%E9%9C%80%E8%A6%81%E7%9F%A5%E9%81%93%E7%9A%84%E5%87%A0%E4%B8%AA%E5%A5%BD%E7%94%A8%E7%9A%84%E4%B8%AD%E6%96%87%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7.html</guid>
        
        <category>中文词法分析工具</category>
        
        
        <category>Deeplearning</category>
        
      </item>
    
      <item>
        <title>HFL-RC：科大讯飞填空式机器阅读理解数据集</title>
        <description>&lt;h1 id=&quot;0-hfl-rc数据集&quot;&gt;&lt;strong&gt;0 HFL-RC数据集&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;语料主要来源于人民日报和儿童童话&lt;/strong&gt;，&lt;a href=&quot;https://arxiv.org/abs/1607.02250&quot;&gt;论文地址&lt;/a&gt;。&lt;a href=&quot;https://github.com/ymcui/Chinese-RC-Dataset&quot;&gt;数据集下载地址&lt;/a&gt;。图1展示了从人民日报提取的样本案例。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;HFL-RC：科大讯飞填空式机器阅读理解数据集_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ae135c900018c2a17320546.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 1 从人民日报提取的样本案例&lt;/p&gt;

&lt;p&gt;从图1中可以看出，文档包含了&lt;code class=&quot;highlighter-rouge&quot;&gt;序号1~10&lt;/code&gt;的句子，每个句子以&lt;code class=&quot;highlighter-rouge&quot;&gt;“|||”&lt;/code&gt;开头，&lt;strong&gt;最后一个句子为问题和答案&lt;/strong&gt;，问题与答案用&lt;code class=&quot;highlighter-rouge&quot;&gt;“|||”&lt;/code&gt;分割，如图1的&lt;code class=&quot;highlighter-rouge&quot;&gt;序号11&lt;/code&gt;的句子，“策略”即为前面句子的答案。&lt;/p&gt;

&lt;p&gt;同时，HTL-RC数据集要求&lt;strong&gt;在文章中随机选择一个词作为答案，这个词必须为名词，且在文中至少出现两次&lt;/strong&gt;；那么显然，包含这个答案的句子就为问题，且&lt;strong&gt;问题的来源是直接摘抄自文档中的一句话&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;为了保证数据的多样性，HTL-RC数据集同时还收集了儿童童话故事作为语料之一，儿童童话故事主要由动物故事或虚拟角色故事组成，这使得我们无法利用训练数据中的性别信息和大量背景知识，这对于解决多种类型的问题是很重要的。同时针对儿童童话故事语料，人工生成测试集，在实验中这比基于人民日报语料机器自动生成测试集要更难一些，因为自动生成的测试集可能更倾向于生成那些单词共现或固定搭配的句子，因此当这种搭配出现在问题的答案（在问题中答案用空格隐去）附近时，机器更容易识别正确答案。而在建立人共制造的测试集时，我们已经消除了这些类型的样本，这使得机器更难理解。直观地说，人工生成的测试集比先前发布的填空式风格的测试集都要难。&lt;/p&gt;

&lt;p&gt;图2 展示了HFL-RC数据集的统计信息&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;HFL-RC：科大讯飞填空式机器阅读理解数据集_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ae135e40001b8f513980506.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 2 HFL-RC数据集的统计信息&lt;/p&gt;

&lt;h1 id=&quot;1-cas-reader模型consensus-attention-sum-reader&quot;&gt;&lt;strong&gt;1 CAS Reader模型（Consensus Attention Sum Reader）&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;CAS Reader模型将文档-问题-答案转化成三元组&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;D, Q, A&amp;gt;&lt;/code&gt;，模型主要受Kadlec的文献2启发，但CAS Reader模型考虑到了每个t时刻的RNN节点的输出，并从中挖掘相关联的信息，而不是仅仅考虑RNN层最后的输出。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;模型主要步骤如下：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;1、将文档&lt;code class=&quot;highlighter-rouge&quot;&gt;D&lt;/code&gt;和问题&lt;code class=&quot;highlighter-rouge&quot;&gt;Q&lt;/code&gt;分别用&lt;code class=&quot;highlighter-rouge&quot;&gt;one-hot向量&lt;/code&gt;表示，并拼接两个向量；&lt;/p&gt;

&lt;p&gt;2、文档&lt;code class=&quot;highlighter-rouge&quot;&gt;D&lt;/code&gt;和问题&lt;code class=&quot;highlighter-rouge&quot;&gt;Q&lt;/code&gt;共享嵌入层权值&lt;code class=&quot;highlighter-rouge&quot;&gt;W_e&lt;/code&gt;。由于问题通常比文档短，通过共享文档和问题的嵌入层权值，可丰富问题的表示。&lt;/p&gt;

&lt;p&gt;3、模型使用了两个双向RNN分别训练文档和问题的向量表示并拼接，训练后得到的向量表示就已经包含了过去和未来的上下文信息，计算公式如下所示。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;HFL-RC：科大讯飞填空式机器阅读理解数据集_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ae135fa00015ce406300354.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:40%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;4、文档向量表示为&lt;code class=&quot;highlighter-rouge&quot;&gt;h_doc&lt;/code&gt;，问题向量表示为&lt;code class=&quot;highlighter-rouge&quot;&gt;h_query&lt;/code&gt;，向量为3维张量。现在&lt;strong&gt;对于问题，模型计算在&lt;code class=&quot;highlighter-rouge&quot;&gt;t&lt;/code&gt;时刻，每个文档单词的重要性，即注意力&lt;/strong&gt;。计算公式如下所示。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;HFL-RC：科大讯飞填空式机器阅读理解数据集_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ae1360d0001486b06640076.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:40%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中&lt;code class=&quot;highlighter-rouge&quot;&gt;h_query(t)&lt;/code&gt;表示t时刻问题的向量表示，计算其与&lt;code class=&quot;highlighter-rouge&quot;&gt;h_doc&lt;/code&gt;的点积，使用&lt;code class=&quot;highlighter-rouge&quot;&gt;softmax函数&lt;/code&gt;得到t时刻问题对文档的注意力分布&lt;code class=&quot;highlighter-rouge&quot;&gt;a(t)&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;a(t)&lt;/code&gt;还可以表示为&lt;code class=&quot;highlighter-rouge&quot;&gt;a(t)=[a(t)_1, a(t)_2, …, a(t)_n]&lt;/code&gt;，其中&lt;code class=&quot;highlighter-rouge&quot;&gt;a(t)_i&lt;/code&gt;表示在&lt;code class=&quot;highlighter-rouge&quot;&gt;t&lt;/code&gt;时刻，文档中第&lt;code class=&quot;highlighter-rouge&quot;&gt;i&lt;/code&gt;个词的注意力值，&lt;code class=&quot;highlighter-rouge&quot;&gt;n&lt;/code&gt;为文档单词个数。&lt;/p&gt;

&lt;p&gt;5、合并问题的注意力分布，得到文档的最后注意力值&lt;code class=&quot;highlighter-rouge&quot;&gt;s&lt;/code&gt;，计算公式如下所示。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;HFL-RC：科大讯飞填空式机器阅读理解数据集_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ae136260001e92c04300070.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:30%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中&lt;code class=&quot;highlighter-rouge&quot;&gt;m&lt;/code&gt;表示问题的单词个数，&lt;code class=&quot;highlighter-rouge&quot;&gt;f&lt;/code&gt;表示合并函数，模型定义了三种合并函数，函数表示如下所示。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;HFL-RC：科大讯飞填空式机器阅读理解数据集_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ae13641000192c309460322.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;6、计算单词&lt;code class=&quot;highlighter-rouge&quot;&gt;w&lt;/code&gt;是答案的条件概率&lt;/p&gt;

&lt;p&gt;文档&lt;code class=&quot;highlighter-rouge&quot;&gt;D&lt;/code&gt;的单词组成单词空间&lt;code class=&quot;highlighter-rouge&quot;&gt;V&lt;/code&gt;，单词&lt;code class=&quot;highlighter-rouge&quot;&gt;w&lt;/code&gt;可能在单词空间&lt;code class=&quot;highlighter-rouge&quot;&gt;V&lt;/code&gt;中出现了多次，其出现的位置&lt;code class=&quot;highlighter-rouge&quot;&gt;i&lt;/code&gt;组成一个集合&lt;code class=&quot;highlighter-rouge&quot;&gt;I(w, D)&lt;/code&gt;，对每个单词&lt;code class=&quot;highlighter-rouge&quot;&gt;w&lt;/code&gt;，我们通过计算它的注意力值并求和得到单词&lt;code class=&quot;highlighter-rouge&quot;&gt;w&lt;/code&gt;是答案的条件概率，计算公式如下所示。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;HFL-RC：科大讯飞填空式机器阅读理解数据集_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ae136520001761706360128.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:40%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;CAS Reader模型结构图如图3所示。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;HFL-RC：科大讯飞填空式机器阅读理解数据集_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ae136620001012a18480924.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 3 CAS Reader模型结构图&lt;/p&gt;
</description>
        <pubDate>Thu, 26 Apr 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deeplearning/2018/04/26/HFL-RC-%E7%A7%91%E5%A4%A7%E8%AE%AF%E9%A3%9E%E5%A1%AB%E7%A9%BA%E5%BC%8F%E6%9C%BA%E5%99%A8%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E6%95%B0%E6%8D%AE%E9%9B%86.html</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2018/04/26/HFL-RC-%E7%A7%91%E5%A4%A7%E8%AE%AF%E9%A3%9E%E5%A1%AB%E7%A9%BA%E5%BC%8F%E6%9C%BA%E5%99%A8%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E6%95%B0%E6%8D%AE%E9%9B%86.html</guid>
        
        <category>机器阅读理解</category>
        
        <category>HFL-RC</category>
        
        <category>填空式数据集</category>
        
        <category>科大讯飞</category>
        
        
        <category>Deeplearning</category>
        
      </item>
    
      <item>
        <title>基于最大熵的中文阅读理解模型</title>
        <description>&lt;h1 id=&quot;0-数据集&quot;&gt;&lt;strong&gt;0 数据集&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;本模型使用了山西大学构建的中文阅读理解语料库&lt;code class=&quot;highlighter-rouge&quot;&gt;CRCC（Chinese Reading Comprehension Corpus）V1.1&lt;/code&gt;。该语料库包含121篇文章，其中80篇来自对外汉语教学，剩余41篇为在网络上爬取的文章，总共约6.5万。文章类型分为14类，其中包含地理、教育、科技、历史、生物等。平均每篇文章包含15个句子，3~6个问句，问句的类型包含Q_HUMAN(人物，25个，占比4%)；Q_LOCATION(地点，51，8%)；Q_ENTITY(实体，78，13%)；Q_TIME(时间，53，9%)；Q_NUMBER(数值，78，13%)；Q_DISCRIBE(描述，332，54%)。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;数据集中的文章已经进行了预处理，包括分词、词性标注、指称指代标注以及框架语义标注&lt;/strong&gt;，预处理具体方法可以参见文献1。&lt;/p&gt;

&lt;p&gt;由于实验数据集规模较小，为了减少实验结果对训练集和测试集较强的依赖性，实验按照1：1的比例划分语料库，并尽可能使得各种类型的问句在训练集和测试集中比例接近1：1，训练集和测试集中各问题类型分布如图1所示。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;基于最大熵的中文阅读理解模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5adff1b9000108a616480568.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 1 训练集和测试集中各问题类型分布&lt;/p&gt;

&lt;h1 id=&quot;1-特征工程&quot;&gt;&lt;strong&gt;1 特征工程&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;基于最大熵来构建中文阅读理解模型主要工作在于构建特征工程，特征抽取是机器学习中至关重要的步骤，&lt;strong&gt;特征抽取的好坏直接影响模型的性能，其主要思想是将无法直接识别的原始数据转化为可识别的特征数据&lt;/strong&gt;。特征抽取是现实机器学习任务中的重要的“数据预处理”（data preprocessing）过程，通常先分析数据并进行特征抽取，然后再训练学习器。&lt;/p&gt;

&lt;p&gt;实验的特征工程主要包含两种类型的特征：&lt;strong&gt;词法特征和浅层句法特征。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;11-词法特征10个&quot;&gt;&lt;strong&gt;1.1 词法特征（10个）&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;DMWM：&lt;/strong&gt;统计问题q与其对应文章中句子s的词匹配个数m，取其中最大的m值记为M，那么每个句子的DMWM值则为（M-m）。其中DMWM为0时表示“问题-句子”的词匹配程度最高，在特殊情况下，比如当所有的m都为0，即问题q与文章所有句子的词匹配个数均为0，则DMWM均为0，在这种情况下我们将DMWM设置为200。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;DMVM：&lt;/strong&gt;统计问题q与其对应文章中句子s的动词匹配个数，计算方法同DMWM。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;DMWM-Prev：&lt;/strong&gt;统计问题q与其对应文章中句子s的前一个句子的词匹配个数，计算方法同DMWM。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;DMWM-Next：&lt;/strong&gt;统计问题q与其对应文章中句子s的后一个句子的词匹配个数，计算方法同DMWM。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;DMVM-Prev：&lt;/strong&gt;统计问题q与其对应文章中句子s的前一个句子的动词匹配个数，计算方法同DMWM。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;DMVM-Next：&lt;/strong&gt;统计问题q与其对应文章中句子s的后一个句子的动词匹配个数，计算方法同DMWM。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PO：&lt;/strong&gt;表示句子s是否包含人（Person）、组织（Organization），有则设置为True，否则为False。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;DT：&lt;/strong&gt;表示句子s是否包含日期（Date）、时间（Time），有则设置为True，否则为False。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;LO：&lt;/strong&gt;表示句子s是否包含地点（Location），有则设置为True，否则为False。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;VA：&lt;/strong&gt;表示句子s是否包含数值（Value），有则设置为True，否则为False。&lt;/p&gt;

&lt;h2 id=&quot;12-浅层句法特征25个&quot;&gt;&lt;strong&gt;1.2 浅层句法特征（25个）&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;基本块类别特征：共8种&lt;/strong&gt;，包含：np（名词块），mp（数量块），sp（指代词块），tp（时间词块），vp（动词块），ap（形容词块），dp（副词块），pp（介词块）。实验分别抽取问句与答案句中的基本块类别进行匹配，如果基本块类别一致，且基本块的中心词一致，则匹配成功，匹配数递增加1，否则匹配失败，匹配数为0。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;基本块关系特征：共13种&lt;/strong&gt;，包含：ZX，LN，LH，PO，SB，AD，JB，AM，CD，RL，SX，XX，SG。实验分别抽取问句与答案句中的基本块关系标记进行匹配，如果基本块关系标记一致，且基本块的中心词一致，则匹配成功，匹配数递增加1，否则匹配失败，匹配数为0。&lt;/p&gt;

&lt;p&gt;接下来我们使用一个样本案例来介绍基本块特征抽取过程。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;基于最大熵的中文阅读理解模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5adff1e1000112aa08220592.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:30%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;提取各基本块的中心词后，得到如下表示：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;基于最大熵的中文阅读理解模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5adff1ef00017bd608080266.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:30%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对于基本块类别特征，匹配的基本块有两个：[人口/n    np-AM] 和 [分布/n    np-SG]，则对于该样本的基本块类别特征向量表示为&lt;code class=&quot;highlighter-rouge&quot;&gt;[2, 0, 0, 0, 0, 0, 0, 0]&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;对于基本块关系特征，匹配的基本块有两个：[人口/n    np-AM] 和 [分布/n    np-SG]，则对于该样本的基本块关系特征向量表示为&lt;code class=&quot;highlighter-rouge&quot;&gt;[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;功能块特征：共4种&lt;/strong&gt;，功能块表示一个中文句子的功能性成分，分析数据集，实验主要考虑了4种功能块：S（主语语块），P（谓语语块），O（宾语语块），D（状语语块），计算方法同基本块特征相似。&lt;/p&gt;

&lt;h1 id=&quot;3-模型&quot;&gt;&lt;strong&gt;3 模型&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;最大熵模型，即在满足约束条件的模型集合中选取熵最大的模型。其本质在于，&lt;strong&gt;已知特征向量X，计算Y的概率，且尽可能让Y的概率最大&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;基于最大熵的中文阅读理解模型的主要任务是：在一篇文章中，找出概率最大的问题q对应的答案句A，也就是说&lt;strong&gt;模型是在句子粒度上回答问题&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;那么，&lt;strong&gt;中文阅读理解任务可以看出是一个二分类问题&lt;/strong&gt;，即给定文章S以及问题Q，对文章S中的n个句子进行二分类，假设“x”表示问题Q及文中的句子Si构成的上下文环境，“y”表示Si是否为答案句，那么基于最大熵模型进行建模可得：&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$ P(y&lt;/td&gt;
      &lt;td&gt;x) = {1 \over Z(x)} e ^ {\sum_{i} \lambda_i f_i(x,y) } $&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;其中，$ Z(x) = \sum_{y}y e ^ {\sum_{i} \lambda_i f_i(x,y) }$为归一化因子，$f_i$为特征函数，$\lambda_i$为其权重。&lt;/p&gt;

&lt;h1 id=&quot;4-实验结果及改进&quot;&gt;&lt;strong&gt;4 实验结果及改进&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;为了探索35个特征中不同组合特征对模型的影响程度，通过逐步增加特征的方式进行了实验。其中特征组合的方式有：&lt;strong&gt;10个特征（词法特征），18个特征（词法特征+基本块类别特征），31个特征（词法特征+基本块类别特征+基本块关系特征），35个特征（词法特征+基本块类别特征+基本块关系特征+功能块特征）&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;图 2 展示了不同特征组合下模型在各个问题集的实验对比结果。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;基于最大熵的中文阅读理解模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5adff2290001dff916420510.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 2 (a) 不同特征组合下模型在各个问题集的HumSent对比结果&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;基于最大熵的中文阅读理解模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5adff2370001e16313160640.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 2 (b) 不同特征组合下模型在各个问题集的实验结果柱状图&lt;/p&gt;

&lt;p&gt;从图2可以看出，逐步加入特征并没有像我们预想的效果逐渐增加，而是&lt;strong&gt;随着特征的增多，HumSent准确率有所下降&lt;/strong&gt;。分析原因有两个：第一是&lt;strong&gt;数据集的预处理准确率不高&lt;/strong&gt;；第二是&lt;strong&gt;数据集规模较小&lt;/strong&gt;，特征的增多，导致特征矩阵越来越稀疏。&lt;/p&gt;

&lt;p&gt;基于以上实验结果以及分析原因，使用&lt;strong&gt;主成分分析方法对特征进行降维&lt;/strong&gt;，避开特征筛选过程，充分利用所有特征的有效信息来训练模型，使用降维后的特征向量构建主成分最大熵模型。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;主成分分析（Principal Component Analysis，PCA）&lt;/strong&gt;， 是一种统计方法。通过正交变换&lt;strong&gt;将一组可能存在相关性的变量转换为一组线性不相关的变量&lt;/strong&gt;，转换后的这组变量叫主成分。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;少变量样本的研究中，我们可以很容易发现变量中的主成分&lt;/strong&gt;，因为变量少，变量之间的相关性弱，独立性强，我们可以很容易通过区分主成分变量来区分样本；多变量大样本虽然会为研究和应用提供了丰富的信息，但也在一定程度上增加了数据采集的工作量，更重要的是在多数情况下，&lt;strong&gt;许多变量之间可能存在相关性，很难区分主成分变量，从而增加了问题分析的复杂性&lt;/strong&gt;，同时对分析带来不便。如果分别对每个指标进行分析，分析往往是孤立的，而不是综合的。盲目减少指标会损失很多信息，容易产生错误的结论。因此需要找到一个合理的方法，在减少需要分析的指标同时，尽量减少原指标包含信息的损失，以达到对所收集数据进行全面分析的目的。由于各变量间存在一定的相关关系，因此有可能&lt;strong&gt;用较少的综合指标分别综合存在于各变量中的各类信息&lt;/strong&gt;。主成分分析与因子分析就属于这类降维的方法。&lt;/p&gt;

&lt;p&gt;图3展示了主成分最大熵模型与非主成分最大熵模型实验对比结果。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;基于最大熵的中文阅读理解模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5adff2480001d66116460510.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 3 (a) 主成分最大熵模型与非主成分最大熵模型的HumSent对比结果&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;基于最大熵的中文阅读理解模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5adff2560001403213100636.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 3 (b) 主成分最大熵模型与非主成分最大熵模型实验柱状图&lt;/p&gt;

&lt;h1 id=&quot;参考文献&quot;&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;张娜, 李济洪. 基于语义标注的中文阅读理解语料库的建设[C]// 全国计算语言学学术会议. 2007.&lt;/li&gt;
  &lt;li&gt;王凯华, 李济洪, 张国华,等. 基于最大熵模型的中文阅读理解问答系统技术研究[C]// 全国计算语言学学术会议. 2007.&lt;/li&gt;
  &lt;li&gt;李济洪, 王瑞波, 王凯华,等. 基于最大熵模型的中文阅读理解问题回答技术研究[J]. 中文信息学报, 2008, 22(6):55-62.&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Wed, 25 Apr 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deeplearning/2018/04/25/%E5%9F%BA%E4%BA%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E7%9A%84%E4%B8%AD%E6%96%87%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E6%A8%A1%E5%9E%8B.html</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2018/04/25/%E5%9F%BA%E4%BA%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E7%9A%84%E4%B8%AD%E6%96%87%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E6%A8%A1%E5%9E%8B.html</guid>
        
        <category>中文阅读理解模型</category>
        
        <category>最大熵</category>
        
        <category>主成分分析</category>
        
        
        <category>Deeplearning</category>
        
      </item>
    
      <item>
        <title>SQuAD：机器阅读理解领域中的ImageNet</title>
        <description>&lt;h2 id=&quot;0-介绍&quot;&gt;&lt;strong&gt;0 介绍&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;上篇博文我们通过介绍机器阅读理解的奠基之作《Teaching Machines to Read and Comprehend》对CNN&amp;amp;DailyMail语料库进行了分析，但&lt;strong&gt;由于CNN&amp;amp;DailyMail的answer只能是实体对象，且只能出现在原文中，而使得基于该语料库训练的模型缺乏推理能力&lt;/strong&gt;，于是斯坦福大学的Rajpurkar等人于2016年在自然语言处理的顶级会议EMNLP上发布了SQuAD语料库。&lt;a href=&quot;https://arxiv.org/abs/1606.05250&quot;&gt;论文下载&lt;/a&gt;。&lt;a href=&quot;https://rajpurkar.github.io/SQuAD-explorer/&quot;&gt;数据集下载&lt;/a&gt;。SQuAD通过众包的方式，&lt;strong&gt;从wikipedia上的536篇文章提取超过10w个问题-答案对，且其中的答案是原文的一个片段而不是单一的实体对象&lt;/strong&gt;。图1展示了SQuAD语料库中的一个原文-问题-答案样本。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;SQuAD：机器阅读理解领域中的&amp;quot;ImageNet&amp;quot;_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5adc667600010bbc08260836.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 1 SQuAD语料库中的一个原文-问题-答案样本&lt;/p&gt;

&lt;h2 id=&quot;1-语料库对比&quot;&gt;&lt;strong&gt;1 语料库对比&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;机器阅读理解是一个数据驱动的研究领域&lt;/strong&gt;，近几年不同的机构都发布了大大小小的机器阅读理解语料库，图2展示了机器阅读理解领域知名语料库对比。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;SQuAD：机器阅读理解领域中的&amp;quot;ImageNet&amp;quot;_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5adc66910001c26608220758.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 2 机器阅读理解领域知名语料库对比&lt;/p&gt;

&lt;p&gt;其中，MCTest：660篇文章，每篇文章包含4个问题，每个问题有四个选项；WikiQA是定位答案在原文所在句子的位置，而SQuAD定位的是答案在原文哪个句子中哪些范围的单词；CNN&amp;amp;DailyMail是完形填空式风格的语料库，其答案一定是实体对象，而SQuAD的答案不一定是实体对象。&lt;/p&gt;

&lt;h2 id=&quot;2-squad分析&quot;&gt;&lt;strong&gt;2 SQuAD分析&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;2.1 多样的答案类型&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;图3展示了SQuAD语料库中答案的多种类型。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;SQuAD：机器阅读理解领域中的&amp;quot;ImageNet&amp;quot;_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5adc66ab00013e6a08180492.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 3 SQuAD语料库中答案的多种类型&lt;/p&gt;

&lt;p&gt;从图3中可看出，19.8%的答案为日期和其他数字类；有32.6%的答案为三种不同类型的专有名词：人名、地名以及其它实体对象；31.8%为名词短语；其余15.8%由形容词短语、动词短语、从句和其他类型组成。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.2 SQuAD语料库的推理能力&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Rajpurkar通过构造问题与答案所在原文的句子之间的多种差异类型来增加SQuAD语料库在问题求解时的推理能力。&lt;/strong&gt;图4展示了SQuAD语料库中问题与答案所在原文的句子之间的差异类型。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;SQuAD：机器阅读理解领域中的&amp;quot;ImageNet&amp;quot;_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5adc66c20001695e16961042.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 4 SQuAD语料库中问题与答案所在原文的句子之间的差异类型&lt;/p&gt;

&lt;p&gt;由图4可看出，&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Lexical variation-词汇差异：
 同义词推理，如called-referred
 背景知识积累/推理，如governing bodies-The European Parliament and the Council of the European Union&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Syntactic variation-句法差异：
即使将问题转化为陈述句后，其与答案所在原文句子的句法结构具有差异&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Multiple sentences reasoning-答案需要在原文多个句子中进行推理才能得到&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ambiguous-众包问题无法有唯一的答案，或众包得到的答案并不对&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2.3 问题和答案所在句子的句法差异性&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;图5 展示了问题和答案所在句子的句法差异性计算过程&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;SQuAD：机器阅读理解领域中的&amp;quot;ImageNet&amp;quot;_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5adc670f0001dbd908160364.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 5 问题和答案所在句子的句法差异性计算过程&lt;/p&gt;

&lt;p&gt;首先&lt;strong&gt;找出两个句子（问题和答案所在原文句子）的相似词&lt;/strong&gt;，比如first，然后再question中找到wh开头的词（即what、why、which等等），而答案所在原文句子则以句子的第一个词作为开头，&lt;strong&gt;计算两个句子的编辑距离&lt;/strong&gt;；对于两个句子有多个相似词，则&lt;strong&gt;选最小编辑距离作为句法差异度的度量值&lt;/strong&gt;。两个句子的句法差异度的度量范围在0~8之间，如图6所示，编辑距离小不代表问题很容易回答，因为问题在原文中可能有多个同样编辑距离小的句子。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;SQuAD：机器阅读理解领域中的&amp;quot;ImageNet&amp;quot;_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5adc67290001db2207900308.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:60%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图6 (a) 编辑距离为0的两个句子&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;SQuAD：机器阅读理解领域中的&amp;quot;ImageNet&amp;quot;_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5adc673a0001094d16440252.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:85%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图6 (b) 编辑距离为6的两个句子&lt;/p&gt;

&lt;p&gt;图7 展示了SQuAD语料库在句法差异的分布情况。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;SQuAD：机器阅读理解领域中的&amp;quot;ImageNet&amp;quot;_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5adc674d0001d3f307660416.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 7 SQuAD语料库在句法差异的分布情况&lt;/p&gt;

&lt;h2 id=&quot;3-模型及实验结果&quot;&gt;&lt;strong&gt;3 模型及实验结果&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Rajpurkar使用逻辑回归算法构建机器阅读理解模型，分析开发集发现，有77.3%的答案来源于原文，那么在训练过程中，规定答案一定是来源于原文，如果答案不出现在原文，则将原文中能表达答案同等意思的最小部分作为答案。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.1 特征工程&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;模型的特征工程总共包含了&lt;strong&gt;1.8亿个特征&lt;/strong&gt;，其中大部分是词汇化特征或依赖树路径特征，图8 展示了特征工程中特征详细信息。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;SQuAD：机器阅读理解领域中的&amp;quot;ImageNet&amp;quot;_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5adc676c00013e7917001174.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图8 特征工程中特征详细信息&lt;/p&gt;

&lt;p&gt;由图8可以看出，&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;匹配词(matching word)、双字词的词频(bigram frequencies)和词根匹配(root match)特征&lt;/strong&gt;帮助模型定位候选答案所在句子；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;长度特征(Length features)&lt;/strong&gt;帮助模型选择具有共同长度和位置的答案跨度；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;跨度中的词频(span word frequencies)&lt;/strong&gt;特征帮助模型剔除偏僻词；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;成分类型特征(Constituent label)和跨度中单词的词性标注特征(span POS tag features)&lt;/strong&gt;帮助模型确定正确答案类型；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;词法特征(lexicalized features)和依赖树路径特征(dependency tree path features)&lt;/strong&gt;来定量问题与候选答案句子之间的词法和句法多样性。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;3.2 参数设置&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;损失函数：交叉熵损失&lt;/li&gt;
  &lt;li&gt;优化方法：AdaGrad&lt;/li&gt;
  &lt;li&gt;初始化学习率：0.1&lt;/li&gt;
  &lt;li&gt;正则化：L2(0.1/batch size)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;3.3 基线方法&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;sliding-window&lt;/strong&gt;
对于每一个候选答案所在的句子，剔除候选答案本身后，计算其与问题之间单个单词和两个单词的重叠个数，重叠个数最大的句子即为正确答案。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;基于距离(distance-based )的计算&lt;/strong&gt;
计算问题与候选答案所在句子之间的距离，距离越小的句子即为正确答案。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;3.4 评价方法&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;完全匹配（Exact Match），即预测的答案与正确答案完全相符&lt;/li&gt;
  &lt;li&gt;F1值&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;3.5 实验结果&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;图9 展示了不同模型实验结果，我们可以看到&lt;strong&gt;逻辑回归模型远优于基线方法&lt;/strong&gt;，但离人类的表现还差很远，说明基于SQuAD语料库的机器阅读理解研究还有很大空间。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;SQuAD：机器阅读理解领域中的&amp;quot;ImageNet&amp;quot;_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5adc683a0001518508100366.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图9 不同模型实验结果对比&lt;/p&gt;

&lt;p&gt;图 10 展示了逻辑回归模型在剔除某种特征后模型的实验结果。我们可以看出&lt;strong&gt;词法特征(lexicalized features)和依赖树路径特征(dependency tree path features)对模型影响最大&lt;/strong&gt;，而剔除其它特征几乎不会对逻辑回归模型造成很大的影响。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;SQuAD：机器阅读理解领域中的&amp;quot;ImageNet&amp;quot;_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5adc68520001a1f505820592.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 10 逻辑回归模型在剔除某种特征后的实验结果&lt;/p&gt;

&lt;p&gt;图 11 展示了模型在不同答案类型的表现情况。我们可以看到&lt;strong&gt;模型对数字类和实体类表现良好，而人对所有类型答案的表现都差不多&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;SQuAD：机器阅读理解领域中的&amp;quot;ImageNet&amp;quot;_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5adc685f0001b9d207640536.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图11 模型在不同答案类型的表现情况&lt;/p&gt;

&lt;p&gt;图 12 展示了在不同问题与答案所在句子之间的句法差异对模型的影响。我们可以看出&lt;strong&gt;随着句法差异越来越大，模型性能逐渐降低，但人类的表现却很稳定。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;SQuAD：机器阅读理解领域中的&amp;quot;ImageNet&amp;quot;_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5adc68a60001509908240520.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 12 不同问题与答案所在句子之间的句法差异对模型的影响&lt;/p&gt;
</description>
        <pubDate>Sun, 22 Apr 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deeplearning/2018/04/22/SQuAD-%E6%9C%BA%E5%99%A8%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E9%A2%86%E5%9F%9F%E4%B8%AD%E7%9A%84ImageNet.html</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2018/04/22/SQuAD-%E6%9C%BA%E5%99%A8%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E9%A2%86%E5%9F%9F%E4%B8%AD%E7%9A%84ImageNet.html</guid>
        
        <category>机器阅读理解数据集</category>
        
        <category>SQuAD</category>
        
        <category>ImageNet</category>
        
        
        <category>Deeplearning</category>
        
      </item>
    
      <item>
        <title>CNN&amp;Dailymail：Teaching Machines to Read and Comprehend</title>
        <description>&lt;h2 id=&quot;0-cnndailymail语料库&quot;&gt;&lt;strong&gt;0 CNN&amp;amp;Dailymail语料库&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;0.0 背景&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;教会机器能够阅读并理解人类文章是人工智能的一个前沿方向，也是机器更好地为人类服务必须具备的一个能力。传统机器阅读理解方法大多为无监督学习，即&lt;strong&gt;采用模板或句法分析器从上下文文档中提取实体关系元组（谓语及主、宾语），并人工设计规则匹配文档信息，保存以供查询&lt;/strong&gt;。这种简单且严重依赖人工经验的方式并不能取得很好的机器阅读理解效果，但有监督学习方法需要大量带标签的阅读理解数据，语料库的极度缺乏也是影响机器阅读理解方法发展的重要原因之一。&lt;/p&gt;

&lt;p&gt;虽然带标签的阅读理解数据获取困难，但有一些学者开始构造&lt;strong&gt;人造叙述性文章以及问题数据集&lt;/strong&gt;，大量的人造数据并以此为语料库构建机器阅读理解的神经网络模型取得了较好的效果，但实践证明，基于人造数据训练得到的网络模型不一定适用于真实应用场景中，因为模拟数据永远&lt;strong&gt;无法捕捉到自然语言的复杂性、丰富性和噪点&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;0.1 CNN&amp;amp;Dailymail&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;于是，Hermann等人于2015年在&lt;a href=&quot;https://arxiv.org/abs/1506.03340&quot;&gt;《Teaching Machines to Read and Comprehend》&lt;/a&gt;一文中发布CNN&amp;amp;Dailymail数据集。&lt;a href=&quot;https://github.com/deepmind/rc-data&quot;&gt;数据集下载&lt;/a&gt;。Hermann从美国有线新闻网（CNN）和每日邮报网中收集了大约一百万条新闻数据作为机器阅读理解语料库，并通过实体检测等方法&lt;strong&gt;将总结和解释性的句子转化为[背景, 问题, 答案]三元组&lt;/strong&gt;。图1展示的是CNN&amp;amp;Dailymail语料库的统计信息。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;CNN&amp;amp;Dailymail：TeachingMachinestoReadandComprehend_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ad96e4b00018cf008900430.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图1 CNN&amp;amp;Dailymail语料库的统计信息&lt;/p&gt;

&lt;p&gt;CNN&amp;amp;Dailymail语料库由2007年4月-2015年4月的CNN新闻文章和2010年6月-2015年4月的每日邮报网新闻文章组成，语料库剔除了单篇超过2000个字的文章和问题答案不在原文出现的文章。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;0.2 命名实体替换&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Hermann将机器阅读理解任务看作是一个&lt;strong&gt;有监督学习问题&lt;/strong&gt;，并尝试求出语料库中每个样本的答案（answer）的条件概率&lt;code class=&quot;highlighter-rouge&quot;&gt;p(a|c,q)&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;c&lt;/code&gt;表示上下文文档，&lt;code class=&quot;highlighter-rouge&quot;&gt;q&lt;/code&gt;表示问题，&lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt;则表示该问题的答案。&lt;strong&gt;Hermann尝试剔除词组共现统计对机器阅读理解的影响，让网络模型更关注从上下文挖掘实体的语义关系&lt;/strong&gt;，故而Hermann将语料库中文章样本的命名实体都进行了替换，且在训练与测试过程中，命名实体替换后都会进行随机排序，防止在训练过程中网络模型过渡关注替换后的命名实体，而忽略去理解问题以及上下文信息，提高模型泛化能力。图2展示了原始版本与命名实体替换后的匿名版本。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;CNN&amp;amp;Dailymail：TeachingMachinestoReadandComprehend_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ad96e7200010b5015340678.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图2 原始版本与命名实体替换后的匿名版本对比&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;为什么要进行命名实体替换？&lt;/strong&gt;
很显然，人在原始版本和匿名版本的文章中都很容易能回答问题，但对于匿名版本的问题，人必须要去阅读原文才能回答问题，而对于原始版本，如果人在不阅读原文仅通过阅读分析问题的情况下也是有可能回答问题的，因为人可能根据实体信息猜出答案，如果是这样则丢失了机器阅读理解的本质。&lt;/p&gt;

&lt;p&gt;从这里也能够看出&lt;strong&gt;CNN&amp;amp;Dailymail语料库的一些特点&lt;/strong&gt;：答案是某种实体对象；答案一定出现在原文中，所以对于需要让机器理解并回答推理性的问题，CNN&amp;amp;Dailymail语料库力不从心。&lt;/p&gt;

&lt;h2 id=&quot;1-模型&quot;&gt;&lt;strong&gt;1 模型&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;1.0 符号匹配模型&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;（1）&lt;strong&gt;框架语义分析模型(Frame-semantic)&lt;/strong&gt;，模型通过识别句子谓语以及它们的主语和宾语，匹配类似&lt;strong&gt;“谁对谁做了什么事情”&lt;/strong&gt;的框架来获取信息。&lt;/p&gt;

&lt;p&gt;分别从问题&lt;code class=&quot;highlighter-rouge&quot;&gt;q&lt;/code&gt;和上下文文档&lt;code class=&quot;highlighter-rouge&quot;&gt;d&lt;/code&gt;中提取实体与谓词的三元组，三元组表示为&lt;code class=&quot;highlighter-rouge&quot;&gt;(e1，V，e2)&lt;/code&gt;，并使用事先定义好的多个规则来匹配问题的答案，如果在一个规则下出现多个答案，则随机选择一个。图3展示了规则定义以及举例分析。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;CNN&amp;amp;Dailymail：TeachingMachinestoReadandComprehend_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ad96ea00001144914640334.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图3 框架语义分析模型的规则定义以及举例分析&lt;/p&gt;

&lt;p&gt;（2）&lt;strong&gt;单词距离基准法(Word distance)&lt;/strong&gt;，将完形填空式问题中的答案占位符与上下文文档中的每个可能的实体对比，并计算问题与指定实体上下文之间的距离，选取距离最小的实体对象作为问题答案。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.1 神经网络模型&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.1.1 Deep LSTM Reader&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;先将原文文档document一次一个单词token输入到一个两层LSTM中，然后将问题query一次一个单词输入到两层LSTM，即模型的输入不仅包含原文文档，还包含问题，原文与问题用分隔符（&lt;code class=&quot;highlighter-rouge&quot;&gt;|||&lt;/code&gt;）划分开，也可以反过来。即使用两个LSTM来编码encode &lt;code class=&quot;highlighter-rouge&quot;&gt;document ||| query&lt;/code&gt; 或 &lt;code class=&quot;highlighter-rouge&quot;&gt;query ||| document&lt;/code&gt;，图4展示了双层LSTM对&lt;code class=&quot;highlighter-rouge&quot;&gt;query ||| document&lt;/code&gt;的编码过程，通过先后将query和document输入双层LSTM中，拼接后通过一个&lt;code class=&quot;highlighter-rouge&quot;&gt;g(q,d)&lt;/code&gt;函数得到&lt;code class=&quot;highlighter-rouge&quot;&gt;query ||| document&lt;/code&gt;的向量表示，然后用得到的表示做分类模型的输入。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;CNN&amp;amp;Dailymail：TeachingMachinestoReadandComprehend_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ad96ebd00013d8f06340284.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图4 双层LSTM对query ||| document的编码过程&lt;/p&gt;

&lt;p&gt;通过一个&lt;code class=&quot;highlighter-rouge&quot;&gt;g(q,d)&lt;/code&gt;函数得到&lt;code class=&quot;highlighter-rouge&quot;&gt;query ||| document&lt;/code&gt;的向量表示作为输入&lt;code class=&quot;highlighter-rouge&quot;&gt;X(t)&lt;/code&gt;，然后输入至一个双层LSTM得到答案，计算演变过程如图5所示。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;CNN&amp;amp;Dailymail：TeachingMachinestoReadandComprehend_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ad96ed100017e4313260404.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图 5 双层LSTM计算演变过程&lt;/p&gt;

&lt;p&gt;其中，&lt;code class=&quot;highlighter-rouge&quot;&gt;||&lt;/code&gt;表示拼接两个向量，&lt;code class=&quot;highlighter-rouge&quot;&gt;h(t, k)&lt;/code&gt;表示&lt;code class=&quot;highlighter-rouge&quot;&gt;t&lt;/code&gt;时刻在&lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt;层隐藏层的状态，&lt;code class=&quot;highlighter-rouge&quot;&gt;i, f, o&lt;/code&gt;分别表示输入门、遗忘门以及输出门的状态。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.1.2 Attentive Reader&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Deep LSTM Reader试图挖掘长距离依赖信息，但这一目的却受限于固定宽度的隐藏层。受机器翻译与图像识别的启发，Attentive Reader采用注意力机制来构建token级别的网络模型。图6 展示了Attentive Reader中query和document的编码过程。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;CNN&amp;amp;Dailymail：TeachingMachinestoReadandComprehend_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ad96ee700017e9707140408.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图6 Attentive Reader中query和document的编码过程&lt;/p&gt;

&lt;p&gt;首先使用双向LSTM层分别对文档和问题进行编码，对于长度为&lt;code class=&quot;highlighter-rouge&quot;&gt;|q|&lt;/code&gt;的query编码，拼接正反向上LSTM的输出作为query的向量表示，使用&lt;code class=&quot;highlighter-rouge&quot;&gt;u&lt;/code&gt;表示；document中&lt;code class=&quot;highlighter-rouge&quot;&gt;t&lt;/code&gt;位置的token输出表示为正反向上LSTM的输出的拼接，使用&lt;code class=&quot;highlighter-rouge&quot;&gt;y(t)&lt;/code&gt;表示，document的表示则是用document中所有token的加权平均来表示；权重矩阵&lt;code class=&quot;highlighter-rouge&quot;&gt;W&lt;/code&gt;为网络在回答问题时对文档中特定位置的token的重视程度，即注意力；变量&lt;code class=&quot;highlighter-rouge&quot;&gt;s(t)&lt;/code&gt;是token的规范化注意力表示；&lt;code class=&quot;highlighter-rouge&quot;&gt;r&lt;/code&gt;为文档表示；然后使用query和document的表示作为分类模型的输入。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.1.3 Impatient Reader&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;不难看出，&lt;strong&gt;Attentive Reader将query作为一个整体来分析document中不同token的注意力&lt;/strong&gt;，但query中不同token本身的重要性也是不一样的，&lt;strong&gt;Impatient Reader进一步分析query中每个token，尝试找到query中的token与document中哪几个token关联最大&lt;/strong&gt;，并且对于query中每个token都需要考虑到上一个token在document中积累的信息。图7展示了Impatient Reader中query和document的编码过程。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;CNN&amp;amp;Dailymail：TeachingMachinestoReadandComprehend_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ad96ef60001d06d07120434.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图7 Impatient Reader中query和document的编码过程&lt;/p&gt;

&lt;p&gt;Impatient Reader模型较Attentive Reader更为复杂，但在某些情况下，Impatient Reader效果可能并不是很好，因为在每读取query中的一个token就要通读原文一次，且还需要考虑上一个token在原文中相关的token，这样效率可能不高，且可能存在梯度弥散的问题。&lt;/p&gt;

&lt;h2 id=&quot;2-实验&quot;&gt;&lt;strong&gt;2 实验&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;2.0 基线方法&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;（1）&lt;strong&gt;多数基线(Maximum frequency)&lt;/strong&gt;选择上下文文档中最常见的实体
（2）&lt;strong&gt;排除式多数(Exclusive frequency)&lt;/strong&gt;选择在上下文中最常见但在问题中没有出现的实体，即排除在问题中出现的实体。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.1 模型超参数设置&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;所有深度学习模型均使用RmsProp优化方法，decay为0.95。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;（1）Deep LSTM Reader&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;隐藏层大小：[64, 128, 256]&lt;/li&gt;
  &lt;li&gt;LSTM层数：[1, 2, 4]&lt;/li&gt;
  &lt;li&gt;学习率初始化：[1E-3, 5E-4, 1E-4, 5E-5]&lt;/li&gt;
  &lt;li&gt;batch size：[16, 32]&lt;/li&gt;
  &lt;li&gt;dropout：[0.0, 0.1, 0.2]&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;（2）Attentive Reader &amp;amp; Impatient Reader&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;隐藏层大小：[64, 128, 256]&lt;/li&gt;
  &lt;li&gt;LSTM层数：1&lt;/li&gt;
  &lt;li&gt;学习率初始化：[1E-4, 5E-5, 2.5E-5, 1E-5]&lt;/li&gt;
  &lt;li&gt;batch size：[8, 16, 32]&lt;/li&gt;
  &lt;li&gt;dropout：[0.0, 0.1, 0.2, 0.5]&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2.2 实验结果&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;图8展示的是基线方法以及深度学习模型的实验结果对比。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;CNN&amp;amp;Dailymail：TeachingMachinestoReadandComprehend_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ad96f0f0001498207500484.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图8 基线方法以及深度学习模型的实验结果对比&lt;/p&gt;

&lt;p&gt;由图8可知，不管在CNN还是Daily Mail中，&lt;strong&gt;深度学习模型普遍比基线方法和传统模型要好&lt;/strong&gt;，这也展现了深度学习在机器阅读理解的适用性；Uniform Reader没有使用注意力机制，其性能表现说明注意力机制在机器阅读理解中有效性，图9展示了其与Impatient Reader、Attentive Reader模型的P-R图；在CNN中Impatient Reader模型较Attentive Reader表现更好，但相差不大，而在Daily Mail中Attentive Reader模型较Impatient Reader表现更好。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;CNN&amp;amp;Dailymail：TeachingMachinestoReadandComprehend_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ad96f1d00018bf306940578.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图9 三种深度学习模型的P-R图（其中Uniform没有使用注意力机制）&lt;/p&gt;
</description>
        <pubDate>Sun, 15 Apr 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deeplearning/2018/04/15/CNN&Dailymail-Teaching-Machines-to-Read-and-Comprehend.html</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2018/04/15/CNN&Dailymail-Teaching-Machines-to-Read-and-Comprehend.html</guid>
        
        <category>机器阅读理解数据集</category>
        
        <category>CNN&amp;Dailymail</category>
        
        
        <category>Deeplearning</category>
        
      </item>
    
      <item>
        <title>机器阅读理解Match-LSTM模型</title>
        <description>&lt;h2 id=&quot;0-基于squad数据集的通用模型架构&quot;&gt;&lt;strong&gt;0 基于SQuAD数据集的通用模型架构&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;由于 SQuAD 的答案限定于来自原文，模型只需要判断原文中哪些词是答案即可，因此是&lt;strong&gt;一种抽取式的 QA 任务而不是生成式任务&lt;/strong&gt;。几乎所有做 SQuAD 的模型都可以概括为同一种框架：&lt;strong&gt;Embed 层，Encode 层，Interaction 层和 Answer 层&lt;/strong&gt;。Embed 层负责将原文和问题中的 tokens 映射为向量表示；Encode 层主要使用 RNN 来对原文和问题进行编码，这样编码后每个 token 的向量表示就蕴含了上下文的语义信息；Interaction 层是大多数研究工作聚焦的重点，该层主要负责捕捉问题和原文之间的交互关系，并输出编码了问题语义信息的原文表示，即 query-aware 的原文表示；最后 Answer 层则基于 query-aware 的原文表示来预测答案范围。图1展示了一个高层的神经 QA 系统基本框架。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;机器阅读理解Match-LSTM模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac3707a0001da6806000337.jpg&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图1 一个高层的神经 QA 系统基本框架&lt;/p&gt;

&lt;h2 id=&quot;1-match-lstm模型架构&quot;&gt;&lt;strong&gt;1 Match-LSTM模型架构&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;图2展示了Match-LSTM模型架构图。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;机器阅读理解Match-LSTM模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac370b700015cfa16040904.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图2 Match-LSTM模型架构图&lt;/p&gt;

&lt;p&gt;在模型实现上，Match-LSTM 的主要步骤如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Embed 层使用&lt;strong&gt;词向量表示原文和问题&lt;/strong&gt;；&lt;/li&gt;
  &lt;li&gt;Encode 层使用单向 LSTM 编码原文和问题 embedding；&lt;/li&gt;
  &lt;li&gt;Interaction层对原文中每个词，&lt;strong&gt;计算其关于问题的注意力分布&lt;/strong&gt;，并使用该注意力分布汇总问题表示，将原文该词表示和对应问题表示输入另一个 LSTM编码，得到&lt;strong&gt;该词的 query-aware 表示&lt;/strong&gt;；&lt;/li&gt;
  &lt;li&gt;在反方向重复步骤 2，获得双向 query-aware 表示；&lt;/li&gt;
  &lt;li&gt;Answer 层基于双向 query-aware 表示&lt;strong&gt;使用 Sequence Model 或 Boundary Model预测答案范围&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Match-LSTM模型的输入由两部分组成：段落（passage）和问题（question）。passage使用一个矩阵&lt;code class=&quot;highlighter-rouge&quot;&gt;P[d * P]&lt;/code&gt;表示，其中&lt;code class=&quot;highlighter-rouge&quot;&gt;d&lt;/code&gt;表示词向量维度大小，&lt;code class=&quot;highlighter-rouge&quot;&gt;P&lt;/code&gt;表示passage中tokens的个数；question使用矩阵&lt;code class=&quot;highlighter-rouge&quot;&gt;Q[d * Q]&lt;/code&gt;表示，其中&lt;code class=&quot;highlighter-rouge&quot;&gt;Q&lt;/code&gt;表示question中tokens的个数。&lt;/p&gt;

&lt;p&gt;Match-LSTM模型的输出即问题的答案有两种表示方法，其一是使用一系列整数数组&lt;code class=&quot;highlighter-rouge&quot;&gt;a = (a1, a2,…)&lt;/code&gt;，其中&lt;code class=&quot;highlighter-rouge&quot;&gt;ai&lt;/code&gt;是&lt;code class=&quot;highlighter-rouge&quot;&gt;[1, P]&lt;/code&gt;中的一个整数，表示在段落中某个token具体的位置，这里的整数数组不一定是连续的，对应Sequence Model ；第二种表示方法是假设答案是段落中一段连续的token组合，即仅使用两个整数来表示答案&lt;code class=&quot;highlighter-rouge&quot;&gt;a = (as, ae)&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;as&lt;/code&gt;表示答案在段落中开始的位置，&lt;code class=&quot;highlighter-rouge&quot;&gt;ae&lt;/code&gt;则表示结束位置，&lt;code class=&quot;highlighter-rouge&quot;&gt;as&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;ae&lt;/code&gt;是&lt;code class=&quot;highlighter-rouge&quot;&gt;[1, P]&lt;/code&gt;中的整数，对应Boundary Model 。&lt;/p&gt;

&lt;p&gt;故对Match-LSTM模型的训练集样本来说，其可用下面的&lt;strong&gt;三维数组&lt;/strong&gt;来表示：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;机器阅读理解Match-LSTM模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac3726700010b6b03200052.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:30%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从图2可知，一个基本的Match-LSTM模型应该包含以下三层结构：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;LSTM preprocessing Layer&lt;/strong&gt;：这层对passage和question进行预处理，得到其向量表示；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Match-LSTM Layer&lt;/strong&gt;：这层试图在passage中匹配question；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Answer Pointer(Ans-Ptr) Layer&lt;/strong&gt;：使用Ptr-Net从passage中选取tokens作为question的answer， Sequence Model 和 Boundary Model的主要区别就在这一层。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;LSTM preprocessing Layer&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;LSTM preprocessing Layer的目的是将token的上下文信息包含到passage和question中的每个token的向量表示中。分别将passage和question输入LSTM preprocessing Layer，经过LSTM preprocessing Layer后，passage和question表示如下矩阵：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;机器阅读理解Match-LSTM模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac372c600016a5706180078.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:60%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Hp&lt;/code&gt;是passage的向量矩阵表示，其大小为&lt;code class=&quot;highlighter-rouge&quot;&gt;[l * P]&lt;/code&gt;，l表示隐藏层的节点个数；&lt;code class=&quot;highlighter-rouge&quot;&gt;Hq&lt;/code&gt;是question的向量矩阵表示，其大小为&lt;code class=&quot;highlighter-rouge&quot;&gt;[l * Q]&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Match-LSTM Layer&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;将LSTM preprocessing Layer的输出作为这一层的输入，计算公式如下：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;机器阅读理解Match-LSTM模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac372de0001273c09740152.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中，&lt;img title=&quot;机器阅读理解Match-LSTM模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac373010001608707580052.png&quot; alt=&quot;图片描述&quot; style=&quot;width:60%&quot; /&gt;，这些参数都是模型需要训练的参数，&lt;img title=&quot;机器阅读理解Match-LSTM模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac3733300010dc602000066.png&quot; alt=&quot;图片描述&quot; style=&quot;width:15%&quot; /&gt;是中间结果，&lt;img title=&quot;机器阅读理解Match-LSTM模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac3734e0001d8fe02420066.png&quot; alt=&quot;图片描述&quot; style=&quot;width:15%&quot; /&gt;表示第&lt;code class=&quot;highlighter-rouge&quot;&gt;i-1&lt;/code&gt;个token的隐藏层输出，&lt;img title=&quot;机器阅读理解Match-LSTM模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac373640001718c00900052.png&quot; alt=&quot;图片描述&quot; style=&quot;width:7%&quot; /&gt;表示在列方向拓展Q列。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;对于&lt;code class=&quot;highlighter-rouge&quot;&gt;Gi&lt;/code&gt;公式的维度变化：&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;table&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td&gt;[l * Q] = [l * l] * [l * Q] + ([l * l] * [l * 1] + [l * l] * [l * 1] + [l * 1]) *&lt;/td&gt;
        &lt;td&gt;Q&lt;/td&gt;
        &lt;td&gt;；&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;对于&lt;code class=&quot;highlighter-rouge&quot;&gt;ai&lt;/code&gt;公式的维度变化：&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;table&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td&gt;[1 * Q] = ([1 * l] * [l * Q] + 1 *&lt;/td&gt;
        &lt;td&gt;Q&lt;/td&gt;
        &lt;td&gt;)。&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ai&lt;/code&gt;表示在passage的第&lt;code class=&quot;highlighter-rouge&quot;&gt;i&lt;/code&gt;个token对question的注意力权重向量。&lt;/p&gt;

&lt;p&gt;将注意力权重向量与question向量的乘积和passage中第&lt;code class=&quot;highlighter-rouge&quot;&gt;i&lt;/code&gt;个token的隐藏层输出向量拼接成一维向量&lt;code class=&quot;highlighter-rouge&quot;&gt;Zi&lt;/code&gt;，公式如下：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;机器阅读理解Match-LSTM模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac3738c000116a502740144.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:25%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中，向量维度分别为：&lt;img title=&quot;机器阅读理解Match-LSTM模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac373a30001165007100058.png&quot; alt=&quot;图片描述&quot; style=&quot;width:50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;将向量Zi作为一个LSTM层的输入，得到&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;机器阅读理解Match-LSTM模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac373b60001352304780084.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中，隐藏层向量维度为：&lt;img title=&quot;机器阅读理解Match-LSTM模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac373ce000105a201900074.png&quot; alt=&quot;图片描述&quot; style=&quot;width:15%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;将&lt;code class=&quot;highlighter-rouge&quot;&gt;P&lt;/code&gt;个该隐藏层向量拼接成&lt;img title=&quot;机器阅读理解Match-LSTM模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac373e10001516e02300058.png&quot; alt=&quot;图片描述&quot; style=&quot;width:15%&quot; /&gt;，为了提取上下文信息，反方向构建&lt;img title=&quot;机器阅读理解Match-LSTM模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac373fa0001712a02420078.png&quot; alt=&quot;图片描述&quot; style=&quot;width:15%&quot; /&gt;，将两者拼接得到Match-LSTM Layer的输出：&lt;img title=&quot;机器阅读理解Match-LSTM模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac37412000137bd02980154.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:20%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Answer Pointer Layer&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;将Match-LSTM Layer的输出&lt;code class=&quot;highlighter-rouge&quot;&gt;Hr&lt;/code&gt;作为这一层的输入。&lt;/p&gt;

&lt;p&gt;Match-LSTM 的 Answer Pointer Layer 层包含了两种预测答案的模式，分别为 Sequence Model 和 Boundary Model。Sequence model提供的是一系列答案序列，但这些答案系列不一定在原文中是连续的；Boundary model是提供答案的开始与截止位置，在这两个位置中间所有的字就都是答案。Sequence Model 将答案看做是一个整数组成的序列，每个整数表示选中的 token 在原文中的位置，因此模型按顺序产生一系列条件概率，每个条件概率表示基于上轮预测的 token 产生的下个 token 的位置概率，最后答案总概率等于所有条件概率的乘积。Boundary Model 简化了整个预测答案的过程，只预测答案开始和答案结束位置，相比于 Sequence Model 极大地缩小了搜索答案的空间，最后的实验也显示简化的 Boundary Model 相比于复杂的 Sequence Model 效果更好，因此 Boundary Model 也成为后来的模型用来预测答案范围的标配。&lt;/p&gt;

&lt;p&gt;Sequence Model的答案定位计算公式如下：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;机器阅读理解Match-LSTM模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac374290001e74407560110.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:60%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt;是&lt;code class=&quot;highlighter-rouge&quot;&gt;[1, P+1]&lt;/code&gt;中某个值，当&lt;code class=&quot;highlighter-rouge&quot;&gt;k=P+1&lt;/code&gt;时，表示答案迭代计算答案位置概率结束。&lt;/p&gt;

&lt;p&gt;Boundary Model的答案定位计算公式如下：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;机器阅读理解Match-LSTM模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac3744000019f4506120110.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:60%&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-实验&quot;&gt;&lt;strong&gt;2 实验&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;模型参数设置如下：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;隐藏层大小：&lt;code class=&quot;highlighter-rouge&quot;&gt;150&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;优化方法：&lt;code class=&quot;highlighter-rouge&quot;&gt;Adamax(β1 = 0.9，β2 = 0.999)&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;minibatch：&lt;code class=&quot;highlighter-rouge&quot;&gt;30&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;没有用&lt;code class=&quot;highlighter-rouge&quot;&gt;L2&lt;/code&gt;正则&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;实验结果对比如图3所示：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;机器阅读理解Match-LSTM模型_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac37472000179ad15620702.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图3 各模型实验对比结果&lt;/p&gt;

&lt;h2 id=&quot;3-参考文献&quot;&gt;&lt;strong&gt;3 参考文献&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;[1] 目前（2017年）机器阅读技术发展得如何？能达到什么水平？有哪些应用？ [2017-05-22]. https://www.zhihu.com/question/59280791/answer/172363224&lt;/p&gt;

&lt;p&gt;[2] Wang S, Jiang J. Machine Comprehension Using Match-LSTM and Answer Pointer[J]. 2016.&lt;/p&gt;
</description>
        <pubDate>Tue, 03 Apr 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deeplearning/2018/04/03/%E6%9C%BA%E5%99%A8%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3Match-LSTM%E6%A8%A1%E5%9E%8B.html</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2018/04/03/%E6%9C%BA%E5%99%A8%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3Match-LSTM%E6%A8%A1%E5%9E%8B.html</guid>
        
        <category>机器阅读理解数据集</category>
        
        <category>Match-LSTM</category>
        
        
        <category>Deeplearning</category>
        
      </item>
    
      <item>
        <title>DuReader：百度大规模的中文机器阅读理解数据集</title>
        <description>&lt;h2 id=&quot;0-什么是机器阅读理解&quot;&gt;&lt;strong&gt;0 什么是机器阅读理解&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;目前，深度学习在图像识别、语音识别等领域取得丰硕成果，&lt;strong&gt;机器阅读理解（Machine Reading Comprehension，MRC）成为了人工智能研究与应用领域的新热点&lt;/strong&gt;。机器阅读理解是指让机器像人类一样阅读文本，提炼文本信息并回答相关问题。对人类而言，阅读理解是获取外部知识的一项基本且重要的能力。同样，对机器而言，机器阅读理解能力也是新一代机器人应具备的基础能力。&lt;/p&gt;

&lt;p&gt;机器阅读理解无论是在工业界还是学术界都有着很高的研究价值，它能够让计算机帮助人类在大量文本中找到想要的答案，从而减轻人们对信息的获取的成本。也许，未来的搜索引擎将不仅仅是返回用户相关的链接和网页，而是通过对互联网上的海量资源进行阅读理解，直接得出答案返回给用户。&lt;/p&gt;

&lt;h2 id=&quot;1-现有机器阅读理解数据集&quot;&gt;&lt;strong&gt;1 现有机器阅读理解数据集&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;上一篇博文对MCTest、CNN&amp;amp;Dailymail、SQuAD以及RACE等机器阅读理解数据集进行了简单的介绍，图1展示了更为全面的机器阅读理解数据集对比。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;DuReader：百度大规模的中文机器阅读理解数据集_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac0aaf6000135a517780524.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图1 机器阅读理解数据集对比&lt;/p&gt;

&lt;p&gt;分析图1，对于完形填空风格的CNN&amp;amp;Dailymail和HLF-RC数据集，其将复杂的及其阅读理解问题简化为对单词的简单预测；RACE通过对中国学生英语阅读理解考试数据的选项选择来测试机器阅读理解能力；基于问答的MRC数据集：NewsQA、SQuAD和TrivaQA将新闻文章、维基百科等数据转换为阅读理解题目，并定位答案出现的起始和结束位置。&lt;/p&gt;

&lt;p&gt;这些数据集的出现，激发了机器阅读理解的研究热情，基于这些数据集构建的模型也具有一定的效果，但&lt;strong&gt;存在以下缺点&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;数据人工合成&lt;/li&gt;
  &lt;li&gt;任务简单&lt;/li&gt;
  &lt;li&gt;应用领域有限&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;此外，最近的研究(Chen等人，2016；贾和梁，2017)表明，现有的MRC模型能够在这些数据集上实现高性能，但对这些数据的理解和推断有限。因此，建立真实世界的MRC数据集显得紧迫且重要。2016年，Nguyen等人发布了一个英文MRC数据集MS-Marco，其中的问题和文档是从搜索引擎收集的，答案由人工注释者生成。百度在2017年发布了大规模的中文MRC数据集：DuReader。&lt;/p&gt;

&lt;p&gt;相比以前的MRC数据集，&lt;strong&gt;DuReader有以下特点&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;所有的问题、原文都来&lt;strong&gt;源于实际数据&lt;/strong&gt;（百度搜索引擎数据和百度知道问答社区），&lt;strong&gt;答案是由人类回答的&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;数据集中包含大量的之前很少研究的是非和观点类的样本。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;每个问题都对应多个答案&lt;/strong&gt;，数据集包含200k问题、1000k原文和420k答案，是目前最大的中文MRC数据集。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;2-dureaderquestion数据分析&quot;&gt;&lt;strong&gt;2 DuReader“question”数据分析&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;百度创造性从两个维度分析问题数据，图2展示了DuReader数据集的问题类型分布情况。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;DuReader：百度大规模的中文机器阅读理解数据集_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac0ab350001190808580296.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图2 DuReader数据集的问题类型分布情况&lt;/p&gt;

&lt;p&gt;根据答案类型，&lt;strong&gt;DuReader将问题分为：Entity（实体）、Description（描述）和YesNo（是非）&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;对于实体类问题&lt;/strong&gt;，其答案一般是单一确定的回答，比如：iPhone是哪天发布？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;对于描述类问题&lt;/strong&gt;，其答案一般较长，是多个句子的总结，典型的how/why类型的问题，比如：消防车为什么是红的？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;对于是非类问题&lt;/strong&gt;，其答案往往较简单，是或者否，比如：39.5度算高烧吗？&lt;/p&gt;

&lt;p&gt;同时，无论将问题分类以上哪种类型都可以&lt;strong&gt;进一步细分为是事实（Fact）类还是观点（Opinion）类&lt;/strong&gt;。如图3展示了这两大类维度的划分方式。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;DuReader：百度大规模的中文机器阅读理解数据集_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac0ad1e000140e018540418.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图3 DuReader数据集问题划分方法&lt;/p&gt;

&lt;p&gt;通过这两个维度的划分方法，&lt;strong&gt;DuReader的问题类别共有6类&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;3-dureader数据集&quot;&gt;&lt;strong&gt;3 DuReader数据集&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;DuReader数据集的样本可用一个四维数组表示：&lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;q,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;t,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;D,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;，其中&lt;code class=&quot;highlighter-rouge&quot;&gt;q&lt;/code&gt;表示问题，&lt;code class=&quot;highlighter-rouge&quot;&gt;t&lt;/code&gt;表示问题类型，&lt;code class=&quot;highlighter-rouge&quot;&gt;D&lt;/code&gt;表示文档集合，&lt;code class=&quot;highlighter-rouge&quot;&gt;A&lt;/code&gt;表示答案集合。一半的样本来源于百度搜索引擎，一半来源于百度知道。图4展示了DuReader数据集的不同类型样本。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;DuReader：百度大规模的中文机器阅读理解数据集_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac0ad4b0001dc8915141338.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图4 DuReader数据集的不同类型样本&lt;/p&gt;

&lt;p&gt;基于问题和文档来对答案进行标注，由于一个问题可能对应多个文档，所以一个问题可能有多个答案，但对于及其相似的答案则归为一个。其数据分布情况如图5所示。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;DuReader：百度大规模的中文机器阅读理解数据集_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac0ad6900012e5109700656.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:60%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图5 答案种类分布情况&lt;/p&gt;

&lt;p&gt;由图5可知，&lt;strong&gt;百度知道中含有多个答案的问题占比高于百度搜索引擎，而含有一个答案的问题占比却低于百度搜索引擎，说明在问答社区中用户生成内容的主观性和多样性&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;DuReader数据集问题的平均字数长度为4.8，答案的平均字数长度为69.6，文档的平均字数长度为396.0，是MS-MARCO的5倍。&lt;/p&gt;

&lt;p&gt;由于规模大且问题类型复杂，基于DuReader数据集的分析工作相比以往数据集都要难得多。&lt;strong&gt;百度通过计算人工答案和文档的最小编辑距离来判断回答问题的困难度&lt;/strong&gt;。编辑距离越大，对文档的编辑修改就更多，回答问题的复杂度也就越高。对于答案直接来源于原文的数据集（如SQuAD），它们的编辑距离应该是0。图6展示了MS-MARCO和DuReader两个数据集答案与文档编辑距离分布情况。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;DuReader：百度大规模的中文机器阅读理解数据集_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac0ad9100011b2c09340636.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:60%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图6 MS-MARCO和DuReader两个数据集答案与文档编辑距离分布情况
&lt;/p&gt;
&lt;p&gt;从图6可以看出，在同为人工标注的数据集MS-MARCO中，77.1%的样本的编辑距离低于3，而在DuReader中51.3%的样本的编辑距离高于10，这说明&lt;strong&gt;DuReader更为复杂&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;4-基线模型&quot;&gt;&lt;strong&gt;4 基线模型&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;百度基于DuReader构建了&lt;strong&gt;两个基线模型：Match-LSTM和BiDAF&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;Match-LSTM是广泛应用的MRC模型，Match-LSTM为了在文章中找到答案，依次遍历文章，动态地将注意力权重与文章的每个标记进行匹配。最后，使用一个应答指针层来查找文章中的答案跨度。&lt;/p&gt;

&lt;p&gt;BiDAF既使用了语境对问题的注意，又使用了问题对上下文的注意，从而突出了问题和上下文中的重要部分。然后，利用注意流层融合所有有用的信息，从而得到每个位置的向量表示。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;模型的相关参数：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;词向量维度：300&lt;/li&gt;
  &lt;li&gt;隐藏层节点大小：150&lt;/li&gt;
  &lt;li&gt;优化算法：Adam&lt;/li&gt;
  &lt;li&gt;初始学习率：0.001&lt;/li&gt;
  &lt;li&gt;batch size：32&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一个问题可能对应了多个文档，&lt;strong&gt;为了训练和测试的效率，在每个文档中选择具有代表意义的段落&lt;/strong&gt;。在训练时，选择与答案相比较时可达到最高查全率的段落；在测试时，由于没有答案，则使用问题来计算查全率。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;评价方法为：BLEU-4和Rouge-L&lt;/strong&gt;。基于DuReader数据集模型实验结果如图7所示。基于不同问题类型模型实验结果如图8所示。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;DuReader：百度大规模的中文机器阅读理解数据集_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac0adc00001f1eb19440484.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图7 基于DuReader数据集模型实验结果对比&lt;/p&gt;

&lt;p&gt;由图7可知，&lt;strong&gt;构建的模型在百度搜索引擎的数据集的表现比百度知道的数据集要差&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;DuReader：百度大规模的中文机器阅读理解数据集_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac0addb0001c88317820336.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图8 基于不同问题类型模型实验结果对比&lt;/p&gt;

&lt;p&gt;由图8可知，&lt;strong&gt;模型在描述类问题普遍表现良好&lt;/strong&gt;，但在是非问题上表现较差。分析可能是因为描述类问题答案往往是同一主题下的长文本，而是非问题的答案则较短（有时候只有Yes或No），且是非类问题的答案主观性强，答案之间往往是矛盾的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;BLEU和Rouge这两种评价指标对是非类问题并不友好，因为这两种评价指标不能很好的反应答案之间的一致性&lt;/strong&gt;，比如两个完全相反的两个答案：“你可以做到”和“你不可以做到”，在BLEU和Rouge评价指标上，这两种矛盾的答案具有高一致性。&lt;/p&gt;

&lt;p&gt;为了解决以上出现在是非类问题的问题，&lt;strong&gt;建议模型不仅输出答案，同时还给出答案的标签（Yes、No或Depend）&lt;/strong&gt;，最终只使用相同标签的答案来计算BLEU和Rouge评价指标。图9表示对YesNo类型问题添加和不添加标签模型的表现。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;DuReader：百度大规模的中文机器阅读理解数据集_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5ac0adf300011ef513760262.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:70%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图9 对YesNo问题的标签感知模型的表现&lt;/p&gt;
</description>
        <pubDate>Sun, 01 Apr 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deeplearning/2018/04/01/DuReader-%E7%99%BE%E5%BA%A6%E5%A4%A7%E8%A7%84%E6%A8%A1%E7%9A%84%E4%B8%AD%E6%96%87%E6%9C%BA%E5%99%A8%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E6%95%B0%E6%8D%AE%E9%9B%86.html</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2018/04/01/DuReader-%E7%99%BE%E5%BA%A6%E5%A4%A7%E8%A7%84%E6%A8%A1%E7%9A%84%E4%B8%AD%E6%96%87%E6%9C%BA%E5%99%A8%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E6%95%B0%E6%8D%AE%E9%9B%86.html</guid>
        
        <category>中文机器阅读理解数据集</category>
        
        <category>DuReader</category>
        
        
        <category>Deeplearning</category>
        
      </item>
    
      <item>
        <title>机器阅读理解中几个经典数据集</title>
        <description>&lt;h2 id=&quot;一2013mctest&quot;&gt;一、2013，MCTest&lt;/h2&gt;

&lt;p&gt;论文：&lt;code class=&quot;highlighter-rouge&quot;&gt;《MCTest：A Challenge Dataset for the Open-Domain Machine Comprehension of Test》&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;数据以json格式给出。小规模，大部分在这个数据集上的研究都是基于特征工程的工作。&lt;/p&gt;

&lt;p&gt;下载链接：&lt;a href=&quot;&quot;&gt;http://www.msmarco.org/dataset.aspx&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;二2015cnndailymail&quot;&gt;二、2015，CNN&amp;amp;Dailymail&lt;/h2&gt;

&lt;p&gt;论文：&lt;code class=&quot;highlighter-rouge&quot;&gt;《Teaching Machines to Read and Comprehend》&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;填空型大规模英文机器理解数据集，答案是原文中的某一个词。&lt;/p&gt;

&lt;p&gt;CNN数据集包含美国有线电视新闻网的新闻文章和相关问题。大约有90k文章和380k问题。&lt;/p&gt;

&lt;p&gt;Dailymail数据集包含每日新闻的文章和相关问题。大约有197k文章和879k问题。&lt;/p&gt;

&lt;p&gt;下载链接：&lt;a href=&quot;&quot;&gt;https://github.com/deepmind/rc-data&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;三2016squad&quot;&gt;三、2016，SQuAD&lt;/h2&gt;

&lt;p&gt;论文：&lt;code class=&quot;highlighter-rouge&quot;&gt;《SQuAD:100000+ Question for Machine Comprehension of Test》&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;机器理解领域的ImageNet，数据来源于对维基百科文章的问题的整理，在500多篇文章中有超过100000个问题答案对，答案不是原文的一个词，而是原文的一个连续文本片段。数据以json格式给出，只给出了训练集以及验证集，如果要获取在测试集上的效果，需要上传模型，官方会把你的模型在测试集上跑，得出结果后再反馈给你。&lt;/p&gt;

&lt;p&gt;下载链接：&lt;a href=&quot;&quot;&gt;https://rajpurkar.github.io/SQuAD-explorer/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;四2017race&quot;&gt;四、2017，RACE&lt;/h2&gt;

&lt;p&gt;论文：&lt;code class=&quot;highlighter-rouge&quot;&gt;《RACE：Large-scale Reading Comprehension Dataset From Examinations》&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;数据集为中国中学生英语阅读理解题目，给定一篇文章和 5 道 4 选 1 的题目，包括了 28000+ passages 和 100,000 问题。与MCTest同为选择题形式的机器阅读数据集，但规模比MCTest大，且相对CNN&amp;amp;Dailymail和SQuAD，RACE更注重推理能力。&lt;/p&gt;

&lt;p&gt;数据以txt格式给出，数据集的high文件夹下有20794篇文章，每篇文章有4个问题；middle文件夹下有7139篇文章，每篇文章有5个问题。&lt;/p&gt;

&lt;p&gt;训练集的high文件夹下有18728篇文章，占比90%，middle文件夹下有6409篇文章，占比90%；&lt;/p&gt;

&lt;p&gt;验证集的high文件夹下有1021篇文章，占比5%，middle文件夹下有368篇文章，占比5%；&lt;/p&gt;

&lt;p&gt;测试集的high文件夹下有1045篇文章，占比5%，middle文件夹下有362篇文章，占比5%。&lt;/p&gt;

&lt;p&gt;需要发送email，官方会给你的邮箱发下载链接，申请地址：&lt;a href=&quot;&quot;&gt;http://www.cs.cmu.edu/~glai1/data/race/
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;样本数据展示：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;机器阅读理解中你需要知道的几个经典数据集_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5abdaed1000156fe12840826.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:60%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;机器阅读理解中你需要知道的几个经典数据集_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5abdaee50001000b12780800.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:60%&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Fri, 30 Mar 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deeplearning/2018/03/30/%E6%9C%BA%E5%99%A8%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E4%B8%AD%E5%87%A0%E4%B8%AA%E7%BB%8F%E5%85%B8%E6%95%B0%E6%8D%AE%E9%9B%86.html</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2018/03/30/%E6%9C%BA%E5%99%A8%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E4%B8%AD%E5%87%A0%E4%B8%AA%E7%BB%8F%E5%85%B8%E6%95%B0%E6%8D%AE%E9%9B%86.html</guid>
        
        <category>机器阅读理解</category>
        
        <category>数据集</category>
        
        
        <category>Deeplearning</category>
        
      </item>
    
      <item>
        <title>机器学习中的正则化</title>
        <description>&lt;h2 id=&quot;11-竹篮打水一场空-过拟合&quot;&gt;1.1 竹篮打水一场空-过拟合&lt;/h2&gt;

&lt;p&gt;如果你发现在训练集上你的模型无比的完美，请晚一点再开心，因为很有可能你的模型已经过拟合了，那么这个模型就算废了。&lt;strong&gt;过拟合的直观解释是模型在训练集上性能完美，但在验证集或测试集上效果却不那么尽人意了&lt;/strong&gt;。机器学习中一个核心任务就是防止模型过拟合，当模型的参数个数远大于数据集样本数量时，&lt;strong&gt;模型则可很好的“记忆”每一个训练数据的随机噪声而忘了去学习训练数据中通用的趋势，这就有可能导致过拟合&lt;/strong&gt;，这个时候你可以简单的扩充数据集中的样本来降低过拟合的影响，但这需要一定的时间和人力成本，且效果可能不那么明显。那么如何用最小的成本来防止模型过拟合呢，即如何使训练错误率与测试错误率的差距尽可能小呢？答案就是本文主要讨论的内容：正则化。&lt;/p&gt;

&lt;h2 id=&quot;12-正则化&quot;&gt;1.2 正则化&lt;/h2&gt;

&lt;p&gt;我们都知道正则化可以降低泛化错误率，降低模型过拟合几率，但Why？How？下面我们来详细分析下正则化。正则化策略主要的目的是限制学习算法的能力，主要的方法可以是：限制网络模型的神经元数量、限制模型参数（连接权重W，偏置项B等）的数目、在目标函数添加一些额外的惩罚项等。添加惩罚项可看成是对损失函数中的某些参数做一些限制，根据惩罚项的不同可分为：&lt;strong&gt;L0范数惩罚、L1范数惩罚（参数稀疏性惩罚）、L2范数惩罚（权重衰减惩罚）&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;121-l0范数惩罚&quot;&gt;1.2.1 L0范数惩罚&lt;/h2&gt;

&lt;p&gt;L0范数惩罚是最“严格”的参数限制策略，它&lt;strong&gt;将模型参数不等于0的个数控制在&lt;code class=&quot;highlighter-rouge&quot;&gt;c&lt;/code&gt;以内来达到限制模型能力的目的。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;122-l1范数惩罚&quot;&gt;1.2.2 L1范数惩罚&lt;/h2&gt;

&lt;p&gt;L0范数惩罚在实际应用中不太友好，进一步放松限制，不要求参数的非零数量被限制在某个范围内，而&lt;strong&gt;要求参数数值的总和要小于某个数值&lt;/strong&gt;，具体公式可见《深度学习中你需要知道的几个基本概念》，这种对参数数值总和的限制被称为L1范数惩罚，又称参数稀疏性惩罚，&lt;strong&gt;那么参数稀疏在哪呢？&lt;/strong&gt;假设一个带L1正则化的损失函数为&lt;code class=&quot;highlighter-rouge&quot;&gt;J=J0+α∑|w|&lt;/code&gt;
其中，&lt;code class=&quot;highlighter-rouge&quot;&gt;J0&lt;/code&gt;是原始的损失函数，&lt;code class=&quot;highlighter-rouge&quot;&gt;α∑|w|&lt;/code&gt;是L1正则化项，&lt;code class=&quot;highlighter-rouge&quot;&gt;α&lt;/code&gt;是正则化系数。L1正则化项是带有绝对值符号的函数，因此加了L1正则化项的损失函数是不完全可微的。当我们在原始损失函数&lt;code class=&quot;highlighter-rouge&quot;&gt;J0&lt;/code&gt;后添加L1正则化项后，相当于对&lt;code class=&quot;highlighter-rouge&quot;&gt;J0&lt;/code&gt;做了一个约束。令&lt;code class=&quot;highlighter-rouge&quot;&gt;L=α∑|w|&lt;/code&gt;，则&lt;code class=&quot;highlighter-rouge&quot;&gt;J=J0+L&lt;/code&gt;，我们知道&lt;strong&gt;梯度下降算法的目的是使损失函数最小化&lt;/strong&gt;，那么我们的任务变成在L约束下求出&lt;code class=&quot;highlighter-rouge&quot;&gt;J0&lt;/code&gt;取最小值的解。假设在二维的情况，即只有两个权值&lt;code class=&quot;highlighter-rouge&quot;&gt;w1&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;w2&lt;/code&gt;，此时&lt;code class=&quot;highlighter-rouge&quot;&gt;L=|w1|+|w2|&lt;/code&gt;。损失函数的梯度等值线如图1中的实线等高椭圆所示，梯度的最小值为其中心点，如果没有加任何限制项，则&lt;strong&gt;模型学习过程就是每次沿着梯度等高线垂直的方向寻找极值点&lt;/strong&gt;。而L1正则化的函数L在&lt;code class=&quot;highlighter-rouge&quot;&gt;w1、w2&lt;/code&gt;的二维平面上画出来表示为图1中的黑色方形。如下图1所示。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;机器学习中的正则化_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5aa9000a0001019f03180297.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:60%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:center&quot;&gt;图1 求解带L1正则化项的损失函数&lt;/p&gt;

&lt;p&gt;上图中&lt;code class=&quot;highlighter-rouge&quot;&gt;J0&lt;/code&gt;与&lt;code class=&quot;highlighter-rouge&quot;&gt;L&lt;/code&gt;在&lt;code class=&quot;highlighter-rouge&quot;&gt;L&lt;/code&gt;的一个顶点处&lt;code class=&quot;highlighter-rouge&quot;&gt;(0,w2)&lt;/code&gt;相交，这个顶点就是损失函数J的最优解。可以直观想象，因为L函数有很多“突出的角”（二维情况下四个，多维情况下更多），&lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;J0&lt;/code&gt;与这些角接触的机率会远大于与&lt;code class=&quot;highlighter-rouge&quot;&gt;L&lt;/code&gt;其它部位接触的机率&lt;/strong&gt;，而&lt;strong&gt;在这些角上会有很多权值等于0，这就是为什么L1正则化可以产生稀疏模型。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在这里，我们在解释下&lt;strong&gt;为什么J0与这些角接触的机率会远大于与L其它部位接触的机率？&lt;/strong&gt;试着想象下，如果方形的四条边凹进去一定的弧度，那么除非梯度等高线在一些特殊的角度才会使得相交点落在四条边上而不是方形的角上。当在多维的情况下（模型参数不只有2个），那么这个时候的L可表示为一个多边形，当边数够多，即角很多，可以近似的看成是四条边凹进去一定弧度后的图形，这样梯度等高线与角相交的概率会远大于L其它部分相交的概率。同样，如果方形的四条边往外凸，当凸出一定弧度后，会转变成一个圆，即为L2正则化的图形，这个时候的&lt;code class=&quot;highlighter-rouge&quot;&gt;J0&lt;/code&gt;与&lt;code class=&quot;highlighter-rouge&quot;&gt;L&lt;/code&gt;的图形上每个点相交的概率都一样，所以L2正则化无法产生稀疏模型。求解带L2正则化项的损失函数如图2所示。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;那么得到稀疏模型有什么好处呢？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;稀疏模型是指模型参数矩阵中有很多参数为0，只有少数参数是非零值的。机器学习中特征向量的维数一般很大，在预测或分类时，那么多特征显然难以选择，但是如果代入这些特征得到的模型是一个稀疏模型，表示只有少数特征对这个模型有贡献，绝大部分特征很大程度上是噪声特征，其没有贡献或贡献微小（因为它们前面的系数是0或者是很小的值，即使去掉对模型也没有什么影响），此时我们就可以只关注系数是非零值的特征。这就是稀疏模型与特征选择的关系。&lt;/p&gt;

&lt;h2 id=&quot;123-l2范数惩罚&quot;&gt;1.2.3 L2范数惩罚&lt;/h2&gt;

&lt;p&gt;我们知道L1范数项不可微，所以我们&lt;strong&gt;将参数的绝对值求和改为参数平方和&lt;/strong&gt;，公式如《深度学习中你需要知道的几个基本概念》所示，这就是L2范数惩罚，即权重衰减惩罚。&lt;/p&gt;

&lt;p&gt;这时一个带L2正则化的损失函数为J可表示为&lt;code class=&quot;highlighter-rouge&quot;&gt;J=J0+α∑w2&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;求解带L2正则化项的损失函数如下图所示。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;机器学习中的正则化_&quot; 图片2=&quot;&quot; src=&quot;https://img.mukewang.com/5aa900b0000123d303180297.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:60%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:center&quot;&gt;图2 求解带L2正则化项的损失函数&lt;/p&gt;

&lt;p&gt;正则化前面的系数&lt;code class=&quot;highlighter-rouge&quot;&gt;α&lt;/code&gt;，可以控制&lt;code class=&quot;highlighter-rouge&quot;&gt;L&lt;/code&gt;图形的大小。&lt;code class=&quot;highlighter-rouge&quot;&gt;α&lt;/code&gt;过小，&lt;code class=&quot;highlighter-rouge&quot;&gt;L&lt;/code&gt;的半径则很大，就越容易达到损失函数的最小值（中心点），会发生过拟合现象；&lt;code class=&quot;highlighter-rouge&quot;&gt;α&lt;/code&gt;过大，&lt;code class=&quot;highlighter-rouge&quot;&gt;L&lt;/code&gt;的半径则很小，即对模型参数惩罚过重，模型的能力也就越弱，会发生欠拟合现象。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;模型在拟合过程中通常都会倾向于让权值尽可能小&lt;/strong&gt;，最终构造一个所有参数都比较小的模型。因为一般认为参数值小的模型比较简单，且能适应不同的数据集，在一定程度上可降低过拟合风险。比如，对于一个线性回归方程，若参数很大，那么只要数据偏移一点点，就会对结果造成很大的影响；但如果参数足够小，数据偏移得多一点也不会对结果造成什么影响，这就是常说的抗扰动能力强。&lt;/p&gt;

&lt;h2 id=&quot;13-其它被视为正则化的策略&quot;&gt;1.3 其它被视为正则化的策略&lt;/h2&gt;

&lt;p&gt;在深度学习中你听过的很多名词其实都是一种正则化策略，下面我们将介绍这些正则化策略。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;参数共享&lt;/strong&gt;，在卷积神经网络中，卷积操作其实就采用了参数共享，通过参数共享，减少模型参数，降低模型复杂度，从而减少模型过拟合风险，卷积神经网络的详细内容见《卷积神经网络你需要知道的几个基本概念》。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;噪声注入以及数据扩充&lt;/strong&gt;，降低泛化错误率直接的方法就是训练更多的数据，但有监督学习中，带标签的数据往往是有限的，我们可以通过噪声注入以及数据扩充方法在现有数据的基础上扩充数据集。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;稀疏表征&lt;/strong&gt;，这种正则化策略事通过某种惩罚措施来抑制神经网络隐藏层中大部分神经元，当信息输入神经网络时，只有关键部分神经元处于激活状态。这和1.2.2节的L1范数惩罚相似，只不过，L1范数是使模型参数稀疏化，而表征稀疏化是隐藏层输出大多数为零或接近零。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Dropout&lt;/strong&gt;，以dropout概率随机断开神经元连接，是一种非常高效的深度学习正则化措施。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;参考文献&quot;&gt;参考文献&lt;/h2&gt;

&lt;p&gt;[1] 杨云、杜飞，清华大学出版社，深度学习实战&lt;/p&gt;
</description>
        <pubDate>Wed, 14 Mar 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deeplearning/2018/03/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96.html</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2018/03/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96.html</guid>
        
        <category>机器学习</category>
        
        <category>正则化</category>
        
        
        <category>Deeplearning</category>
        
      </item>
    
      <item>
        <title>循环神经网络你需要知道的几个基本概念</title>
        <description>&lt;h2 id=&quot;11-为什么有了全连接神经网络和cnn还需要rnn&quot;&gt;1.1 为什么有了全连接神经网络和CNN还需要RNN？&lt;/h2&gt;

&lt;p&gt;我们通过前两篇博文知道了全连接神经网络和卷积神经网络的基本工作原理，这两种网络结构的层与层之间是全连接或部分连接的，&lt;strong&gt;但在每层之间的节点是无连接的，这样的网络结构并不能很好的处理序列数据&lt;/strong&gt;。当我们要建立一个模型来预测句子的下一个单词是什么时，结合n-gram语言模型思想，一般是需要用到当前单词以及前面单词，因为一个句子中每个单词的出现并不是独立的。比如，如果第一个词是“天空”，接下来的词是“很”，那么下一个词很大概率会是“蓝”，RNN则可以处理类似这样的序列数据。&lt;strong&gt;RNN通过每层之间节点的连接结构来记忆之前的信息，并利用这些信息来影响后面节点的输出。RNN可充分挖掘序列数据中的时序信息以及语义信息，这种在处理时序数据时比全连接神经网络和CNN更具有深度表达能力&lt;/strong&gt;，RNN已广泛应用于语音识别、语言模型、机器翻译、时序分析等各个领域。&lt;/p&gt;

&lt;h2 id=&quot;12-rnn模型&quot;&gt;1.2 RNN模型&lt;/h2&gt;

&lt;p&gt;我们先来看一个RNN经典结构，图1展示了一个典型按时间展开后的RNN结构。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;循环神经网络你需要知道的几个基本概念_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5aa64138000175ef07820220.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:center&quot;&gt;图1 按时间展开后的RNN结构&lt;/p&gt;

&lt;p&gt;从图1可以看出，RNN在每一个时刻都有一个输入&lt;code class=&quot;highlighter-rouge&quot;&gt;Xt&lt;/code&gt;，然后根据当前节点的状态&lt;code class=&quot;highlighter-rouge&quot;&gt;At&lt;/code&gt;计算输出值&lt;code class=&quot;highlighter-rouge&quot;&gt;ht&lt;/code&gt;，而&lt;code class=&quot;highlighter-rouge&quot;&gt;At&lt;/code&gt;是根据上一时刻的状态&lt;code class=&quot;highlighter-rouge&quot;&gt;At-1&lt;/code&gt;和当前的输入&lt;code class=&quot;highlighter-rouge&quot;&gt;Xt&lt;/code&gt;共同决定的。&lt;strong&gt;和卷积神经网络卷积核或池化核的参数共享类似，这里RNN结构中的参数在不同时刻中也是共享的&lt;/strong&gt;。&lt;/p&gt;

&lt;h3 id=&quot;121-rnn前向传播过程&quot;&gt;1.2.1 RNN前向传播过程&lt;/h3&gt;

&lt;p&gt;图2展示了RNN的前向传播的计算过程。
&lt;img title=&quot;循环神经网络你需要知道的几个基本概念_&quot; 图片2=&quot;&quot; src=&quot;https://img.mukewang.com/5aa641ab00010acc07730469.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:center&quot;&gt;图2 RNN的前向传播的计算过程&lt;/p&gt;

&lt;p&gt;如图2所示，假设节点状态的维度为&lt;code class=&quot;highlighter-rouge&quot;&gt;2&lt;/code&gt;，节点的输入和输出维度为&lt;code class=&quot;highlighter-rouge&quot;&gt;1&lt;/code&gt;，那么在循环体的全连接层神经网络的输入维度为&lt;code class=&quot;highlighter-rouge&quot;&gt;3&lt;/code&gt;，&lt;strong&gt;也就是将上一时刻的状态与当前时刻的输入拼接成一维向量作为循环体的全连接层神经网络的输入&lt;/strong&gt;，在这里&lt;code class=&quot;highlighter-rouge&quot;&gt;t0&lt;/code&gt;时刻的节点状态初始化为&lt;code class=&quot;highlighter-rouge&quot;&gt;[0.0, 0.0]&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;t0&lt;/code&gt;时刻的节点输入为&lt;code class=&quot;highlighter-rouge&quot;&gt;[1.0]&lt;/code&gt;，拼接之后循环体的全连接层神经网络的输入为&lt;code class=&quot;highlighter-rouge&quot;&gt;[0.0, 0.0, 1.0]&lt;/code&gt;，循环体中的全连接层的权重表示为二维矩阵&lt;code class=&quot;highlighter-rouge&quot;&gt;[[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]]&lt;/code&gt;，偏置项为&lt;code class=&quot;highlighter-rouge&quot;&gt;[0.1, -0.1]&lt;/code&gt;，我们可以看到权重矩阵和偏置项在&lt;code class=&quot;highlighter-rouge&quot;&gt;t0&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;t1&lt;/code&gt;时刻的循环体中是一样的，&lt;strong&gt;这也说明了RNN结构中的参数在不同时刻中也是共享的&lt;/strong&gt;。经过循环体中的全连接层神经网络后节点的状态改变为&lt;code class=&quot;highlighter-rouge&quot;&gt;tanh([0.6, 0.5]) = [0.537, 0.462]&lt;/code&gt;，当前节点状态的输出作为下一个节点状态的输入。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;为了将当前时刻的状态转变为节点的最终输出，RNN中还有另外一个全连接神经网络来计算节点输出&lt;/strong&gt;，在图2中被表示为&lt;code class=&quot;highlighter-rouge&quot;&gt;[0.537, 0.462] * [1.0, 2.0] + [0.1] = [1.56]&lt;/code&gt;，用于输出的全连接层权重为&lt;code class=&quot;highlighter-rouge&quot;&gt;[1.0, 2.0]&lt;/code&gt;，偏置项为&lt;code class=&quot;highlighter-rouge&quot;&gt;[0.1]&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;1.56&lt;/code&gt;表示为&lt;code class=&quot;highlighter-rouge&quot;&gt;t0&lt;/code&gt;时刻节点的最终输出。&lt;/p&gt;

&lt;p&gt;得到RNN的前向传播结果之后，和其他神经网络类似，定义损失函数，使用反向传播算法和梯度下降算法训练模型，但RNN唯一的区别在于：&lt;strong&gt;由于它每个时刻的节点都有一个输出，所以RNN的总损失为所有时刻（或部分时刻）上的损失和&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;13-lstm结构&quot;&gt;1.3 LSTM结构&lt;/h2&gt;

&lt;p&gt;上节介绍的RNN模型，&lt;strong&gt;存在“长期依赖”的问题&lt;/strong&gt;。模型在预测“大海的颜色是”下一个单词时，很容易判断为“蓝色”，因为这里相关信息与待预测词的位置相差不大，模型不需要记忆这个短句子之前更长的上下文信息。但当模型预测“十年前，北京的天空很蓝，但随着大量工厂的开设，废气排放监控不力，空气污染开始变得越来越严重，渐渐地，这里的天空变成了”下一个单词时，依靠“短期依赖”就不能很好的解决这类问题，因为仅仅根据“这里的天空变成了”这一小段，后一个单词可以是“蓝色”，也可以是“灰色”。上节描述的简单RNN结构可能无法学习到这种“长期依赖”的信息，LSTM可以很好的解决这类问题。图3展示了LSTM单元结构图。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;循环神经网络你需要知道的几个基本概念_&quot; 图片3=&quot;&quot; src=&quot;https://img.mukewang.com/5aa642150001827705950366.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:center&quot;&gt;图3 LSTM单元结构图&lt;/p&gt;

&lt;p&gt;与简单RNN结构中单一tanh循环体不同的是，LSTM使用三个“门”结构来控制不同时刻的状态和输出。&lt;strong&gt;所谓的“门”结构就是使用了sigmoid激活函数的全连接神经网络和一个按位做乘法的操作&lt;/strong&gt;，sigmoid激活函数会输出一个0~1之间的数值，这个数值描述的是当前有多少信息能通过“门”，0表示任何信息都无法通过，1表示全部信息都可以通过。其中，“遗忘门”和“输入门”是LSTM单元结构的核心。下面我们来详细分析下三种“门”结构。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;遗忘门，用来让RNN“忘记”之前没有用的信息。&lt;/strong&gt;比如“十年前，北京的天空是蓝色的”，但当看到“空气污染开始变得越来越严重”后，RNN应该忘记“北京的天空是蓝色的”这个信息。遗忘门会根据当前时刻节点的输入&lt;code class=&quot;highlighter-rouge&quot;&gt;Xt&lt;/code&gt;、上一时刻节点的状态&lt;code class=&quot;highlighter-rouge&quot;&gt;C(t-1)&lt;/code&gt;和上一时刻节点的输出&lt;code class=&quot;highlighter-rouge&quot;&gt;h(t-1)&lt;/code&gt;来决定哪些信息将被遗忘。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;输入门，用来让RNN决定当前输入数据中哪些信息将被留下来。&lt;/strong&gt;在RNN使用遗忘门“忘记”部分之前的信息后，还需要从当前的输入补充最新的记忆。输入门会根据当前时刻节点的输入&lt;code class=&quot;highlighter-rouge&quot;&gt;Xt&lt;/code&gt;、上一时刻节点的状态&lt;code class=&quot;highlighter-rouge&quot;&gt;C(t-1)&lt;/code&gt;和上一时刻节点的输出&lt;code class=&quot;highlighter-rouge&quot;&gt;h(t-1)&lt;/code&gt;来决定哪些信息将进入当前时刻节点的状态&lt;code class=&quot;highlighter-rouge&quot;&gt;Ct&lt;/code&gt;，比如看到“空气污染开始变得越来越严重”后，模型需要记忆这个最新的信息。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;输出门，LSTM在得到最新节点状态&lt;code class=&quot;highlighter-rouge&quot;&gt;Ct&lt;/code&gt;后，结合上一时刻节点的输出&lt;code class=&quot;highlighter-rouge&quot;&gt;h(t-1)&lt;/code&gt;和当前时刻节点的输入&lt;code class=&quot;highlighter-rouge&quot;&gt;Xt&lt;/code&gt;来决定当前时刻节点的输出。&lt;/strong&gt;比如当前时刻节点状态为被污染，那么“天空的颜色”后面的单词应该是“灰色”。&lt;/p&gt;

&lt;p&gt;在TensorFlow中可以使用&lt;code class=&quot;highlighter-rouge&quot;&gt;lstm = rnn_cell.BasicLSTMCell(lstm_hidden_size)&lt;/code&gt;来声明一个LSTM结构。&lt;/p&gt;

&lt;h2 id=&quot;14-双向循环神经网络brnn&quot;&gt;1.4 双向循环神经网络（BRNN）&lt;/h2&gt;

&lt;p&gt;RNN和LSTM都只能依据之前时刻的时序信息来预测下一时刻的输出，但在有些问题中，&lt;strong&gt;当前时刻的输出不仅和之前的状态有关，还可能和未来的状态有关系&lt;/strong&gt;。比如预测一句话中缺失的单词不仅需要根据前文来判断，还需要考虑它后面的内容，真正做到基于上下文判断。BRNN有两个RNN上下叠加在一起组成的，输出由这两个RNN的状态共同决定。BRNN结构图如图4所示。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;循环神经网络你需要知道的几个基本概念_&quot; 图片4=&quot;&quot; src=&quot;https://img.mukewang.com/5aa6424f0001485b07120276.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:center&quot;&gt;图4 BRNN结构图&lt;/p&gt;

&lt;p&gt;对于每个时刻&lt;code class=&quot;highlighter-rouge&quot;&gt;t&lt;/code&gt;，输入会同时提供给两个方向相反的RNN，输出由这两个单向RNN共同决定。&lt;/p&gt;

&lt;h2 id=&quot;15-深层循环神经网络drnn&quot;&gt;1.5 深层循环神经网络（DRNN）&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;DRNN可以增强模型的表达能力，主要是将每个时刻上的循环体重复多次&lt;/strong&gt;，每一层循环体中参数是共享的，但不同层之间的参数可以不同。DRNN结构图如图5所示。
&lt;img title=&quot;循环神经网络你需要知道的几个基本概念_&quot; 图片5=&quot;&quot; src=&quot;https://img.mukewang.com/5aa6426f0001c71204910466.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:center&quot;&gt;图5 DRNN结构图&lt;/p&gt;

&lt;p&gt;TensorFlow中可以通过&lt;code class=&quot;highlighter-rouge&quot;&gt;rnn_cell.MultiRNNCell([lstm] * number_of_layer)&lt;/code&gt;来构建DRNN，其中&lt;code class=&quot;highlighter-rouge&quot;&gt;number_of_layer&lt;/code&gt;表示了有多少层。&lt;/p&gt;

&lt;p&gt;在我们构建自己的任务模型时，往往会设置dropout来让构建的网络模型更加健壮，类似在卷积神经网络只在最后全连接层使用dropout，&lt;strong&gt;DRNN一般只在不同层循环体结构中使用dropout，而不在同一层的循环体结构中使用&lt;/strong&gt;。即从时刻&lt;code class=&quot;highlighter-rouge&quot;&gt;t-1&lt;/code&gt;传递到&lt;code class=&quot;highlighter-rouge&quot;&gt;t&lt;/code&gt;时刻时，RNN不进行状态的dropout，但在同一时刻t中，不同层循环体之间会使用dropout，图6展示了DRNN中使用dropout，其中实线箭头表示不使用dropout，虚线箭头表示使用dropout。
&lt;img title=&quot;循环神经网络你需要知道的几个基本概念_&quot; 图片6=&quot;&quot; src=&quot;https://img.mukewang.com/5aa642940001932204600364.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:center&quot;&gt;图6 DRNN中使用dropout&lt;/p&gt;

&lt;p&gt;TensorFlow中可以使用&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.nn.rnn_cell.DropoutWrapper&lt;/code&gt;类来实现dropout功能。&lt;/p&gt;

&lt;p&gt;在实际编程中，我们可以通过TensorFlow的高层封装工具TFLearn来自定义模型，&lt;strong&gt;TFLearn封装了一些常用的神经网络模型&lt;/strong&gt;，有兴趣的可以找找教程。&lt;/p&gt;

&lt;h2 id=&quot;参考文献&quot;&gt;参考文献&lt;/h2&gt;

&lt;p&gt;[1]郑泽宇，顾思宇. Tensorflow：实战Google深度学习框架[M]. 电子工业出版社, 2017.&lt;/p&gt;
</description>
        <pubDate>Mon, 12 Feb 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deeplearning/2018/02/12/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BD%A0%E9%9C%80%E8%A6%81%E7%9F%A5%E9%81%93%E7%9A%84%E5%87%A0%E4%B8%AA%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2018/02/12/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BD%A0%E9%9C%80%E8%A6%81%E7%9F%A5%E9%81%93%E7%9A%84%E5%87%A0%E4%B8%AA%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html</guid>
        
        <category>循环神经网络</category>
        
        
        <category>Deeplearning</category>
        
      </item>
    
      <item>
        <title>卷积神经网络你需要知道的几个基本概念</title>
        <description>&lt;h2 id=&quot;11-为什么有了全连接网络模型还要cnn&quot;&gt;1.1 为什么有了全连接网络模型还要CNN？&lt;/h2&gt;

&lt;p&gt;全连接网络模型是指在神经网络中每两层之间的所有结点都是相连接的，但在处理图像数据时，全连接网络所需要的参数个数太多，比如处理一张单通道图片，图片大小为&lt;code class=&quot;highlighter-rouge&quot;&gt;28\*28&lt;/code&gt;，设隐藏层的节点数为&lt;code class=&quot;highlighter-rouge&quot;&gt;500&lt;/code&gt;个，则由其组成的全连接网络模型的参数有&lt;code class=&quot;highlighter-rouge&quot;&gt;28\*28*500+500=392500&lt;/code&gt;，“+500”是因为考虑了偏置项b的情况，而当图片更大时，参数会急剧增多，&lt;strong&gt;参数过多不仅会导致网络模型计算速度变慢，同时也容易导致过拟合问题&lt;/strong&gt;，CNN的出现就是为了在一定程度上改善这种情况。&lt;/p&gt;

&lt;h2 id=&quot;12-卷积层和池化层&quot;&gt;1.2 卷积层和池化层&lt;/h2&gt;

&lt;p&gt;图1展示了一个典型的CNN模型结构图。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;卷积神经网络你需要知道的几个基本概念_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5aa4dad60001994208920253.jpg&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:center&quot;&gt;图1 典型的CNN模型结构图&lt;/p&gt;

&lt;p&gt;从上图中可以看出，CNN的卷积层（Convolution）和池化层（Polling）中每个节点只与上一层的部分节点相连，卷积层的每个节点的输入只是上一层中的一小块，这个小块的大小由卷积核的窗口大小决定，通常来说，经过卷积层处理的节点矩阵会变得更深，具体的深度由卷积层中卷积核的多少来决定。&lt;strong&gt;卷积核的参数是共享可以使得图像上的内容不受位置的影响&lt;/strong&gt;，即图片中的猫不管是在图片的左上角或者右下角都应该被分类为猫，&lt;strong&gt;同时共享卷积核的参数可以大幅减少网络模型中的参数&lt;/strong&gt;，降低运算的复杂度。&lt;/p&gt;

&lt;p&gt;池化层的每个节点的输入也是上一层（通常是卷积层）的一小块，这个小块的大小由池化核的窗口大小决定，池化层不会改变节点矩阵的深度，但它可以改变矩阵的大小，通俗来说，对于图像处理，&lt;strong&gt;池化层中池化操作可以理解为是将一张分辨率高的图片转化为分辨率低的图片&lt;/strong&gt;。常用的池化操作有最大池化、平均池化等，通过卷积层和池化层后，可以进一步缩小网络模型中的参数个数，下面我们来分析下CNN如何减少网络模型中的参数。&lt;/p&gt;

&lt;h3 id=&quot;121-维度变化过程&quot;&gt;1.2.1 维度变化过程&lt;/h3&gt;

&lt;p&gt;卷积层是CNN中重要的概念之一，通过卷积核对上一层进行卷积操作，完成特征抽取。本节主要分析卷积层和池化层的维度变化过程，在使用全0填充（如果步长为1则可避免节点矩阵通过卷积层后尺寸发生变化）时，卷积层\池化层的输出维度计算公式为：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;卷积神经网络你需要知道的几个基本概念_&quot; 图片2=&quot;&quot; src=&quot;https://img.mukewang.com/5aa4db570001eadc02970089.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;out(longth)&lt;/code&gt;表示卷积层输出矩阵的长度，它等于输入层矩阵长度除以在长度方向上的步长的向上取整值，&lt;code class=&quot;highlighter-rouge&quot;&gt;out(width)&lt;/code&gt;表示卷积层输出矩阵的宽度，它等于输入层矩阵宽度除以在宽度方向上的步长的向上取整值。&lt;/p&gt;

&lt;p&gt;如果不使用全0填充，则卷积层\池化层的输出维度计算公式为：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;卷积神经网络你需要知道的几个基本概念_&quot; 图片3=&quot;&quot; src=&quot;https://img.mukewang.com/5aa4db780001caa904380078.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;filter(length)&lt;/code&gt;表示卷积核\池化核在在长度方向上的大小，&lt;code class=&quot;highlighter-rouge&quot;&gt;filter(width)&lt;/code&gt;表示卷积核\池化核在在宽度方向上的大小。
假如输入层矩阵的维度为&lt;code class=&quot;highlighter-rouge&quot;&gt;32\*32\*1&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;1&lt;/code&gt;代表灰度图像，第一层卷积核尺寸为&lt;code class=&quot;highlighter-rouge&quot;&gt;5\*5&lt;/code&gt;，深度为&lt;code class=&quot;highlighter-rouge&quot;&gt;6&lt;/code&gt;（即有6个卷积核），不使用全0填充，步长为&lt;code class=&quot;highlighter-rouge&quot;&gt;1&lt;/code&gt;。则卷积层的输出维度为&lt;code class=&quot;highlighter-rouge&quot;&gt;（32-5+1=28）&lt;/code&gt;，卷积层的参数共有&lt;code class=&quot;highlighter-rouge&quot;&gt;5\*5\*1\*6+6=156&lt;/code&gt;个，这里可以发现，&lt;strong&gt;卷积层的参数个数与图片大小无关，它只与卷积核尺寸、深度以及当前层节点矩阵的深度有关&lt;/strong&gt;，这使得CNN可以扩展到任意大小的图像数据上，卷积层的输出维度即下一层（通常是池化层）的输入维度有&lt;code class=&quot;highlighter-rouge&quot;&gt;28\*28\*6=4704&lt;/code&gt;个节点；池化层的池化核大小为&lt;code class=&quot;highlighter-rouge&quot;&gt;2\*2&lt;/code&gt;，步长为&lt;code class=&quot;highlighter-rouge&quot;&gt;2&lt;/code&gt;，池化层的输出维度为&lt;code class=&quot;highlighter-rouge&quot;&gt;（28-2+1）/2=13.5&lt;/code&gt;，向上取整的结果为14，池化层不影响节点矩阵的深度，则池化层的输出维度为&lt;code class=&quot;highlighter-rouge&quot;&gt;14\*14*6&lt;/code&gt;。&lt;/p&gt;

&lt;h2 id=&quot;参考文献&quot;&gt;参考文献&lt;/h2&gt;

&lt;p&gt;[1]郑泽宇，顾思宇. Tensorflow：实战Google深度学习框架[M]. 电子工业出版社, 2017.&lt;/p&gt;
</description>
        <pubDate>Sun, 21 Jan 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deeplearning/2018/01/21/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BD%A0%E9%9C%80%E8%A6%81%E7%9F%A5%E9%81%93%E7%9A%84%E5%87%A0%E4%B8%AA%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2018/01/21/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BD%A0%E9%9C%80%E8%A6%81%E7%9F%A5%E9%81%93%E7%9A%84%E5%87%A0%E4%B8%AA%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html</guid>
        
        <category>卷积神经网络</category>
        
        
        <category>Deeplearning</category>
        
      </item>
    
      <item>
        <title>深度学习中你需要知道的几个基本概念</title>
        <description>&lt;p&gt;深度学习在一定程度上等同于深层神经网络，维基百科对深度学习的概念为：一类通过多层非线性变换对高复杂性数据建模算法的合集。从该定义中可以看出两个深度学习的特征：多层和非线性。&lt;/p&gt;

&lt;h2 id=&quot;11-非线性与线性&quot;&gt;1.1 非线性与线性&lt;/h2&gt;

&lt;p&gt;由于模型的输出被简单的表示为输入的加权和，线性模型只能通过直线来划分平面。任意线性模型的组合依旧是线性模型，所以如果没有激活函数，只通过线性变化，任意层的全连接神经网络和单层神经网络模型的表达能力没有区别，且其在解决复杂问题上显得吃力。下面使用TensorFlow官方提供的一个神经网络游乐场来分析线性模型的局限性。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;图1 非线性可分问题的线性模型图&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5a9de1a9000102bd11770710.png&quot; alt=&quot;图1 非线性可分问题的线性模型图&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:center&quot;&gt;图1 非线性可分问题的线性模型图&lt;/p&gt;

&lt;p&gt;从图1可以看出，在正上方激活函数Activation一栏中我们选择了“Linear”线性函数，学习率Learning rate为0.03，全连接线性神经网络模型包含：输入层有两个节点，代表两个输入；隐藏层有三个节点；输出层为一个节点，表示分类结果。在输出图上方还给出了训练和测试的损失值（Test loss 和 Training loss），随着Epoch的增加，loss也会随之减少。在左边我们可以选择不同的数据集喂给定义好的模型，这里我们选择一个非线性可分的数据集。训练100epoch的模型结果如图2所示。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;图2 非线性可分问题的线性模型结果图&quot; 图片2=&quot;&quot; src=&quot;https://img.mukewang.com/5a9de1bc000175d811600697.png&quot; alt=&quot;图2 非线性可分问题的线性模型结果图&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:center&quot;&gt;图2 非线性可分问题的线性模型结果图&lt;/p&gt;

&lt;p&gt;从图2模型结果图分析可知，训练100次后，模型并没有很好地拟合非线性任务，且在输出图中看出有一条直线来表示模型的划分方式，模型将在直线上方的点分类为蓝色，将直线下方的点分类为黄色，显然这种分类效果并不理想。为了对比线性模型与非线性模型在同一问题上的效果，我们将Activation改为Relu，其他超参数不变，实验结果如图3所示。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;图3 非线性可分问题的非线性模型结果图&quot; 图片3=&quot;&quot; src=&quot;https://img.mukewang.com/5a9de1e60001c15011620700.png&quot; alt=&quot;图3 非线性可分问题的非线性模型结果图&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:center&quot;&gt;图3 非线性可分问题的非线性模型结果图&lt;/p&gt;

&lt;p&gt;从图3模型结果图分析可知，非线性模型的Test loss仅为0.033，说明非线性模型对处理非线性问题效果要比线性模型好。同时为了展现线性模型处理线性任务的有效性，我们选取线性可分的数据集进行线性模型实验，Activation选择Linear，且其它超参数保持不变，实验结果如图4所示。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;图4 线性可分问题的线性模型结果图&quot; 图片4=&quot;&quot; src=&quot;https://img.mukewang.com/5a9de2060001164611570692.png&quot; alt=&quot;图4 线性可分问题的线性模型结果图&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:center&quot;&gt;图4 线性可分问题的线性模型结果图&lt;/p&gt;

&lt;p&gt;从图4模型结果图分析可知，Test loss可达到0.000，说明在线性可分问题中，线性模型可以很好的区分不同颜色的点，线性模型可以很好的处理线性可分任务。&lt;/p&gt;

&lt;h2 id=&quot;12-激活函数&quot;&gt;1.2 激活函数&lt;/h2&gt;

&lt;p&gt;但现实生活中，我们往往需要处理复杂的非线性可分的问题，这种问题无法通过直线或高维空间平面来划分，深度学习的出现可以处理这类问题。&lt;/p&gt;

&lt;p&gt;线性模型的输出是所有输入的简单加权和，如果将加权和再通过一个非线性函数，则构建的神经网络模型不再是是线性模型，这个非线性函数就是我们常看到的激活函数，TensorFlow中封装了7中不同的非线性激活函数，如&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.nn.relu，tf.sigmoid和tf.tanh&lt;/code&gt;等。&lt;/p&gt;

&lt;h2 id=&quot;13-损失函数&quot;&gt;1.3 损失函数&lt;/h2&gt;

&lt;p&gt;本节介绍两种常用的损失函数，一种是分类问题中的交叉熵，另一种则是回归问题的均方差。
交叉熵（cross entropy）主要思想是通过刻画两个概率分布的距离，从而判断输出向量与期望向量的相似度。假设给定两个概率分布p和q，则交叉熵的公式可表示为：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;交叉熵的公式&quot; 图片4=&quot;&quot; src=&quot;https://img.mukewang.com/5a9de23b00019ea202610058.png&quot; alt=&quot;交叉熵的公式&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们可以用softmax将神经网络前向传播的输出结果变成一个概率分布，比如神经网络有n个输出节点，即模型有n个类别的数据，假设有一个三分类问题，即n=3，且一个输入样本属于类别k=1，则模型输出结果越接近[0,1,0]越好。&lt;/p&gt;

&lt;p&gt;我们举个例子来解释交叉熵的计算过程，某样本的期望向量为（1，0，0），模型1经过Softmax回归后的预测向量为（0.5，0.4，0.1），则预测向量与期望向量之间的交叉熵为：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;H((1,0,0),(0.5,0.4,0.1)) = -(1 * log(0.5) + 0 * log(0.4) + 0 * log(0.1)) = 0.3&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;模型2经过Softmax回归后的预测向量为（0.8，0.1，0.1），则预测向量与期望向量之间的交叉熵为：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;H((1,0,0),(0.8,0.1,0.1)) = -(1 * log(0.8) + 0 * log(0.1) + 0 * log(0.1)) = 0.1&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;交叉熵越小，说明模型的预测结果与期望结果越接近，由此可以看出，模型2的效果更好。
TensorFlow中可以通过&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.nn.softmax_cross_entropy_with_logits(y_pred, y)&lt;/code&gt;来计算预测向量与期望向量之间的交叉熵。&lt;/p&gt;

&lt;p&gt;均方误差（Mean Squared Error，MSE）是回归问题常用的损失函数，MSE的公式如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;MSE的公式&quot; 图片4=&quot;&quot; src=&quot;https://img.mukewang.com/5a9de2710001f30e02870073.png&quot; alt=&quot;MSE的公式&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在TensorFlow中可以通过&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.reduce_mean(tf.square(y-y_pred))&lt;/code&gt;来计算MSE。当然我们也可以根据任务导向，自定义损失函数。&lt;/p&gt;

&lt;h2 id=&quot;14-优化算法&quot;&gt;1.4 优化算法&lt;/h2&gt;

&lt;p&gt;神经网络中需要知道的两个基本的优化概念：反向传播算法和梯度下降算法。反向传播算法主要思想是根据定义好的损失函数优化网络模型中所有的参数，使得神经网络在训练集上的损失函数达到最小值，反向传播算法使用梯度下降算法优化网络模型中的单个参数的取值。梯度下降算法形象的解释就好比我们下山，假如我们随意向上或向下走一步，根据之后与之前所处山的高度来判断我们是在向山顶走还是在向山谷走，如果我们走一步之后所处山的高度比之前低，则说明我们走的方向是正确的，那么下一步我们就接着往这个方向走。在这里还隐含着两个概念：梯度与学习率。参数的梯度通过求偏导的方式计算，如果是多层网络结果，则使用链式求导法则来更新模型参数。学习率（learning rate）用来定义每次网络参数更新的幅度，对比到下山的过程，我们没走一步的步长即为学习率，学习率过大可能导致我们直接跨过了最低山谷，而导致每次在最低山谷两边徘徊，但学习率过下可能导致陷入极小山谷而不是最小山谷。所以在训练网络模型时，参数的初始值和学习率初始值很大程度上会影响模型最后的结果，只有当损失函数为凸函数时，梯度下降算法才能保证模型能训练到最小值，即全局最优解。&lt;/p&gt;

&lt;p&gt;除了不能保证取得全局最优解，梯度下降算法在海量数据下，计算所有训练数据的损失函数是非常耗时的。为了加速训练过程，可以选择随机梯度下降算法，随机梯度下降算法主要思想是在每一次迭代时，随机优化某一个batch训练数据的损失函数。&lt;/p&gt;

&lt;h3 id=&quot;141-学习率衰减&quot;&gt;1.4.1 学习率衰减&lt;/h3&gt;

&lt;p&gt;TensorFlow有一种灵活设置学习率的方法：指数衰减法，即在初始的时候使用一个较大的学习率以加快较优的解，然后随着迭代次数增加逐步减小学习率。&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.train.exponential_decay&lt;/code&gt;方法实现了指数衰减学习率。&lt;/p&gt;

&lt;h3 id=&quot;142-过拟合&quot;&gt;1.4.2 过拟合&lt;/h3&gt;

&lt;p&gt;过拟合的思想是当一个模型过于复杂时（一般是模型的参数个数大于训练样本数），它可以很好的“记忆”每一个训练数据的随机噪声而忘了去学习训练数据中通用的趋势。如图5所示可以很形象的解释过拟合问题。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;图5 过拟合问题&quot; 图片5=&quot;&quot; src=&quot;https://img.mukewang.com/5a9de2a7000185a210180726.png&quot; alt=&quot;图5 过拟合问题&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:center&quot;&gt;图5 过拟合问题&lt;/p&gt;

&lt;p&gt;避免过拟合问题常用的方法为正则化，其基本思想是，在损失函数中加入刻画模型复杂程度部分，从而限制权重的大小，并使得网络模型不能过度拟合训练数据中的随机噪声。假设损失函数为L，加入正则化后，模型需要优化的损失函数为&lt;code class=&quot;highlighter-rouge&quot;&gt;L+c*R(w)&lt;/code&gt;，R(w)表示的是模型的复杂程度，c表示模型的复杂损失占总损失的比例，R(w)包含L1正则化与L2正则化，L1正则化的公式为：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;L1正则化的公式&quot; 图片4=&quot;&quot; src=&quot;https://img.mukewang.com/5a9de2c60001728503920104.png&quot; alt=&quot;L1正则化的公式&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;L2正则化的公式为：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;L2正则化的公式&quot; 图片4=&quot;&quot; src=&quot;https://img.mukewang.com/5a9de2d70001548204200116.png&quot; alt=&quot;L2正则化的公式&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;L1正则化会让参数变得更加稀疏，而L2正则化不会，且L2正则化可导，而L1正则化不可导，所以我们一般使用L2正则化。滑动平均模型通过控制模型更新速度可以使得模型在测试数据上更加健壮，在TensorFlow中可以使用&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.train.ExponentialMovingAverage&lt;/code&gt;来实现滑动平均模型。&lt;/p&gt;

&lt;h2 id=&quot;参考文献&quot;&gt;参考文献&lt;/h2&gt;

&lt;p&gt;[1]郑泽宇，顾思宇. Tensorflow：实战Google深度学习框架[M]. 电子工业出版社, 2017.&lt;/p&gt;
</description>
        <pubDate>Mon, 18 Dec 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deeplearning/2017/12/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E4%BD%A0%E9%9C%80%E8%A6%81%E7%9F%A5%E9%81%93%E7%9A%84%E5%87%A0%E4%B8%AA%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2017/12/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E4%BD%A0%E9%9C%80%E8%A6%81%E7%9F%A5%E9%81%93%E7%9A%84%E5%87%A0%E4%B8%AA%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html</guid>
        
        <category>深度学习</category>
        
        
        <category>Deeplearning</category>
        
      </item>
    
      <item>
        <title>深度学习发展大事记</title>
        <description>&lt;p&gt;现在所说的深度学习基本是深层神经网络的代名词，神经网络技术不是最近新发明的，其最早可以追溯到1943年。1943，神经网络早期的神经网络模型类似于仿生机器学习，受大脑的学习机理启发，模仿大脑神经元结构设计人工神经网络中的神经元。Warren McCulloch教授和Walter Pitts教授提出了McCulloch-Pills Neuron的计算结构。图1是大脑神经元结构与McCulloch-Pills Neuron结构对比图。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;深度学习-发展大事记_&quot; 图片1=&quot;&quot; src=&quot;https://img.mukewang.com/5a9624c00001441117580544.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图1 大脑神经元结构与McCulloch-Pills Neuron结构对比图&lt;/p&gt;

&lt;p&gt;McCulloch-Pills Neuron结构使用了简单的线性加权和来模拟大脑神经元输入与输出之间的变换，最终通过一个阈值函数得到一个0或1的输出，完成神经元的计算。&lt;/p&gt;

&lt;p&gt;1958，McCulloch-Pills Neuron结构的权值还是通过简单的人工手动设置，这显然既费时又费力，让程序自动学习并调整权值就非常重要。Frank Rosenblatt教授在1958年提出感知机模型，它可被视为一种最简单形式的前馈神经网络（单层人工神经网络），是一种二元线性分类器。感知机利用梯度下降法对损失函数进行极小化，求出可将训练数据进行线性划分的分离超平面，从而求得感知机模型。&lt;/p&gt;

&lt;p&gt;1969，McCulloch-Pills Neuron结构与感知机模型的提出让机器学习迎来第一春，但它们也存在较大的局限性，Marvin Minsky教授等证明感知机模型只能解决线性可分问题，同时也指出在当时的计算能力下，多层神经网络的实现是不可能的事情，这些局限性导致学术界开始抨击机器学习模型，降低了机器学习在学术界的热度。神经网络的研究在之后的十几年中几乎处于停滞状态。&lt;/p&gt;

&lt;p&gt;20世纪80年代，分布式知识表达和神经网络反向传播算法的提出给了低迷的神经网络研究一剂兴奋剂。分布式知识表达的基本思想是现实世界中的知识和概念可以用多个神经元来表示，同时一个神经元也可以参与多个概念的表达，比如用一类神经元表示汽车的颜色，另一类神经元表示汽车的类型，那么对于“白色小轿车”便可以用两个神经元来表示，这种将单个神经元拓展到多个神经元的方式，大大加强了模型的表达能力，使得神经网络从宽度的方向走向了深度的方向。反向传播算法（Back Propagation，BP）降低了神经网络模型训练的时间成本，直到今天，BP算法都是训练神经网络模型的主要方法。&lt;/p&gt;

&lt;p&gt;20世纪80年代末90年代初，神经网络的研究迎来了新一轮的发展高峰期，现在常用的网络模型，如卷积神经网络、循环神经网络、LSTM网络模型等都在这一时期获得了飞速发展，但受计算资源、数据量等影响，训练深层神经网络依旧非常困难。值得注意的是，在神经网络发展的同时，传统的机器学习算法也取得了突破性的进展，其热度逐步超越了神经网络，成为了机器学习领域最常用的方法。&lt;/p&gt;

&lt;p&gt;随着计算机海量计算能力的进一步提高，以及云计算、GPU等的出现，神经网络的发展迎来的又一轮高潮，2012年李飞飞等人举办了ImageNet图像分类竞赛，随后深度学习的热度呈指数级上升，到2016年，深度学习已经成为了谷歌上最热门的搜索词。如今我们正处于一个深度学习飞速发展的时期，吴恩达在他的深度学习课程中说到，由于强大的计算资源、海量的数据、算法的飞速发展，深度学习将会在未来十年持续发展。&lt;/p&gt;

&lt;h2 id=&quot;参考文献&quot;&gt;参考文献&lt;/h2&gt;

&lt;p&gt;[1] 郑泽宇、顾思宇，电子工业出版社，Tensorflow实战Goggle深度学习框架&lt;/p&gt;
</description>
        <pubDate>Tue, 21 Nov 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deeplearning/2017/11/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%8F%91%E5%B1%95%E5%A4%A7%E4%BA%8B%E8%AE%B0.html</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2017/11/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%8F%91%E5%B1%95%E5%A4%A7%E4%BA%8B%E8%AE%B0.html</guid>
        
        <category>深度学习</category>
        
        
        <category>Deeplearning</category>
        
      </item>
    
      <item>
        <title>如何使用N-gram语言模型来进行篇章单元分类？</title>
        <description>&lt;h2 id=&quot;一-什么是n-gram语言模型language-model&quot;&gt;&lt;strong&gt;一、 什么是N-gram语言模型(Language Model)&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;N-gram是自然语言处理（NLP）中一个非常重要的概念，通常在NLP中，人们基于一定的语料库，可以利用N-gram来做以下几类事情：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;预计或者评估一个句子是否合理；&lt;/li&gt;
  &lt;li&gt;评估两个字符串之间的差异程度，这也是模糊匹配中常用的一种手段；&lt;/li&gt;
  &lt;li&gt;语音识别；&lt;/li&gt;
  &lt;li&gt;机器翻译；&lt;/li&gt;
  &lt;li&gt;文本分类。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;我们主要使用N-gram语言模型来进行文本分类。假定S表示某个有意义的句子，由一串特定顺序排列的词w1,w2,w3,..,wn组成，n是句子的长度。想知道S在文本中(语料库)出现的可能性，也就是数学上所说的概率P(S)：&lt;/p&gt;

&lt;p&gt;P(S)=P(w1,w2,w3,..,wn)=P(W1)P(W2|W1)P(W3|W1,W2)..P(Wn|W1,W2,..,Wn−1)&lt;/p&gt;

&lt;p&gt;由于要计算wi出现的概率，就要去统计前i-1词出现的情况，假设词库中有n个词，就有n^(i-1)种可能，这样每增加一个单词，模型的计算成本都指数倍的增长。于是，我们做一个简单的马尔科夫假设（Markov Assumption）来简化问题：假设第i个词出现的概率只与前面的N-1个词有关，这就是N-gram语言模型的由来。比如计算的概率时候，我们假设单词wi出现的概率只与前面出现的N个词有关：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;当N=1的时候，为一元模型（Unigram model）：P(S)=P(w1,w2,w3,..,wn)=P(W1)*P(W2)*…*P(Wn)&lt;/li&gt;
  &lt;li&gt;当N=2的时候，叫二元模型（Bigram model）：P(S)=P(w1,w2,w3,..,wn)=P(W1|start)*P(W2|W1)*…*P(Wn|Wn-1)&lt;/li&gt;
  &lt;li&gt;当N=3的时候，叫 三元模型（trigram model）：P(S)=P(w1,w2,w3,..,wn)=P(W2|start,W1)*P(W3|W1,W2)*…*P(Wn|Wn-1,Wn-2)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;也许你已经意识到，N是一个超参数，在面临实际问题时，我们应该如何选择依赖词的个数？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;更大的n：对下一个词出现的约束信息更多，具有更大的辨别力；&lt;/li&gt;
  &lt;li&gt;更小的n：在训练语料库中出现的次数更多，具有更可靠的统计信息，具有更高的可靠性。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;理论上，n越大越好，但在经验上看，trigram用的最多，尽管如此，原则上，能用bigram解决，绝不使用trigram。&lt;/p&gt;

&lt;p&gt;对于每一个概率计算我们使用最大似然估计法（Maximum Likelihood Estimate）来做：&lt;/p&gt;

&lt;p&gt;p(w1|wi-1) = count(wi-1, wi) / count(wi-1)&lt;/p&gt;

&lt;p&gt;如给定句子集：&lt;/p&gt;

&lt;p&gt;&amp;lt;s&amp;gt; I am Sam &amp;lt;/s&amp;gt;&lt;/p&gt;

&lt;p&gt;&amp;lt;s&amp;gt; Sam I am &amp;lt;/s&amp;gt;&lt;/p&gt;

&lt;p&gt;&amp;lt;s&amp;gt; I do not like green eggs and ham &amp;lt;/s&amp;gt;&lt;/p&gt;

&lt;p&gt;部分bigram语言模型如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;如何使用N-gram语言模型来进行篇章单元分类？_&quot; 图片1=&quot;&quot; src=&quot;http://img.mukewang.com/59f83efa0001a1d108820096.jpg&quot; alt=&quot;bigram语言模型&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;二-基于n-gram模型的篇章单元分类器&quot;&gt;&lt;strong&gt;二、 基于N-gram模型的篇章单元分类器&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;NLP领域大牛Dan Jurafsky 和 Chirs Manning在他们的斯坦福大学自然语言处理课程中，他们用训练集的9222个句子来统计的部分二元单词分布情况：&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;表1 部分二元单词分布情况表&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;如何使用N-gram语言模型来进行篇章单元分类？_&quot; 图片2=&quot;&quot; src=&quot;http://img.mukewang.com/59f83f06000153fb13360446.jpg&quot; alt=&quot;部分二元单词分布情况表&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;第一行，第二列表示给定前一个词是 “i” 时，当前词为“want”的情况一共出现了827次。据此，我们便可以算得相应的频率分布表如下：&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;表2 频率分布表&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;如何使用N-gram语言模型来进行篇章单元分类？_&quot; 图片3=&quot;&quot; src=&quot;http://img.mukewang.com/59f83f12000164bf13060436.png&quot; alt=&quot;频率分布表&quot; style=&quot;display:block; margin:auto; width:80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;因为我们从表1中知道 “i” 一共出现了2533次，而其后出现 “want” 的情况一共有827次，所以&lt;code class=&quot;highlighter-rouge&quot;&gt;P(want|i)=827/2533≈0.33&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;假设我们现在有一个标记为背景（Background）语料库（由于现在只有两句，所以我们就不画上面的单词分布情况表以及频率分布表了）如下，其中&amp;lt;BG&amp;gt;是句首标记，&amp;lt;/BG&amp;gt;是句尾标记：&lt;/p&gt;

&lt;p&gt;&amp;lt;BG&amp;gt;yes no no no no yes&amp;lt;/BG&amp;gt;&lt;/p&gt;

&lt;p&gt;&amp;lt;BG&amp;gt;no no no yes yes yes no&amp;lt;/BG&amp;gt;&lt;/p&gt;

&lt;p&gt;下面我们的任务是来评估如下这个句子属于“背景”这个篇章单元类别的概率：&lt;/p&gt;

&lt;p&gt;s=&amp;lt;BG&amp;gt;yes no no yes&amp;lt;/BG&amp;gt;（先假设这句话的所属篇章单元类别为“背景”，这样我们可以提取第一个单词和最后一个单词的与“背景”相关的特征）&lt;/p&gt;

&lt;p&gt;我们来演示利用trigram模型来计算概率的结果：&lt;/p&gt;

&lt;p&gt;P(yes|&amp;lt;BG&amp;gt;) = 1/2&lt;/p&gt;

&lt;p&gt;P(no|&amp;lt;BG&amp;gt;,yes) = 1&lt;/p&gt;

&lt;p&gt;P(no|yes,no) = 1/2&lt;/p&gt;

&lt;p&gt;P(yes|no,no) = 2/5&lt;/p&gt;

&lt;p&gt;P(&amp;lt;/BG&amp;gt;|no,yes) = 1/2&lt;/p&gt;

&lt;p&gt;P(s) = 1/2*1*1/2*2/5*1/2 = 0.05，即句子s属于“背景”的概率为0.05。&lt;/p&gt;

&lt;p&gt;为了避免数据溢出、提高性能，通常会使用取log后使用加法运算替代乘法运算。&lt;/p&gt;

&lt;p&gt;log(p1*p2*p3*p4) = log(p1) + log(p2) + log(p3) + log(p4)&lt;/p&gt;

&lt;p&gt;那么我们如何用N-gram来做篇章单元的分类器呢？其实很简单了，只要根据每个类别的语料库训练各自的语言模型，也就是上面的频率分布表，实质上就是每一个篇章单元的类别都有一个概率分布，当新来一个篇章单元的时候，只要根据各自的语言模型，计算出每个语言模型下这个篇章单元的发生概率，篇章单元在哪个模型的概率大，这篇文本就属于哪个类别了。&lt;/p&gt;

&lt;h2 id=&quot;三-工具与数据集&quot;&gt;&lt;strong&gt;三、 工具与数据集&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;推荐开源语言模型工具：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;SRILM（http://www.speech.sri.com/projects/srilm/）&lt;/li&gt;
  &lt;li&gt;IRSTLM（http://hlt.fbk.eu/en/irstlm）&lt;/li&gt;
  &lt;li&gt;MITLM（http://code.google.com/p/mitlm/）&lt;/li&gt;
  &lt;li&gt;BerkeleyLM（http://code.google.com/p/berkeleylm/）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;推荐开源n-gram数据集：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Google Web1T5-gram（http://googleresearch.blogspot.com/2006/08/all-our-n-gram-are-belong-to-you.html）&lt;/li&gt;
  &lt;li&gt;Google Book N-grams（http://books.google.com/ngrams/）&lt;/li&gt;
  &lt;li&gt;Chinese Web 5-gram（http://www.ldc.upenn.edu/Catalog/catalogEntry.jsp?catalogId=LDC2010T06）&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;四-参考文献&quot;&gt;&lt;strong&gt;四、 参考文献&lt;/strong&gt;&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;斯坦福大学自然语言处理第四课“语言模型（Language Modeling）：http://52opencourse.com/111/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%AC%E5%9B%9B%E8%AF%BE-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88language-modeling%EF%BC%89&lt;/li&gt;
  &lt;li&gt;N-gram语言模型文本分类器：http://blog.csdn.net/shiwei1003462571/article/details/43482881&lt;/li&gt;
  &lt;li&gt;Ngram语言模型：https://flystarhe.github.io/2016/08/16/ngram/&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Tue, 31 Oct 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deeplearning/2017/10/31/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8N-gram%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E8%BF%9B%E8%A1%8C%E7%AF%87%E7%AB%A0%E5%8D%95%E5%85%83%E5%88%86%E7%B1%BB.html</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2017/10/31/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8N-gram%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9D%A5%E8%BF%9B%E8%A1%8C%E7%AF%87%E7%AB%A0%E5%8D%95%E5%85%83%E5%88%86%E7%B1%BB.html</guid>
        
        <category>N-gram</category>
        
        <category>篇章单元分类</category>
        
        
        <category>Deeplearning</category>
        
      </item>
    
      <item>
        <title>如何阅读一篇英文论文？</title>
        <description>&lt;p&gt;刚拿到一篇英文论文的时候，很多人可能是通读全文，读到哪里不懂就停下来仔细去抠细节，我开始也这样，但发现效率有点低，下面是我总结的看英文论文的一般步骤。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第一遍（5-10 mins）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;第一遍先大概看下全文的各个大大小小的标题，对于论文的组织结构以及研究方向与重点有一个大概的把握。&lt;/p&gt;

&lt;p&gt;在进行这一遍阅读之前，脑海里先带着这五个问题，在阅读完第一遍之后，你应该要能回答这五个问题：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;文章类型：你现在阅读的论文是什么类型的文章？综述类文章？对现有系统的分析还是测量统计类文章？&lt;/li&gt;
  &lt;li&gt;研究背景：有没有哪些其它的与之相关的论文？基于哪些理论来解决这篇论文的问题？&lt;/li&gt;
  &lt;li&gt;假设正确：论文会有一些假设性的条件，这些假设是否正确合理？&lt;/li&gt;
  &lt;li&gt;论文贡献：论文对其研究方向有哪些主要贡献？&lt;/li&gt;
  &lt;li&gt;逻辑清晰：这篇论文写得好吗？结构清晰吗？&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;方法论：有了这几个疑问之后，第一遍的阅读具体应该怎么来做？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;仔细阅读标题（title）、摘要（abstract）、介绍（introduction）&lt;/li&gt;
  &lt;li&gt;阅读章节的标题，第一遍先忽略其内容&lt;/li&gt;
  &lt;li&gt;阅读总结部分&lt;/li&gt;
  &lt;li&gt;浏览下参考文献目录，试着勾勒出你阅读过的内容的逻辑&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当你读完第一遍后，&lt;strong&gt;你不应该过于陷入细节中&lt;/strong&gt;，你只需要对到底要不要阅读这篇论文以及理解这篇论文需要什么样的知识积累做到心中有数即可。&lt;/p&gt;

&lt;p&gt;理解这一步对我们自己写paper的时候也有很大的帮助，在自己写paper的时候也要思考应该在读者第一遍粗略阅读时给读者提供简洁易懂的信息，不然的话，读者扫了一遍文章发现不能理解文章的大致内容，那你的论文可能就没什么人看了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第二遍（1 hour）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在第二遍的时候应该要仔细阅读论文，但对于一些类似于证明等细节就不必过于纠结。这样的阅读方式有利于我们在脑海里&lt;strong&gt;迅速构建论文的关键点&lt;/strong&gt;，注意在论文的空白处做下标记，哪怕是很简短的词。&lt;/p&gt;

&lt;p&gt;方法论：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;仔细看论文中的图、表以及其他插图。图的坐标轴分别代表着什么，有没有标错，图表等细节也可以在一定程度上体现论文的优劣；&lt;/li&gt;
  &lt;li&gt;在阅读论文的过程中标记那些还未阅读的参考文献，以便进一步阅读来了解论文的背景。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;通过第二遍的阅读，你应该能够掌握论文的内容，可以总结论文的主旨和论据。有时候你读完第二遍的时候发现对论文还是一知半解，这可能是因为论文中提到的技术与理论你还没掌握，那么你有三个选择：第一是放弃这篇论文，祈祷上天这对你未来学业与职业影响不大（上天听不听得到就不在这里的讨论范围啦[笑哭]）；第二是先去积累论文中那些你还未掌握的技术与理论，然后再回到论文来；第三是你也可以勇往直前进行第三遍阅读。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第三遍（小白4-5 hour，老司机1 hour）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如果你认为这篇论文很有用且你还未完全理解这篇论文，那么建议你再读一遍。第三遍的关键是你需要把自己作为本文的作者，作出与作者相同的假设，然后&lt;strong&gt;重新构建论文&lt;/strong&gt;。通过将这种重构与实际文章进行比较，你可以轻松地识别论文的创新，也可以轻松识别其隐藏的缺陷。在这一遍中，你通过这种重构的方式会更多的关注到论文的细节部分，你应该尝试着去明白为什么要作这些假设，为什么要用这种理论或技术，这对你未来这个方向的研究工作打下了良好的基础。&lt;/p&gt;

&lt;p&gt;在第三遍阅读后，你应该再重新根据你的标记以及记忆来重新审视这篇论文，总结出其优缺点，明确文章中隐含的假设，以及实验或分析技术的潜在问题。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如何做文献搜索？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;第一，利用&lt;strong&gt;Google学术、百度学术或中国知网&lt;/strong&gt;等搜索工具搜索你要想领域的文章，建议是先看些综述类的文章，这样你能直观的对研究方向的发展现状有一个大概的了解，对相关的理论也有一定的理解。如果你英文够好可以直接看英文论文，如果功力还不够，建议先找中文论文看看，对一些专有名词有一定积累后再看国外的文献会轻松些。&lt;/p&gt;

&lt;p&gt;第二，在一些论文中的参考书目中找到&lt;strong&gt;共同引用和重复的作者姓名&lt;/strong&gt;。在每个领域都会有一些核心的papers和researchers，直接在网上下载那些核心papers，在上述论文搜索工具中搜索researchers的姓名，看看他们最近在研究什么，这样有利于你掌握这个领域的最新研究成果。&lt;/p&gt;

&lt;p&gt;第三，访问那些顶级会议的网站，并查看它们最近的会议记录。寻找和你研究方向相关的高质量论文，这些论文以及之前找到的论文&lt;strong&gt;构成了你文献搜索的第一个论文集&lt;/strong&gt;。对每篇论文都读两遍，如果它们都引用了你之前没有找到的关键论文，那么把它并入到你的论文集中，然后再根据新加入的论文来更新你的论文集。&lt;/p&gt;
</description>
        <pubDate>Sun, 29 Oct 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/life/2017/10/29/%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E4%B8%80%E7%AF%87%E8%8B%B1%E6%96%87%E8%AE%BA%E6%96%87.html</link>
        <guid isPermaLink="true">http://localhost:4000/life/2017/10/29/%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E4%B8%80%E7%AF%87%E8%8B%B1%E6%96%87%E8%AE%BA%E6%96%87.html</guid>
        
        <category>阅读</category>
        
        <category>英文论文</category>
        
        
        <category>Life</category>
        
      </item>
    
      <item>
        <title>论文笔记-识别议论文中论证性篇章结构</title>
        <description>&lt;p&gt;现在看这种类型的英文论文开始有点感觉了，大部分术语积累的差不多之后看论文确实相对刚开始看要快一些，一遍过下来也掌握的信息也比较多，如果你和我一样都在看英文论文的道路上挣扎，建议你看下这篇帖子的内容，&lt;a href=&quot;https://www.zhihu.com/question/27375221&quot;&gt;如何看懂英文文献？&lt;/a&gt; 还是有些帮助的，也欢迎你留言，我们一起交流，共同进步。&lt;/p&gt;

&lt;p&gt;本文《Identifying Argumentative Discourse Structures in Persuasive Essays》主要研究的是议论文中论证部分的篇章结构分析，研究工作分两部分，第一部分为议论文中论证性篇章结构类别识别，第二部分为在第一部分的论证类别识别的基础上对论证关系进行研究。论文将数据集中的文章句子的类别分为：&lt;strong&gt;主论点（major claim）、分论点（claim）、论据（premise）以及非论证部分（none）&lt;/strong&gt;，在主论点、分论点以及论据之间有两种论证关系：支持（support）与反对（attack）。数据集来自Stab和Gurevych在2014年编译的议论文语料库。表1表示的是语料库中各种类别的分布情况，语料库包含90个主论点（基本上是每篇文章包含一个主论点），429个分论点和1033个论据。&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;表1 数据集中类别分布情况&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;论文笔记-识别议论文中论证性篇章结构_&quot; 图片1=&quot;&quot; src=&quot;http://img.mukewang.com/59ef275700017f2b07600078.png&quot; alt=&quot;数据集中类别分布情况&quot; style=&quot;display:block; margin:auto&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;1-篇章结构类别识别&quot;&gt;&lt;strong&gt;1 篇章结构类别识别&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;论文使用Weka数据挖掘软件中的分类器进行分类，使用DKPro框架中的Stanford POS-Tagger和Parser进行数据预处理，使用使DKPro-TC文本分类框架来提取论文句子的特征。&lt;/p&gt;

&lt;h2 id=&quot;11-特征选择&quot;&gt;&lt;strong&gt;1.1 特征选择&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&quot;111-结构特征&quot;&gt;1.1.1 结构特征&lt;/h3&gt;

&lt;p&gt;这部分主要提取的是篇章单元的词统计特征、位置特征以及标点符号特征。&lt;/p&gt;

&lt;p&gt;词统计特征，Biran and Rambow在2011年发现论据的平均长度比其他句子要长，所以将篇章单元所覆盖句子中单词的数量加入到特征集中，除此之外，特征集还包含：当前句子的前一个和后一个篇章单元所包含词的数量，篇章单元的覆盖句子的词占篇章单元单词的比例。&lt;/p&gt;

&lt;p&gt;位置特征，四个Boolean特征：篇章单元是否出现在文章的介绍（introduction）或结论（conclusion）中，是否出现在某一段的第一句或最后一句；一个数值特征：篇章单元中所覆盖句子在文章中的位置，主论点经常出现在文章的介绍（introduction）或结论（conclusion）中，段落也经常是以论点作为开始或结束。本论文认为这个特征能够很好的预测（主/分）论点。&lt;/p&gt;

&lt;p&gt;标点符号特征：篇章单元所覆盖句子中的标点符号数量；当前句子的前一个和后一个篇章单元的标点符号的数量；句子是否以问号结束。&lt;/p&gt;

&lt;h3 id=&quot;112-词汇特征&quot;&gt;1.1.2 词汇特征&lt;/h3&gt;

&lt;p&gt;最小语义粒度：在中文中，最小语义粒度为字，但是一个单字所表示的语义信息太少，一般的，大多都以词作为最基本的语素，在实际的交流中也正是如此。但是用词作为最小的语义粒度也有一个问题，就是词和词之间的关系随着分词而丢失了，其实这部分信息非常重要。为了减小这种隐性的语义损失，有人提出了N-gram模型。N-gram模型基于这样一种假设，第n个词的出现只与前面N-1个词相关，而与其它任何词都不相关。简单来说，unigram模型对应的最小语素就是单字，bigram模型是二字串，举例说明：“我爱北京天安门”的bigram表示形式就是“我爱 爱北 北京 京天 天安 安门”，以此类推。由于N-gram存在致命的缺陷——产生的结果过于稀疏，假设正常分词的词表中有1000个词，如果是bigram那么可能的N-gram就有1000000个，如果是trigram，那么可能的N-gram就有1000000000个，其维度增长是指数级的。一般在使用中只使用二字串或三字串作为最小的语义粒度，并且需要其他处理来缩减维度，减少计算资源的消耗。本文定义了长度为1-3的n-gram作为一个布尔特征，用n-gram来判断是否包含那些某些篇章结构类别的指示词。&lt;/p&gt;

&lt;p&gt;这部分的特征主要使用&lt;code class=&quot;highlighter-rouge&quot;&gt;Stanford POS-Tagger&lt;/code&gt;来进行预处理阶段的词性标注，词汇特征主要包括：动词（verbs）、副词（adverbs）和情态动词（modals），常用的技术有：词类区分（POS: Part-of-Speech tagging）和命名实体识别（NE: named entity tagging）。&lt;/p&gt;

&lt;p&gt;动词和副词在识别篇章单元上有重要的作用，比如，某些动词（believe、think、agree等）标志着一个主论点的出现，某些副词（also、often、really等）就可能是论据的表达方式，某些情态动词（should、could等）通常用来预示分论点的出现。&lt;/p&gt;

&lt;h3 id=&quot;113-句法特征&quot;&gt;1.1.3 句法特征&lt;/h3&gt;

&lt;p&gt;这部分主要提取的特征有：&lt;/p&gt;

&lt;p&gt;句子的子从句数量，分析树（parse tree）的深度，分析树中的产生式（production rules）是否出现在篇章单元的子树中。NP、VP、PP是名词、动词、介词短语（短语级别）；N、V、P分别是名词、动词、介词。&lt;/p&gt;

&lt;p&gt;每个篇章单元中句子的主要动词的时态，论据一般使用过去时，而论点一般使用现在时。&lt;/p&gt;

&lt;h3 id=&quot;114-指示词特征&quot;&gt;1.1.4 指示词特征&lt;/h3&gt;

&lt;p&gt;论点经常有这些指示词：therefore、thus、consequently等引出，然而论据可能包含这些词：because、reason、furthermore等。本论文使用&lt;code class=&quot;highlighter-rouge&quot;&gt;Penn Discourse Treebank 2.0 Annotation Manual&lt;/code&gt;来收集类似上面指示词，剔除掉与识别论证结构无关的指示词，最终收集到55个指示词。将这些作为一个布尔特征集来代表这55个指示词是否在一个篇章单位中。&lt;/p&gt;

&lt;p&gt;除此之外还定义了5个Boolean特征来表示是否包含这五个第一人称：I，me，my，mine，myself。本论文认为这些特征与主论点有很强的关联性，因为这些词的出现常常表达了作者的个人立场。&lt;/p&gt;

&lt;h3 id=&quot;115-上下文特征&quot;&gt;1.1.5 上下文特征&lt;/h3&gt;

&lt;p&gt;论文认为一个论点的出现，后面往往跟着有论据。所以会从篇章单位的上下句子提取相关特征（标点符号的数量，单词数，子从句数以及一个代表是否存在情态动词的布尔特征）来表述上下文特征。&lt;/p&gt;

&lt;h2 id=&quot;12-篇章单元分类&quot;&gt;&lt;strong&gt;1.2 篇章单元分类&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;本论文使用SVM、贝叶斯、C4.5决策树以及随机森林四种分类方法，使用信息增益（Information Gain）来判断某些特征能够为分类系统带来多少信息，带来的信息越多，该特征越重要，也就是对一个特征而言，分类系统有它和没它时信息量将发生变化，而前后信息量的差值就是这个特征给系统带来的信息量，信息量向正方向增长越大则表明该特征越能影响分类系统的效果。以信息增益为依据选取前100个特征。结果表明，使用SVM分类方法效果最好，虽然贝叶斯方法的准确度比SVM的低，但效率更高。SVM分类结果对比表如表2所示：&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;表2 SVM分类结果对比表&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;论文笔记-识别议论文中论证性篇章结构_&quot; 图片2=&quot;&quot; src=&quot;http://img.mukewang.com/59ef278400012b1906660340.png&quot; alt=&quot;SVM分类结果对比表&quot; style=&quot;display:block; margin:auto&quot; /&gt;&lt;/p&gt;

&lt;p&gt;不同特征对篇章单元的识别结果的影响如表3所示：&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;表3 不同特征对篇章单元的识别结果影响对比表&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;论文笔记-识别议论文中论证性篇章结构_&quot; 图片3=&quot;&quot; src=&quot;http://img.mukewang.com/59ef27a500010cf807580242.png&quot; alt=&quot;不同特征对篇章单元的识别结果影响对比表&quot; style=&quot;display:block; margin:auto&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;13-结果分析&quot;&gt;&lt;strong&gt;1.3 结果分析&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;有趣的是指示词特征对识别非论证部分（none）并没有用，但在识别主论点（major claim）、分论点（claim）、论据（premise）上表现良好，一个主要的原因可能是指示词并不是对篇章单元的每个句子产生作用，有些指示词具有一词多义，比如since，可能表示时间的“自从”，也可能表示的是因果的“因为”。&lt;/p&gt;

&lt;p&gt;分类系统对识别论证部分和非论证部分有很好的效果，但在识别主论点（major claims）与分论点（claims）上的效果一般，结果矩阵如表4所示：&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;表4 结果分析矩阵&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;论文笔记-识别议论文中论证性篇章结构_&quot; 图片4=&quot;&quot; src=&quot;http://img.mukewang.com/59ef27bf00018ade05340218.png&quot; alt=&quot;结果分析矩阵&quot; style=&quot;display:block; margin:auto&quot; /&gt;&lt;/p&gt;

&lt;p&gt;MC=Major Claim，Cl=Claim，Pr=Premise，No=None，横轴表示实际类别，纵轴表示分类预测的类别。&lt;/p&gt;

&lt;p&gt;从上面的结果分析矩阵可以得出，总共有193个分论点（Claims）被错误分类为论据（Premise）。论文对这个现象的解释是：许多的分论点出现在第一段，且含有first(ly)、second(ly)等指示单词，这可能表示的是分论点对主论点的支持或解释，但往往会被分类器认为是主论点的论据。为解决这个问题，论文作者提出了一个可能的解决方法，即定义指示单词的位置特征或消除指示单词特征作用。&lt;/p&gt;

&lt;p&gt;有些包含一个完整的句子且不包含指示单词的分论点也可能被错误分类，比如，“Competition helps in improvement and evolution”作为一个分论点可能被错误分类为论据。实际上，如果不知道作者的写作含义，可能连人也分不清是什么类别，解决这类问题的方法是，特征集中加入更多复杂的上下文特征。&lt;/p&gt;

&lt;h1 id=&quot;2-论证关系识别&quot;&gt;&lt;strong&gt;2 论证关系识别&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;21-什么是论证关系&quot;&gt;&lt;strong&gt;2.1 什么是论证关系？&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;“(1) Museums and art galleries provide a better understanding about arts than Internet. (2) In most museums and art galleries, detailed descriptions in terms of the background, history and author are provided. (3) Seeing an artwork online is not the same as watching it with our own eyes, as (4) the picture online does not show the texture or three-dimensional structure of the art, which is important to study.”
在上面这段英文中，加粗部分（1）为一个论点（Claims），斜体部分（2，3，4）为论据（Premise），论据（2）和（3）支持/加强论点（1），而论据（4）支持/加强论据（3），所以这段英文中有3对支持/加强（support）论证关系（2，1）、（3，1）和（4，3）。&lt;/p&gt;

&lt;p&gt;本论文将论证关系分为Support和Non-support，且不考虑分论点与主论点之间的论证关系，因为这是唯一个跨越段落的论证关系，在6330对（pair）论证关系中，Support和Non-support分布情况如下表所示：&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;表5 Support和Non-support分布情况表&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;论文笔记-识别议论文中论证性篇章结构_&quot; 图片5=&quot;&quot; src=&quot;http://img.mukewang.com/59ef27e20001369a04640076.png&quot; alt=&quot;Support和Non-support分布情况表&quot; style=&quot;display:block; margin:auto&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;22-特征选择&quot;&gt;&lt;strong&gt;2.2 特征选择&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&quot;221-结构特征&quot;&gt;2.2.1 结构特征&lt;/h3&gt;

&lt;p&gt;三个基于词统计特征：源单元的词数量；目标单元的词数量；源单元和目标单元的词数量绝对差；
三个基于标点符号统计特征：源单元的标点符号数量；目标单元的标点符号数量；源单元和目标单元的标点符号数量绝对差；
九个基于位置的结构特征：源单元与目标单元所覆盖句子在文章中的位置（2）；源单元与目标单元所覆盖句子是否处于段落的开始或结尾（4）；目标单元是否出现在源单元之前（1）；源单元与目标单元所覆盖句子之间的距离（1）；源单元与目标单元是否在同一个句子中（1）。&lt;/p&gt;

&lt;h3 id=&quot;222-词汇特征&quot;&gt;2.2.2 词汇特征&lt;/h3&gt;

&lt;p&gt;词汇特征主要包括单词对（word pairs）、第一个单词、情态动词、两个篇章单元相同术语的数量。论文认为篇章单元的第一个单词包含重要的信息。&lt;/p&gt;

&lt;h3 id=&quot;223-句法特征&quot;&gt;2.2.3 句法特征&lt;/h3&gt;

&lt;p&gt;同篇章结构类别识别的句法特征。&lt;/p&gt;

&lt;h3 id=&quot;224-指示词特征&quot;&gt;2.2.4 指示词特征&lt;/h3&gt;

&lt;p&gt;同篇章结构类别识别的指示词特征。&lt;/p&gt;

&lt;h3 id=&quot;225-篇章单元类型特征&quot;&gt;2.2.5 篇章单元类型特征&lt;/h3&gt;

&lt;p&gt;篇章单元类型（major claim，claim，premise）特征对两个篇章单元的论证关系识别有重要指示作用。&lt;/p&gt;

&lt;h2 id=&quot;23-分类结果分析&quot;&gt;&lt;strong&gt;2.3 分类结果分析&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;同样是SVM的分类效果最好。&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;表6 论证关系分类效果表&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;论文笔记-识别议论文中论证性篇章结构_&quot; 图片6=&quot;&quot; src=&quot;http://img.mukewang.com/59ef280e0001201d06660266.png&quot; alt=&quot;论证关系分类效果表&quot; style=&quot;display:block; margin:auto&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;表6 论证关系分类效果表&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;论文笔记-识别议论文中论证性篇章结构_&quot; 图片7=&quot;&quot; src=&quot;http://img.mukewang.com/59ef28200001c04d06140224.png&quot; alt=&quot;论证关系分类效果表&quot; style=&quot;display:block; margin:auto&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 24 Oct 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deeplearning/2017/10/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E8%AF%86%E5%88%AB%E8%AE%AE%E8%AE%BA%E6%96%87%E4%B8%AD%E8%AE%BA%E8%AF%81%E6%80%A7%E7%AF%87%E7%AB%A0%E7%BB%93%E6%9E%84.html</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2017/10/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E8%AF%86%E5%88%AB%E8%AE%AE%E8%AE%BA%E6%96%87%E4%B8%AD%E8%AE%BA%E8%AF%81%E6%80%A7%E7%AF%87%E7%AB%A0%E7%BB%93%E6%9E%84.html</guid>
        
        <category>论文笔记</category>
        
        <category>议论文</category>
        
        <category>论证性</category>
        
        <category>篇章结构识别</category>
        
        
        <category>Deeplearning</category>
        
      </item>
    
      <item>
        <title>论文笔记-基于全局和局部内聚的学生论文中的篇章结构识别</title>
        <description>&lt;p&gt;找技术路线很头大啊，明天还要做一个技术分享（压力山大）…这篇论文《Discourse Element Identification in Student Essays based on Global and Local Cohesion》的训练集是中国学生写的中文文章，虽然对我研究的托福雅思的英文议论文不同，但我想思路和技术方法可能是有一定借鉴作用的。&lt;/p&gt;

&lt;p&gt;论文主要是通过探索整篇文章中句子与句子之间关系的内聚性来分析文章的篇章结构。通过这种方式能更好的识别Thesis、Main idea和Conclusion标签类别。论文将篇章结构的识别作为一个分类问题来看待，文章中的每个句子使用分类器（朴树贝叶斯、决策树和SVM等）独立分类，论文主要使用SVM模型和基于线性链的条件随机场模型（CRF）来对句子进行篇章结构标签分类。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1 基本特征：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;位置特征&lt;/li&gt;
  &lt;li&gt;指示单词特征：in my opinion，in conclusion，should，hope等&lt;/li&gt;
  &lt;li&gt;非文本特征：单词的长度，段落句子个数，标点符号特征等&lt;/li&gt;
  &lt;li&gt;主题和提示信息特征：对每个句子提取与文章标题和提示信息的余弦相似性的特征&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2 内聚链&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这里主要挖掘关系与词汇的内聚特征，主要构建的是在文章所有句子范围内单词的身份链（identity chains）和词汇链（lexical chains）。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;身份链（identity chains）：通过挖掘每个句子中的人物名称，第一、二、三人称等特征，将同属一类身份的部分组成一个身份链；&lt;/li&gt;
  &lt;li&gt;词汇链（lexical chains）：通过挖掘每个句子中不同词汇的重复，单词的同义表达等特征，将同属一类单词的部分组成一个词汇链。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;3 全局链（global chains）与局部链（local chains）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;基于第二部分的内聚链来构造一个句子链（Sentence Chains），一个句子链包含那些相似的身份链和词汇链。&lt;/p&gt;

&lt;p&gt;局部链是那些只包含单一子主题的句子链，全局链那些只包含多个子主题的句子链。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;基于全局和局部内聚的学生论文中的篇章结构识别_&quot; 图片1=&quot;&quot; src=&quot;http://img.mukewang.com/59eb38b30001999f09180520.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图1 训练样本中全局链与局部链图&lt;/p&gt;

&lt;p&gt;网格中的每个实体节点表示一个句子中包含来自内聚链的单词。
文章假设一个段落就是一个子主题，所以将那些跨越三个段落的句子链分类为全局链，只在一个段落中的句子链为局部链。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4 基于句子链的内聚特征：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;链类型特征：global-identity, local-identity, global-lexical 和 local-lexical chains&lt;/li&gt;
  &lt;li&gt;全局标题特征：全局链中的某个句子如果包含题目中的关键字，那么可能将这条句子分类为thesis标签&lt;/li&gt;
  &lt;li&gt;相互作用特征：如果两个句子链中有超过1个共同句子，则认为两个句子链相互作用&lt;/li&gt;
  &lt;li&gt;结构特征：句子链覆盖句子或段落的最大数和平均数&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用条件随机场（CRF）模型对三个不同主题的六种篇章结构分类效果如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;基于全局和局部内聚的学生论文中的篇章结构识别_&quot; 图片2=&quot;&quot; src=&quot;http://img.mukewang.com/59eb38f50001cbbf18600658.png&quot; alt=&quot;图片描述&quot; style=&quot;display:block; margin:auto; width:100%&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图2 分类效果图&lt;/p&gt;

&lt;p&gt;我们可以发现添加了内聚特征的模型可以明显提升识别Main idea 和 Thesis类别标签的精确度。&lt;/p&gt;
</description>
        <pubDate>Thu, 19 Oct 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deeplearning/2017/10/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%9F%BA%E4%BA%8E%E5%85%A8%E5%B1%80%E5%92%8C%E5%B1%80%E9%83%A8%E5%86%85%E8%81%9A%E7%9A%84%E5%AD%A6%E7%94%9F%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E7%AF%87%E7%AB%A0%E7%BB%93%E6%9E%84%E8%AF%86%E5%88%AB.html</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2017/10/19/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%9F%BA%E4%BA%8E%E5%85%A8%E5%B1%80%E5%92%8C%E5%B1%80%E9%83%A8%E5%86%85%E8%81%9A%E7%9A%84%E5%AD%A6%E7%94%9F%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E7%AF%87%E7%AB%A0%E7%BB%93%E6%9E%84%E8%AF%86%E5%88%AB.html</guid>
        
        <category>论文笔记</category>
        
        <category>全局</category>
        
        <category>局部</category>
        
        <category>篇章结构识别</category>
        
        
        <category>Deeplearning</category>
        
      </item>
    
      <item>
        <title>论文笔记-在学生作文中自动识别篇章结构</title>
        <description>&lt;p&gt;最近在研究基于自然语言处理的作文自动评分系统，现在对其中一篇与篇章结构分析相关的论文：《Finding the WRITE stuff： Automatic identification of discourse structure in student essays》作一个大概总结。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1 为什么要研究篇章结构？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;现在国内外都有很多自动评分系统，这些自动评分系统大多从拼写检查、语法检查、内容分析等来帮助学生提高写作质量，学生通过这些类型的自动评分系统的反馈来改进他们写作的某些方面：语法、拼写等。这些系统将会继续受到学生的重视，因为在这些方面的改善对于学生写出高质量文章依然是至关重要的。&lt;/p&gt;

&lt;p&gt;随着学生深入学习英文写作，便需要开始思考文章的篇章结构。不同类型的作文一般具有不同类型的篇章结构，比如信件、议论文等，它们拥有不同的篇章结构且篇章结构的优良在很大程度上影响作文的评分。分析篇章结构的自动评分系统为学生提供作文篇章结构的反馈，它使得学生对作文的篇章结构有了全面的分析，例如，如果系统反馈出学生的作文没有结论部分，那么学生可以在作文的结论部分多下功夫。这种类似于传统教师的自动化反馈可以帮助学生提高他们在篇章结构的组织和把控能力。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2 什么是篇章结构？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;就议论文而言，现在普遍将篇章结构分为8类：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Title 文章标题&lt;/li&gt;
  &lt;li&gt;Introduction 介绍文章背景&lt;/li&gt;
  &lt;li&gt;Prompt 主题总述或汇总提示&lt;/li&gt;
  &lt;li&gt;Thesis 阐述了作者对他/她正在争论的问题的主要矛盾&lt;/li&gt;
  &lt;li&gt;Main idea 提出与文章相关的主要思想/论点&lt;/li&gt;
  &lt;li&gt;Supporting idea 提供证据来解释或支持文章的主要思想&lt;/li&gt;
  &lt;li&gt;Conclusion 总结全文的主要思想&lt;/li&gt;
  &lt;li&gt;Other/Irrelevant 不适用于上述要素，也不构成任何有意义的贡献&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img title=&quot;论文笔记-在学生作文中自动识别篇章结构&quot; 图片1=&quot;&quot; src=&quot;http://img.mukewang.com/59e821a300018fef06730510.png&quot; alt=&quot;一篇标记好的议论文作文&quot; style=&quot;display:block; margin:auto&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图1 一篇标记好的议论文作文&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3 如何分析篇章结构？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;篇章结构的研究分析可分为微观和宏观两个角度。微观篇章结构指的是篇章中一个句子内部的结构或两个连续的句子之间的结构，宏观篇章结构是指更高层次的结构，表现为句群、段落之间的结构。&lt;/p&gt;

&lt;p&gt;微观角度的篇章结构理论主要包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;浅层衔接理论&lt;/li&gt;
  &lt;li&gt;Hobbs模型&lt;/li&gt;
  &lt;li&gt;修辞结构理论（RST）&lt;/li&gt;
  &lt;li&gt;宾州篇章树库理论（PDTB）&lt;/li&gt;
  &lt;li&gt;意图结构理论&lt;/li&gt;
  &lt;li&gt;信息结构理论&lt;/li&gt;
  &lt;li&gt;基于连接依存数&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;宏观角度的篇章结构理论则相对较少，主要包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;篇章模式&lt;/li&gt;
  &lt;li&gt;超主位理论&lt;/li&gt;
  &lt;li&gt;篇章宏观结构理论&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;3.1 基于决策的篇章结构分析方法&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;核心思想是：使用一系列特征提取的算法提取文章中每个句子的与篇章结构相关的特征，将这些特征向量输入C5.0（一种决策树的机器学习算法）中来对句子所属类别进行分类。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.1.1 基于RST提取修辞特征和核心与边界状态&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;按照修辞结构理论（RST），可以将任何一篇议论文按照图2的形式构建RST篇章树。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;论文笔记-在学生作文中自动识别篇章结构_&quot; 图片2=&quot;&quot; src=&quot;http://img.mukewang.com/59e821f70001070610190341.png&quot; alt=&quot;RST篇章树&quot; style=&quot;display:block; margin:auto&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图2 RST篇章树&lt;/p&gt;

&lt;p&gt;树的叶子节点表示文章中的篇章单位（Discourse Unit），在连接篇章单位的弧线上标明文本间的修辞关系；箭头指向的篇章单位在该关系中为核心（nucleus），否则为边界（satellite）；水平线表示文本范围（span）；垂直线对应的文本范围为该修辞关系的“核心”。比如图2中A和B两个篇章单位的修辞关系是：B是A的背景描述，A在“背景”修辞关系中为“核心”，B为“边界”。&lt;/p&gt;

&lt;p&gt;修辞特征可以反映两个篇章单位之间的语义、所包含的含义以及文本之间的关系，一般来说这种由不同篇章单位以及它们之间的修辞特征关系构成的修辞结构树可以由Marcu的&lt;code class=&quot;highlighter-rouge&quot;&gt;cue-phrase-based discourse parser&lt;/code&gt;来构建。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.1.2 提取核心单词、术语等词汇特征&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;提取句子中核心单词或术语的特征，比如A，becauseB，because表示对A这种结果的一种增强；First的出现可能意味着一个新的论点或论据的出现。“opinion”,“feel”相对“Should”, “might” ,“agree” ,“disagree” 与 “I”连接的时候更有可能与Thesis相关。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.1.3 提取句法结构与语法特征&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;五种句法结构与语法：主从复合句、补语从句、不定式分句、关系从句以及助动词。一个不定式短语出现在一个句子或一个段落的开始往往标志一个新论点（Main idea）的出现。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.1.4 基于位置的特征&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这种方法制定了一系列句子位置对应篇章结构类别的规则：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Introductory：作文的第一句；&lt;/li&gt;
  &lt;li&gt;Thesis：第一段中除第一句以外的所有文本；&lt;/li&gt;
  &lt;li&gt;Main ideas：所有正文段落的第一句；&lt;/li&gt;
  &lt;li&gt;Supporting ideas：正文段落中除第一句以外的所有文本；&lt;/li&gt;
  &lt;li&gt;Conclusion：最后一段中的所有文本。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;3.1.5 基于标点符号的特征&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;句号、问号、感叹号等。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.2 基于概率的篇章结构分析方法&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;核心思想：基于概率的篇章结构分析方法希望给一篇作文中越可能的标签序列分配更高的概率，越不可能的标签序列分配越低的概率。&lt;/p&gt;

&lt;p&gt;步骤一：有限状态机使用极大似然估计技术从训练数据中估计每个句子的标签概率，比如，如果句子中包含“conclusion”单词时，这个句子是Conclusion标签的概率要比Introduction标签的概率大；&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;论文笔记-在学生作文中自动识别篇章结构_&quot; 图片3=&quot;&quot; src=&quot;http://img.mukewang.com/59e8222b0001993b06720307.png&quot; alt=&quot;正确标记的训练数据的标签序列&quot; style=&quot;display:block; margin:auto&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图3 正确标记的训练数据的标签序列&lt;/p&gt;

&lt;p&gt;步骤二：接下来我们需要为由步骤一组成的标签序列评估其概率，选择最有可能的一组标签序列。局部语言模型评估某个标签序列的概率公式为：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;论文笔记-在学生作文中自动识别篇章结构_&quot; 图片4=&quot;&quot; src=&quot;http://img.mukewang.com/59e822520001be8008620048.png&quot; alt=&quot;评估某个标签序列的概率公式&quot; style=&quot;display:block; margin:auto&quot; /&gt;&lt;/p&gt;

&lt;p&gt;假设每个句子标签的概率都依赖其前两个句子标签，&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;论文笔记-在学生作文中自动识别篇章结构_&quot; 图片5=&quot;&quot; src=&quot;http://img.mukewang.com/59e8225f00011d4107260064.png&quot; alt=&quot;每个句子标签的概率&quot; style=&quot;display:block; margin:auto&quot; /&gt;&lt;/p&gt;

&lt;p&gt;局部语言模型无法捕捉全局特征，预测的标签序列缺乏全局连贯性，比如：96%的Thesis句出现在一个单独的段落中，一个总结句可能出现在Thesis后的n个Main idea/Supporting idea语句块之后，如果n&amp;gt;2，这种可能性高达88%。使用EM算法来训练全局语言模型捕捉这种全局特征。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;论文笔记-在学生作文中自动识别篇章结构_&quot; 图片6=&quot;&quot; src=&quot;http://img.mukewang.com/59e8226d0001e76c06730296.png&quot; alt=&quot;语言模型&quot; style=&quot;display:block; margin:auto&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;图4 语言模型&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;L表示标签序列，W表示其对应的单词序列，P(L)表示标签序列L的概率，而P(W&lt;/td&gt;
      &lt;td&gt;L)表示序列L产生序列W的概率&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;基于概率的篇章结构分析方法以文章中每个句子的单词序列W作为输入，使用极大似然估计技术和EM算法来计算出最大概率的标签序列L。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;论文笔记-在学生作文中自动识别篇章结构_&quot; 图片7=&quot;&quot; src=&quot;http://img.mukewang.com/59e8228b0001819002940032.png&quot; alt=&quot;最大概率的标签序列L&quot; style=&quot;display:block; margin:auto&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;P(L)表示标签序列L的概率，而P(W&lt;/td&gt;
      &lt;td&gt;L)表示标签序列L产生序列W的概率。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
</description>
        <pubDate>Mon, 16 Oct 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deeplearning/2017/10/16/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%9C%A8%E5%AD%A6%E7%94%9F%E4%BD%9C%E6%96%87%E4%B8%AD%E8%87%AA%E5%8A%A8%E8%AF%86%E5%88%AB%E7%AF%87%E7%AB%A0%E7%BB%93%E6%9E%84.html</link>
        <guid isPermaLink="true">http://localhost:4000/deeplearning/2017/10/16/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-%E5%9C%A8%E5%AD%A6%E7%94%9F%E4%BD%9C%E6%96%87%E4%B8%AD%E8%87%AA%E5%8A%A8%E8%AF%86%E5%88%AB%E7%AF%87%E7%AB%A0%E7%BB%93%E6%9E%84.html</guid>
        
        <category>论文笔记</category>
        
        <category>作文自动评分系统</category>
        
        <category>篇章结构</category>
        
        
        <category>Deeplearning</category>
        
      </item>
    
      <item>
        <title>死磕数据库调优-数据库优化的几点思考</title>
        <description>&lt;p&gt;上篇我们讲了下在数据库表设计时如何根据业务需求来选取最适合自己的字段属性设计，今天我们来聊聊当你拿到一句sql语句，你会从哪些方面来优化它。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;方面一、in、exists还是join&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;使用场景：我们要查询整个湖北省所有的水土流失信息，显然全国的水土流失表中的数据比湖北省城市数要大很多，假设全国的水土流失表有100万条数据，湖北省总共有80个市（包括直辖市、县级市和市辖区等）。&lt;/p&gt;

&lt;p&gt;问题：那么对于这种使用场景，sql中使用in还是exists？&lt;/p&gt;

&lt;p&gt;测试：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;1、select * from shuituInfo where cid in(select id from city );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2、select * from shuituInfo where exists(select id from city where shuituInfo.cid= city.id);&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;测试下来，在表结构一样的情况下，我们发现1比2的效率要高很多。&lt;/p&gt;

&lt;p&gt;分析：&lt;/p&gt;

&lt;p&gt;如果两个表中一个较小，一个较大，则子查询表数据大的用exists，子查询表数据小的用in。因为in会使用城市表中的id去到水土流失信息表中直接匹配所需要的行，而exists是根据匹配项去判断是或者否，然后根据是否返回结果。当子查询的表数据量大而主表数据量小，用exists判断，效率就会高，而当子查询的表数据量小而主表数据量大的时候，直接匹配你需要的值则更快。&lt;/p&gt;

&lt;p&gt;主表有100万行，子查询里面有80条数据，那么exists会把100万行在子查询里面进行匹配，匹配上了就显示，匹配不上就不显示，所以需要判断100万次，而in则会使用子查询的80条记录直接匹配主表中的100万行数据，in的效率通常会更高，但是如果反过来，主表80条记录，子查询里面有100万行，exists只进行80次判断，而in会用100万个数据去匹配这80条记录，所以比exists更快。所以说in的效率取决于子表的数据量大小，而exists的效率取决于主表的数据量大小。如果字表的数据量小，使用in时只需要从主表中检索符合字表的数据就好了；如果主表的数据量小，使用exists只需要判断主表中的数据是否满足子查询。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;3、select s.* from shuituInfo s, city c where s.cid = c.id;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;其实我们使用隐式(implicit) inner join的效率会更高一点：&lt;/p&gt;

&lt;p&gt;EXISTS &amp;lt;= IN &amp;lt;= JOIN&lt;/p&gt;

&lt;p&gt;NOT EXISTS &amp;lt;= NOT IN &amp;lt;= LEFT JOIN&lt;/p&gt;

&lt;p&gt;所以在同等情况下，尽量避免子查询，而用join来实现。个人理解是，join之所以更有效率一些，是因为MySQL不需要在内存中创建临时表来完成查询工作。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;方面二、union 和 union all&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在一些应用场景下，我们常需要使用union来写一些去重的sql，但union会将各查询子集的记录做比较并去除相同的记录，所以比起单纯的union all（不排除重复的值）来说通常速度都会慢上许多。一般来说，如果我们确定在某些应用场景下合并子集后不会出现重复值那么使用union all。&lt;/p&gt;

&lt;p&gt;对于索引列最好使用union all，因复杂的查询【包含运算等】将使or、in放弃索引而全表扫描。&lt;/p&gt;

&lt;p&gt;对于只有非索引字段最好使用or或者in，因为非索引字段本来要全表扫描而union all会成倍增加表扫描的次数。见文献-MySQL中使用or、in与union all在查询命令下的效率对比&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;方面三、常见的优化手段&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;1、应该尽量把字段设置为&lt;code class=&quot;highlighter-rouge&quot;&gt;not null&lt;/code&gt;，这样在将来执行查询的时候，数据库不用去比较&lt;code class=&quot;highlighter-rouge&quot;&gt;null&lt;/code&gt;值。&lt;/p&gt;

&lt;p&gt;2、最好是在相同类型的字段间进行比较的操作。在MySQL3.23版之前，这甚至是一个必须的条件。例如不能将一个建有索引的INT字段和BIGINT字段进行比较；但是作为特殊的情况，在CHAR类型的字段和VARCHAR类型字段的字段大小相同的时候，可以将它们进行比较。&lt;/p&gt;

&lt;p&gt;3、在建有索引的字段上尽量不要使用函数进行操作，或者进行计算。比如：在一个DATE类型的字段上使用YEAE()函数时，将会使索引不能发挥应有的作用。&lt;/p&gt;

&lt;p&gt;4、在搜索字符型字段时，我们有时会使用like关键字和通配符，这种做法虽然简单，但却也是以牺牲系统性能为代价的。因为在有些情况（比如&lt;code class=&quot;highlighter-rouge&quot;&gt;like '%param%'&lt;/code&gt;）下，like查询使用不到索引，会扫描全表，但如果是&lt;code class=&quot;highlighter-rouge&quot;&gt;like 'param'&lt;/code&gt; 或&lt;code class=&quot;highlighter-rouge&quot;&gt;like 'param%'&lt;/code&gt;的情况下，索引不会失效。但在数据量非常大的时候还是建议不使用like。&lt;/p&gt;

&lt;p&gt;参考文献：&lt;/p&gt;

&lt;p&gt;MySQL中使用or、in与union all在查询命令下的效率对比：http://www.jb51.net/article/75171.htm&lt;/p&gt;

&lt;p&gt;MySQL数据库优化的八种方式：http://www.cnblogs.com/zhyunfe/p/6209074.html&lt;/p&gt;

&lt;p&gt;20+条MySQL性能优化的最佳经验：http://www.jfox.info/20-tiao-mysql-xing-nen-you-hua-de-zui-jia-jing-yan.html&lt;/p&gt;

</description>
        <pubDate>Sun, 13 Aug 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/database/2017/08/13/%E6%AD%BB%E7%A3%95%E6%95%B0%E6%8D%AE%E5%BA%93%E8%B0%83%E4%BC%98-%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96%E7%9A%84%E5%87%A0%E7%82%B9%E6%80%9D%E8%80%83.html</link>
        <guid isPermaLink="true">http://localhost:4000/database/2017/08/13/%E6%AD%BB%E7%A3%95%E6%95%B0%E6%8D%AE%E5%BA%93%E8%B0%83%E4%BC%98-%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96%E7%9A%84%E5%87%A0%E7%82%B9%E6%80%9D%E8%80%83.html</guid>
        
        <category>数据库设计</category>
        
        <category>数据库优化</category>
        
        
        <category>Database</category>
        
      </item>
    
      <item>
        <title>死磕数据库调优-不选最好的，只选最适合的</title>
        <description>&lt;p&gt;终于把老板（导师）接的项目的一期做完了，项目也算告一段落了。整个项目从0到1，从架构设计到功能逻辑实现，我感觉这是我锻炼到的最多的一次，其中我思考最多的不是功能逻辑的实现，因为在不同的项目里需求不一样，功能逻辑也就不一样，所以这个在web项目里没有什么通用性（除了功能需求相似的情况下），因为这是我第一次做架构，而这个角色不会太多的思考某个功能点的技术路线或解决方案应该是怎么样，而是会比以往思考的更多的是框架性能是否足够优化，能承受多大的并发压力，比如数据库表应该怎样设计、数据库性能应该怎样优化等问题。接下来我会总结下在项目中我对数据库性能优化的一系列思考，今天先来讲讲我在项目中遇到的那些字段属性的选择。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;根据业务需求选取最合适的字段属性&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;主流的关系型数据库（如MySQL，Oracle，SQLServer等）都支持大量数据的存取，但在我们的项目中如果不考虑实际业务需求来设计表的字段属性，那么就很可能会造成大量多余的数据存储空间，所以我们在设计数据库表的字段属性时，我们可以将表中字段的宽度设得尽可能小。&lt;/p&gt;

&lt;p&gt;在数据库中，字符型的数据是最多的，可以占到整个数据库的80%以上。为此正确处理字符型的数据，对于提高数据库的性能有很大的作用。&lt;/p&gt;

&lt;p&gt;例如，我们用char(11)来存储手机号码，char是固定长度的，在不足11位的情况下会在后面补齐空格，而varchar是变长的，11只是最大值，当你存储的字符小于11时，按实际长度存储。通常情况下手机号码的长度是固定在11位的，所以不需要使用varchar(11)来存储，因为在char比varchar效率稍高一些；同样的，我们用char(6)来定义邮政编码这个字段，如果将其设置为char(255)，显然给数据库增加了不必要的空间，甚至使用varchar这种类型也是多余的。&lt;/p&gt;

&lt;p&gt;所以如果某个字段的长度总是近似的，如一般在90个到100个字符之间，甚至是相同的长度，此时比较适合采用char字符类型。比较典型的应用就是MD5哈希值。当利用MD5哈希值来存储用户密码时，就非常使用采用char字符类型。因为其长度是相同的。另外，像用来存储用户的身份证号码等等，一般也建议使用char类型的数据。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;varchar VS char&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;从碎片角度进行考虑。使用CHAR字符型时，由于存储空间都是一次性分配的。为此某个字段的内容，其都是存储在一起的。单从这个角度来讲，其不存在碎片的困扰。而可变长度的字符数据类型，其存储的长度是可变的。当其更改前后数据长度不一致时，就不可避免的会出现碎片的问题。故使用可变长度的字符型数据时，我们就要时不时的对碎片进行整理。如执行数据库导出导入作业，来消除碎片。&lt;/p&gt;

&lt;p&gt;另外varchar在位数相同的情况下会比char多占用一个存储位置。比如char(1)与varchar(1)这两个定义，虽然这两个都只能够用来保存单个的字符，但是varchar要比char多占用一个存储位置。这主要是因为使用varchar数据类型时，会多用1个字节用来存储长度信息。这个管理上的开销char字符类型是没有的。&lt;/p&gt;

&lt;p&gt;那既然varchar是变长的，那么varchar(100)和varchar(200)有没有什么区别呢？当然有区别了，虽然它们用来存储90个字符数据的时候其存储空间是相同的。但是对于内存的消耗是不同的。对于varchar数据类型来说，硬盘上的存储空间虽然都是根据实际字符长度来分配存储空间的，但是对于内存来说，它是使用固定大小的内存块来保存值，也就是说varchar(200)是使用200个字符空间来保存值。显然，这对于排序或者临时表(这些内容都需要通过内存来实现)作业会产生比较大的不利影响。所以说在内存的操作方式中，varchar是按照最长的方式在内存中进行操作的。比如说要进行排序的时候，varcahr(100)是按照100这个长度来进行的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;常见的字符串类型&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕数据库调优-记在数据库设计中对数据库性能优化的思考&quot; 图片2=&quot;&quot; src=&quot;http://img.mukewang.com/598fdf33000107f114620540.png&quot; style=&quot;width:100%&quot; alt=&quot;常见的字符串类型&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们一般会用tinyint(1)来描述性别而不会直接用char，也不会用int(1)。int类型占4个字节，tinyint占1个字节。int(1)和int(4) 从本身长度还是存储方式上都是一样的，区别就是显示的长度不同，如果列制定了zerofill 就会用0填充显示，int(4)指定后就会显示为0002。tinyint(1)和tinyint(4)没什么区别，存123都能存的下，而如果tinyint(3) zerofill 的话，插入值 12，会存储012，zerofill自动左边补零，它会限制显示长度。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;常见的数值类型&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕数据库调优-记在数据库设计中对数据库性能优化的思考&quot; 图片1=&quot;&quot; src=&quot;http://img.mukewang.com/598fdf200001df3614640560.png&quot; style=&quot;width:100%&quot; alt=&quot;常见的数值类型&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;tinyint VS enum VS set&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;enum是一个字符串对象，其值通常选自一个允许值列表中，该列表在表创建时的列规格说明中被明确地列举。枚举最大可以有 65535 个成员值。&lt;/p&gt;

&lt;p&gt;在下列某些情况下，值也可以是空串(“”) 或 NULL：&lt;/p&gt;

&lt;p&gt;如果将一个无效值插入一个 ENUM (即，一个不在允许值列表中的字符串)，空字符串将作为一个特殊的错误值被插入。事实上，这个字符串有别于一个”普通的”空字符串，因为这个字符串有个数字索引值为 0。稍后有更详细描述。&lt;/p&gt;

&lt;p&gt;如果一个 ENUM 被声明为 NULL，NULL 也是该列的一个合法值，并且该列的缺省值也将为 NULL 。如果一个 ENUM 被声明为 NOT NULL，该列的缺省值将是该列表所允许值的第一个成员。&lt;/p&gt;

&lt;p&gt;每个枚举值均有一个索引值：&lt;/p&gt;

&lt;p&gt;在列说明中列表值所允许的成员值被从 1 开始编号。&lt;/p&gt;

&lt;p&gt;空字符串错误值的索引值为 0。这就意味着，你可以使用下面所示的 SELECT 语句找出被赋于无效 ENUM值的记录行。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mysql&amp;gt; SELECT * FROM tbl_name WHERE enum_col=0;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;NULL 值的索引值为 NULL。&lt;/p&gt;

&lt;p&gt;指定为 ENUM(“one”, “two”, “three”) 的一个列，可以有下面所显示的任一值。每个值的索引值也如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕数据库调优-记在数据库设计中对数据库性能优化的思考&quot; 图片3=&quot;&quot; src=&quot;http://img.mukewang.com/599017d90001470b13720314.png&quot; style=&quot;width:100%&quot; alt=&quot;ENUM&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从上面的enum分析可以看出，enum适合存储表单界面中的“单选值”，下面我们来看看set数据类型。&lt;/p&gt;

&lt;p&gt;set是一种多选字符串数据类型，适合存储表单界面的“多选值”。设定set的时候，同样需要给定“固定的几个选项”；存储的时候，可以存储其中的若干个值。&lt;/p&gt;

&lt;p&gt;设定set的格式：&lt;code class=&quot;highlighter-rouge&quot;&gt;set(&quot;param1&quot;,&quot;param2&quot;,&quot;param3&quot;,...)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;set的每个选项值也对应一个数字，依次是1，2，4，8，16…，最多有64个选项
使用的时候，可以使用set选项的字符串本身（多个选项用逗号分隔），也可以使用多个选项的数字之和（比如：1+2+4=7）&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕数据库调优-记在数据库设计中对数据库性能优化的思考&quot; 图片4=&quot;&quot; src=&quot;http://img.mukewang.com/599018370001dd7511780932.png&quot; style=&quot;width:100%&quot; alt=&quot;set&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;15=1+2+4+8 &amp;lt;=&amp;gt; ‘music,read,swimming,footbal’&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;7=1+2+4&amp;lt;=&amp;gt; ‘music,read,swimming’&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;了解了set后，以后我们在做权限管理这一块功能的时候就不需要单建一张权限表，然后在角色表里加一个权限的字段，现在我们直接用set就可以很方便实现一个角色对应多种权限。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;那么对于enum和tinyint我们到底用哪一个呢？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;个人推荐尽量使用tinyint来代替enum，我们可以用tinyint(1)来代替enum表示性别字段，enum对php这种弱类型来说简直是灾难，而且如果项目以后要做不同数据库的迁移，enum可能会出现一些问题，enum的移植性不如tinyint，维护起来比较麻烦。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考文献：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;MySQL数据库中CHAR与VARCHAR之争：http://tech.it168.com/a2011/0426/1183/000001183173.shtml&lt;/p&gt;

&lt;p&gt;MySQL 数据类型：http://www.runoob.com/mysql/mysql-data-types.html&lt;/p&gt;
</description>
        <pubDate>Tue, 08 Aug 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/database/2017/08/08/%E6%AD%BB%E7%A3%95%E6%95%B0%E6%8D%AE%E5%BA%93%E8%B0%83%E4%BC%98-%E4%B8%8D%E9%80%89%E6%9C%80%E5%A5%BD%E7%9A%84-%E5%8F%AA%E9%80%89%E6%9C%80%E9%80%82%E5%90%88%E7%9A%84.html</link>
        <guid isPermaLink="true">http://localhost:4000/database/2017/08/08/%E6%AD%BB%E7%A3%95%E6%95%B0%E6%8D%AE%E5%BA%93%E8%B0%83%E4%BC%98-%E4%B8%8D%E9%80%89%E6%9C%80%E5%A5%BD%E7%9A%84-%E5%8F%AA%E9%80%89%E6%9C%80%E9%80%82%E5%90%88%E7%9A%84.html</guid>
        
        <category>数据库设计</category>
        
        <category>数据库调优</category>
        
        <category>字段属性</category>
        
        
        <category>Database</category>
        
      </item>
    
      <item>
        <title>死磕Spring源码-Spring MVC</title>
        <description>&lt;p&gt;Spring IoC是Spring的核心，所以IoC也是Spring MVC的基础，Spring MVC 会建立起一个IOC容器体系，IoC的启动过程与web容器启动的过程是集成在一起的，它们的启动由ContextLoaderListener监听器负责完成。建立IOC容器体系后，DispatcherServlet作为Spring MVC处理web请求的转发器也建立起来，从而完成响应HTTP请求的准备工作。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;一、IOC容器的启动（ContextLoaderListener）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;IoC容器的启动过程就是建立上下文的过程，由ContextLoaderListener启动的上下文为根上下文，在根上下文的基础上，还有一个与Web MVC相关的上下文作为根上下文的子上下文来保存DispatcherServlet所需要的MVC对象，构成一个上下文体系。这个上下文体系的建立与初始化是由ContextLoader来完成的。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class ContextLoaderListener extends ContextLoader implements ServletContextListener {
     public ContextLoaderListener() {
     }
     public ContextLoaderListener(WebApplicationContext context) {
          super(context);
     }
     @Override
     public void contextInitialized(ServletContextEvent event) {
          initWebApplicationContext(event.getServletContext());
     }
     @Override
     public void contextDestroyed(ServletContextEvent event) {
          closeWebApplicationContext(event.getServletContext());
          ContextCleanupListener.cleanupAttributes(event.getServletContext());
     }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;在ContextLoaderListener中实现了ServletContextListener接口，这个接口里的函数会结合Web容器的生命周期被调用（contextInitialized，服务器启动时被调用；contextDestroyed，服务器关闭时被调用）。因为ServletContextListener是ServletContext的监听者，如果ServletContext发生变化，会触发预先设计好的动作，比如初始化和销毁。比如初始化：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ContextLoaderListener.contextInitialized
@Override
public void contextInitialized(ServletContextEvent event) {
    initWebApplicationContext(event.getServletContext());
}
//初始化WebApplicationContext根上下文
public WebApplicationContext initWebApplicationContext(ServletContext servletContext) {
    //根上下文作为唯一实例存在，用ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE标志位来实现
    if (servletContext.getAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE) != null) {
        throw new IllegalStateException(
                &quot;Cannot initialize context because there is already a root application context present - &quot; +
                &quot;check whether you have multiple ContextLoader* definitions in your web.xml!&quot;);
    }

    Log logger = LogFactory.getLog(ContextLoader.class);
    servletContext.log(&quot;Initializing Spring root WebApplicationContext&quot;);
    if (logger.isInfoEnabled()) {
        logger.info(&quot;Root WebApplicationContext: initialization started&quot;);
    }
    long startTime = System.currentTimeMillis();

    try {
        if (this.context == null) {
            //创建根上下文
            this.context = createWebApplicationContext(servletContext);
        }
        if (this.context instanceof ConfigurableWebApplicationContext) {
            //转型为需要产生的IoC容器
            ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) this.context;
            if (!cwac.isActive()) {
                if (cwac.getParent() == null) {
                    // 载入根上下文的双亲上下文
                    ApplicationContext parent = loadParentContext(servletContext);
                    cwac.setParent(parent);
                }
                configureAndRefreshWebApplicationContext(cwac, servletContext);
            }
        }
        //设置ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE标志位
   servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context);

        ClassLoader ccl = Thread.currentThread().getContextClassLoader();
        if (ccl == ContextLoader.class.getClassLoader()) {
            currentContext = this.context;
        }
        else if (ccl != null) {
            currentContextPerThread.put(ccl, this.context);
        }

        if (logger.isDebugEnabled()) {
            logger.debug(&quot;Published root WebApplicationContext as ServletContext attribute with name [&quot; +
                    WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE + &quot;]&quot;);
        }
        if (logger.isInfoEnabled()) {
            long elapsedTime = System.currentTimeMillis() - startTime;
            logger.info(&quot;Root WebApplicationContext: initialization completed in &quot; + elapsedTime + &quot; ms&quot;);
        }

        return this.context;
    }
    catch (RuntimeException ex) {
        logger.error(&quot;Context initialization failed&quot;, ex);
        servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, ex);
        throw ex;
    }
    catch (Error err) {
        logger.error(&quot;Context initialization failed&quot;, err);
        servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, err);
        throw err;
    }
}

protected WebApplicationContext createWebApplicationContext(ServletContext sc) {
    //判断使用什么样的类作为Web容器中的IoC容器
    Class&amp;lt;?&amp;gt; contextClass = determineContextClass(sc);
    if (!ConfigurableWebApplicationContext.class.isAssignableFrom(contextClass)) {
        throw new ApplicationContextException(&quot;Custom context class [&quot; + contextClass.getName() +
                &quot;] is not of type [&quot; + ConfigurableWebApplicationContext.class.getName() + &quot;]&quot;);
    }
    return (ConfigurableWebApplicationContext) BeanUtils.instantiateClass(contextClass);
}

protected Class&amp;lt;?&amp;gt; determineContextClass(ServletContext servletContext) {
    String contextClassName = servletContext.getInitParameter(CONTEXT_CLASS_PARAM);
    //如果在ServletContext中配置了CONTEXT_CLASS_PARAM，则使用这个class反射生成根上下文实例。
    if (contextClassName != null) {
        try {
            return ClassUtils.forName(contextClassName, ClassUtils.getDefaultClassLoader());
        }
        catch (ClassNotFoundException ex) {
            throw new ApplicationContextException(
                    &quot;Failed to load custom context class [&quot; + contextClassName + &quot;]&quot;, ex);
        }
    }
    else {//如果没有配置CONTEXT_CLASS_PARAM，则使用默认的contextClass来反射生成根上下文实例。
        contextClassName = defaultStrategies.getProperty(WebApplicationContext.class.getName());
        try {
            return ClassUtils.forName(contextClassName, ContextLoader.class.getClassLoader());
        }
        catch (ClassNotFoundException ex) {
            throw new ApplicationContextException(
                    &quot;Failed to load default context class [&quot; + contextClassName + &quot;]&quot;, ex);
        }
    }
}

//设置ServletContext以及配置各类参数，最终调用refresh方法来初始化容器
protected void configureAndRefreshWebApplicationContext(ConfigurableWebApplicationContext wac, ServletContext sc) {
    if (ObjectUtils.identityToString(wac).equals(wac.getId())) {
        // The application context id is still set to its original default value
        String idParam = sc.getInitParameter(CONTEXT_ID_PARAM);
        if (idParam != null) {
            wac.setId(idParam);
        }
        else {
            // Generate default id...
            wac.setId(ConfigurableWebApplicationContext.APPLICATION_CONTEXT_ID_PREFIX +
                    ObjectUtils.getDisplayString(sc.getContextPath()));
        }
    }

    wac.setServletContext(sc);
    String configLocationParam = sc.getInitParameter(CONFIG_LOCATION_PARAM);
    if (configLocationParam != null) {
        wac.setConfigLocation(configLocationParam);
    }

    ConfigurableEnvironment env = wac.getEnvironment();
    if (env instanceof ConfigurableWebEnvironment) {
        ((ConfigurableWebEnvironment) env).initPropertySources(sc, null);
    }

    customizeContext(sc, wac);
    wac.refresh();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;ContextLoaderListener初始化根上下文过程图&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-SpringMVC&quot; 图片1=&quot;&quot; src=&quot;http://img.mukewang.com/597dfb49000101aa16560728.png&quot; style=&quot;width:100%&quot; alt=&quot;初始化根上下文过程图&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;二、Spring MVC的启动（DispatcherServlet）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在完成ContextLoaderListener的初始化后，Web容器开始初始化DispatcherServlet。DispatcherServlet会建立自己的上下文来持有Spring MVC的Bean对象，在建立自己持有的IOC容器时，会将根上下文作为自己持有的上下文的双亲上下文，建立了这个上下文后将该上下文保存到ServletContext中，供以后检索和使用。DispatcherServlet的启动过程也就是Spring MVC的启动过程。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.1 DispatcherServlet的继承关系&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-SpringMVC&quot; 图片2=&quot;&quot; src=&quot;http://img.mukewang.com/597ef8590001cdb904720208.png&quot; style=&quot;width:50%&quot; alt=&quot;DispatcherServlet的继承关系&quot; /&gt;&lt;/p&gt;

&lt;p&gt;DispatcherServlet通过继承FrameworkServlet和HttpServletBean来继承HttpServlet，这样就可以使用Servlet API来对HTTP请求进行响应，成为Spring MVC的前端处理器。&lt;/p&gt;

&lt;p&gt;DispatcherServlet的工作分为两部分：一个是&lt;strong&gt;初始化部分&lt;/strong&gt;，通过调用initStrategies方法完成Spring MVC的初始化；一个是&lt;strong&gt;对HTTP请求进行响应&lt;/strong&gt;，作为一个servlet，Web容器会调用Servlet的doGet和doPost方法来完成响应动作。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.2 DispatcherServlet的启动与初始化&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;DispatcherServlet的启动与Servlet的启动是相似的，在Servlet初始化时会调用init方法，在DispatcherServlet的基类HttpServletBean的初始化也由init开始。DispatcherServlet持有一个以自己的Servlet名称命名的IoC容器，这个容器作为根上下文的子上下文存在，在Web容器的上下文体系中，一个根上下文可以作为多个Servlet子上下文的双亲上下文。&lt;/p&gt;

&lt;p&gt;一般情况下controller相关的bean或者对应的注解扫描配置在子上下文中，而service、dao的bean或者对应的注解扫描配置在根上下文中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;建立MVC的上下文代码逻辑：&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;HttpServletBean.init()
@Override
public final void init() throws ServletException {
    if (logger.isDebugEnabled()) {
        logger.debug(&quot;Initializing servlet '&quot; + getServletName() + &quot;'&quot;);
    }

    // 获取Servlet的初始化参数，配置Bean属性
    try {
        PropertyValues pvs = new ServletConfigPropertyValues(getServletConfig(), this.requiredProperties);
        BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this);
        ResourceLoader resourceLoader = new ServletContextResourceLoader(getServletContext());
        bw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, getEnvironment()));
        initBeanWrapper(bw);
        bw.setPropertyValues(pvs, true);
    }
    catch (BeansException ex) {
        logger.error(&quot;Failed to set bean properties on servlet '&quot; + getServletName() + &quot;'&quot;, ex);
        throw ex;
    }

    // 具体初始化过程
    initServletBean();

    if (logger.isDebugEnabled()) {
        logger.debug(&quot;Servlet '&quot; + getServletName() + &quot;' configured successfully&quot;);
    }
}

@Override
protected final void initServletBean() throws ServletException {
    getServletContext().log(&quot;Initializing Spring FrameworkServlet '&quot; + getServletName() + &quot;'&quot;);
    if (this.logger.isInfoEnabled()) {
        this.logger.info(&quot;FrameworkServlet '&quot; + getServletName() + &quot;': initialization started&quot;);
    }
    long startTime = System.currentTimeMillis();
    //初始化上下文
    try {
        this.webApplicationContext = initWebApplicationContext();
        initFrameworkServlet();
    }
    catch (ServletException ex) {
        this.logger.error(&quot;Context initialization failed&quot;, ex);
        throw ex;
    }
    catch (RuntimeException ex) {
        this.logger.error(&quot;Context initialization failed&quot;, ex);
        throw ex;
    }

    if (this.logger.isInfoEnabled()) {
        long elapsedTime = System.currentTimeMillis() - startTime;
        this.logger.info(&quot;FrameworkServlet '&quot; + getServletName() + &quot;': initialization completed in &quot; +
                elapsedTime + &quot; ms&quot;);
    }
}

//这里的初始化上下文和ContextLoaderListner不太一样
protected WebApplicationContext initWebApplicationContext() {
    //使用ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE来获取根上下文
    WebApplicationContext rootContext =
            WebApplicationContextUtils.getWebApplicationContext(getServletContext());
    WebApplicationContext wac = null;

    if (this.webApplicationContext != null) {
        wac = this.webApplicationContext;
        if (wac instanceof ConfigurableWebApplicationContext) {
            ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) wac;
            if (!cwac.isActive()) {
                if (cwac.getParent() == null) {
                    // 设置根上下文为双亲上下文
                    cwac.setParent(rootContext);
                }
                configureAndRefreshWebApplicationContext(cwac);
            }
        }
    }
    if (wac == null) {
        wac = findWebApplicationContext();
    }
    //如果以上都没有能获取MVC的IoC容器，则创建一个
    if (wac == null) {
        wac = createWebApplicationContext(rootContext);
    }

    if (!this.refreshEventReceived) {
        onRefresh(wac);
    }

    if (this.publishContext) {
        //把建立好的子上下文存放到ServletContext中去，使用的属性名就是当前servlet名
        String attrName = getServletContextAttributeName();
        getServletContext().setAttribute(attrName, wac);
        if (this.logger.isDebugEnabled()) {
            this.logger.debug(&quot;Published WebApplicationContext of servlet '&quot; + getServletName() +
                    &quot;' as ServletContext attribute with name [&quot; + attrName + &quot;]&quot;);
        }
    }

    return wac;
}

protected WebApplicationContext createWebApplicationContext(ApplicationContext parent) {
    Class&amp;lt;?&amp;gt; contextClass = getContextClass();
    if (this.logger.isDebugEnabled()) {
        this.logger.debug(&quot;Servlet with name '&quot; + getServletName() +
                &quot;' will try to create custom WebApplicationContext context of class '&quot; +
                contextClass.getName() + &quot;'&quot; + &quot;, using parent context [&quot; + parent + &quot;]&quot;);
    }
    if (!ConfigurableWebApplicationContext.class.isAssignableFrom(contextClass)) {
        throw new ApplicationContextException(
                &quot;Fatal initialization error in servlet with name '&quot; + getServletName() +
                &quot;': custom WebApplicationContext class [&quot; + contextClass.getName() +
                &quot;] is not of type ConfigurableWebApplicationContext&quot;);
    }
    //实例化需要的具体上下文对象，这个上下文对象也是XmlWebApplicationContext
    ConfigurableWebApplicationContext wac =
            (ConfigurableWebApplicationContext) BeanUtils.instantiateClass(contextClass);

    wac.setEnvironment(getEnvironment());
    //设置双亲上下文
    wac.setParent(parent);
    wac.setConfigLocation(getContextConfigLocation());

    configureAndRefreshWebApplicationContext(wac);

    return wac;
}

protected void configureAndRefreshWebApplicationContext(ConfigurableWebApplicationContext wac) {
    if (ObjectUtils.identityToString(wac).equals(wac.getId())) {
        if (this.contextId != null) {
            wac.setId(this.contextId);
        }
        else {
            wac.setId(ConfigurableWebApplicationContext.APPLICATION_CONTEXT_ID_PREFIX +
                    ObjectUtils.getDisplayString(getServletContext().getContextPath()) + &quot;/&quot; + getServletName());
        }
    }

    wac.setServletContext(getServletContext());
    wac.setServletConfig(getServletConfig());
    wac.setNamespace(getNamespace());
    wac.addApplicationListener(new SourceFilteringListener(wac, new ContextRefreshListener()));

    ConfigurableEnvironment env = wac.getEnvironment();
    if (env instanceof ConfigurableWebEnvironment) {
        ((ConfigurableWebEnvironment) env).initPropertySources(getServletContext(), getServletConfig());
    }

    postProcessWebApplicationContext(wac);
    applyInitializers(wac);
    //通过refresh方法来调用容器初始化过程
    wac.refresh();
}

DispatcherServlet.onRefresh
protected void onRefresh(ApplicationContext context) {
    initStrategies(context);
}

//启动整个Spring MVC框架的初始化
protected void initStrategies(ApplicationContext context) {
    initMultipartResolver(context);
    initLocaleResolver(context);
    initThemeResolver(context);
    initHandlerMappings(context);
    initHandlerAdapters(context);
    initHandlerExceptionResolvers(context);
    initRequestToViewNameTranslator(context);
    initViewResolvers(context);
    initFlashMapManager(context);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;MVC框架的初始化是在initStrategies方法中完成的，初始化了支持国际化的LocaleResolver、request映射的HandlerMappings、视图生成的ViewResolvers等。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//初始化HandlerMapping
private void initHandlerMappings(ApplicationContext context) {
    this.handlerMappings = null;
    //detectAllHandlerMappings这里默认为true，即默认从所有的IoC容器中获取HandlerMapping
    if (this.detectAllHandlerMappings) {
        // Find all HandlerMappings in the ApplicationContext, including ancestor contexts.
        Map&amp;lt;String, HandlerMapping&amp;gt; matchingBeans =
                BeanFactoryUtils.beansOfTypeIncludingAncestors(context, HandlerMapping.class, true, false);
        if (!matchingBeans.isEmpty()) {
            this.handlerMappings = new ArrayList&amp;lt;HandlerMapping&amp;gt;(matchingBeans.values());
            // We keep HandlerMappings in sorted order.
            AnnotationAwareOrderComparator.sort(this.handlerMappings);
        }
    }
    else {//否则从当前的IoC容器中通过getBean获取所有Bean名称为“handlerMapping”的HandlerMapping
        try {
            HandlerMapping hm = context.getBean(HANDLER_MAPPING_BEAN_NAME, HandlerMapping.class);
            this.handlerMappings = Collections.singletonList(hm);
        }
        catch (NoSuchBeanDefinitionException ex) {
            // Ignore, we'll add a default HandlerMapping later.
        }
    }

    // 如果没有handlerMappings，则从配置文件中读取
    if (this.handlerMappings == null) {
        this.handlerMappings = getDefaultStrategies(context, HandlerMapping.class);
        if (logger.isDebugEnabled()) {
            logger.debug(&quot;No HandlerMappings found in servlet '&quot; + getServletName() + &quot;': using default&quot;);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;initHandlerMappings是对HandlerMappings的初始化，这些Map的作用是为HTTP请求找到相应的Controller控制器，以完成功能逻辑。IoC容器初始化后，容器里有各种各样的Bean，initHandlerMappings会从IoC容器中通过getBean来获取handlerMapping，handlerMapping包含了MVC中Controller的定义和配置，同时handlerMappings变量就已经获取了在BeanDefinition配置好的映射关系。加载的HandlerMapping被放在一个List中并已经排好序，存储着HTTP请求对应的映射数据，List中的一个元素就是一个HandlerMapping，一个mapping中有一系列的URL与Controller的映射。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;initHandlerMappings方法调用栈&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-SpringMVC&quot; 图片3=&quot;&quot; src=&quot;http://img.mukewang.com/597ef9330001fb1313280208.png&quot; style=&quot;width:100%&quot; alt=&quot;initHandlerMappings方法调用栈&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-SpringMVC&quot; 图片4=&quot;&quot; src=&quot;http://img.mukewang.com/597ef94100012e7b13780762.png&quot; style=&quot;width:100%&quot; alt=&quot;死磕Spring源码-SpringMVC&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.3 MVC处理HTTP分发请求&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;上面已经完成了HandlerMapping的加载，每一个HandlerMapping持有一系列从URL请求到Controller的映射，这种映射关系通常用一个Map（LinkedHashMap，命名为handlerMap）来持有。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;private final Map&amp;lt;String, Object&amp;gt; urlMap = new LinkedHashMap&amp;lt;String, Object&amp;gt;();&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;某个URL映射到哪个Controller，这部分的配置是在容器对Bean进行依赖注入时发生的，通过Bean的postProcessor来完成，（registerHandler方法）。这样就为DispatcherServlet的分发奠定了数据基础。&lt;/p&gt;

&lt;p&gt;SimpleUrlHandlerMapping注册handler的代码逻辑&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;SimpleUrlHandlerMapping.initApplicationContext
@Override
public void initApplicationContext() throws BeansException {
    super.initApplicationContext();
    registerHandlers(this.urlMap);
}

protected void registerHandlers(Map&amp;lt;String, Object&amp;gt; urlMap) throws BeansException {
    if (urlMap.isEmpty()) {
        logger.warn(&quot;Neither 'urlMap' nor 'mappings' set on SimpleUrlHandlerMapping&quot;);
    }
    else {
        for (Map.Entry&amp;lt;String, Object&amp;gt; entry : urlMap.entrySet()) {
            String url = entry.getKey();
            Object handler = entry.getValue();
            // 确保url以&quot;/&quot;开头
            if (!url.startsWith(&quot;/&quot;)) {
                url = &quot;/&quot; + url;
            }
            // 去掉空格
            if (handler instanceof String) {
                handler = ((String) handler).trim();
            }
            registerHandler(url, handler);
        }
    }
}

protected void registerHandler(String urlPath, Object handler) throws BeansException, IllegalStateException {
    Assert.notNull(urlPath, &quot;URL path must not be null&quot;);
    Assert.notNull(handler, &quot;Handler object must not be null&quot;);
    Object resolvedHandler = handler;

    if (!this.lazyInitHandlers &amp;amp;&amp;amp; handler instanceof String) {
        String handlerName = (String) handler;
        if (getApplicationContext().isSingleton(handlerName)) {
            resolvedHandler = getApplicationContext().getBean(handlerName);
        }
    }

    Object mappedHandler = this.handlerMap.get(urlPath);
    if (mappedHandler != null) {
        if (mappedHandler != resolvedHandler) {
            throw new IllegalStateException(
                    &quot;Cannot map &quot; + getHandlerDescription(handler) + &quot; to URL path [&quot; + urlPath +
                    &quot;]: There is already &quot; + getHandlerDescription(mappedHandler) + &quot; mapped.&quot;);
        }
    }
    else {
        //如果url是“/”，则这个url映射的Controller就是rootHandler
        if (urlPath.equals(&quot;/&quot;)) {
            if (logger.isInfoEnabled()) {
                logger.info(&quot;Root mapping to &quot; + getHandlerDescription(handler));
            }
            setRootHandler(resolvedHandler);
        }//如果url是“/*”，则这个url映射的Controller就是DefaultHandler
        else if (urlPath.equals(&quot;/*&quot;)) {
            if (logger.isInfoEnabled()) {
                logger.info(&quot;Default mapping to &quot; + getHandlerDescription(handler));
            }
            setDefaultHandler(resolvedHandler);
        }
        else {//如果url是正常的url，设置handlerMap的key和value分别对应url和对应的Controller
            this.handlerMap.put(urlPath, resolvedHandler);
            if (logger.isInfoEnabled()) {
                logger.info(&quot;Mapped URL path [&quot; + urlPath + &quot;] onto &quot; + getHandlerDescription(handler));
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;准备好handlerMap中的数据后，我们来看看handlerMapping如何完成请求的映射处理。
在HandlerMapping中定义了getHandler方法，这个方法会根据我们刚刚初始化得到的handlerMap来获取与HTTP请求对应的HandlerExecutionChain，它封装了具体的Controller对象。HandlerExecutionChain有两个比较重要：拦截器（Interceptor）链和handler对象，handler对象就是HTTP对应的Controller，通过拦截器链里的拦截器来对handler对象提供功能的增强。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;AbstractHandlerMapping.getHandler
@Override
public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception {
    //获取request对应的handler
    Object handler = getHandlerInternal(request);
    //获取默认的handler
    if (handler == null) {
        handler = getDefaultHandler();
    }
    if (handler == null) {
        return null;
    }
    // 根据名称取出对应的Handler Bean
    if (handler instanceof String) {
        String handlerName = (String) handler;
        handler = getApplicationContext().getBean(handlerName);
    }
    //把这个handler封装到HandlerExecutionChain中并加上拦截器
    HandlerExecutionChain executionChain = getHandlerExecutionChain(handler, request);
    if (CorsUtils.isCorsRequest(request)) {
        CorsConfiguration globalConfig = this.corsConfigSource.getCorsConfiguration(request);
        CorsConfiguration handlerConfig = getCorsConfiguration(handler, request);
        CorsConfiguration config = (globalConfig != null ? globalConfig.combine(handlerConfig) : handlerConfig);
        executionChain = getCorsHandlerExecutionChain(request, executionChain, config);
    }
    return executionChain;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;获取request对应的handler的代码逻辑&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Override
protected Object getHandlerInternal(HttpServletRequest request) throws Exception {
    //从request获取url路径
    String lookupPath = getUrlPathHelper().getLookupPathForRequest(request);
    //从HandlerMap中获取指定url路径的handler
    Object handler = lookupHandler(lookupPath, request);
    if (handler == null) {
        // 如果没有对应url路径的handler则返回相应的handler（RootHandler或DefaultHandler）
        Object rawHandler = null;
        if (&quot;/&quot;.equals(lookupPath)) {
            rawHandler = getRootHandler();
        }
        if (rawHandler == null) {
            rawHandler = getDefaultHandler();
        }
        if (rawHandler != null) {
            if (rawHandler instanceof String) {
                String handlerName = (String) rawHandler;
                rawHandler = getApplicationContext().getBean(handlerName);
            }
            validateHandler(rawHandler, request);
            handler = buildPathExposingHandler(rawHandler, lookupPath, lookupPath, null);
        }
    }
    if (handler != null &amp;amp;&amp;amp; logger.isDebugEnabled()) {
        logger.debug(&quot;Mapping [&quot; + lookupPath + &quot;] to &quot; + handler);
    }
    else if (handler == null &amp;amp;&amp;amp; logger.isTraceEnabled()) {
        logger.trace(&quot;No handler mapping found for [&quot; + lookupPath + &quot;]&quot;);
    }
    return handler;
}

protected Object lookupHandler(String urlPath, HttpServletRequest request) throws Exception {
    // 直接匹配url
    Object handler = this.handlerMap.get(urlPath);
    if (handler != null) {
        if (handler instanceof String) {
            String handlerName = (String) handler;
            handler = getApplicationContext().getBean(handlerName);
        }
        validateHandler(handler, request);
        return buildPathExposingHandler(handler, urlPath, urlPath, null);
    }
    // 如果直接匹配url不成功，则匹配最佳的
    List&amp;lt;String&amp;gt; matchingPatterns = new ArrayList&amp;lt;String&amp;gt;();
    for (String registeredPattern : this.handlerMap.keySet()) {
        if (getPathMatcher().match(registeredPattern, urlPath)) {
            matchingPatterns.add(registeredPattern);
        }
        else if (useTrailingSlashMatch()) {
            if (!registeredPattern.endsWith(&quot;/&quot;) &amp;amp;&amp;amp; getPathMatcher().match(registeredPattern + &quot;/&quot;, urlPath)) {
                matchingPatterns.add(registeredPattern +&quot;/&quot;);
            }
        }
    }
    String bestPatternMatch = null;
    Comparator&amp;lt;String&amp;gt; patternComparator = getPathMatcher().getPatternComparator(urlPath);
    if (!matchingPatterns.isEmpty()) {
        Collections.sort(matchingPatterns, patternComparator);
        if (logger.isDebugEnabled()) {
            logger.debug(&quot;Matching patterns for request [&quot; + urlPath + &quot;] are &quot; + matchingPatterns);
        }
        bestPatternMatch = matchingPatterns.get(0);
    }
    if (bestPatternMatch != null) {
        handler = this.handlerMap.get(bestPatternMatch);
        if (handler == null) {
            Assert.isTrue(bestPatternMatch.endsWith(&quot;/&quot;));
            handler = this.handlerMap.get(bestPatternMatch.substring(0, bestPatternMatch.length() - 1));
        }
        if (handler instanceof String) {
            String handlerName = (String) handler;
            handler = getApplicationContext().getBean(handlerName);
        }
        validateHandler(handler, request);
        String pathWithinMapping = getPathMatcher().extractPathWithinPattern(bestPatternMatch, urlPath);

        Map&amp;lt;String, String&amp;gt; uriTemplateVariables = new LinkedHashMap&amp;lt;String, String&amp;gt;();
        for (String matchingPattern : matchingPatterns) {
            if (patternComparator.compare(bestPatternMatch, matchingPattern) == 0) {
                Map&amp;lt;String, String&amp;gt; vars = getPathMatcher().extractUriTemplateVariables(matchingPattern, urlPath);
                Map&amp;lt;String, String&amp;gt; decodedVars = getUrlPathHelper().decodePathVariables(request, vars);
                uriTemplateVariables.putAll(decodedVars);
            }
        }
        if (logger.isDebugEnabled()) {
            logger.debug(&quot;URI Template variables for request [&quot; + urlPath + &quot;] are &quot; + uriTemplateVariables);
        }
        return buildPathExposingHandler(handler, bestPatternMatch, pathWithinMapping, uriTemplateVariables);
    }
    return null;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;得到handler对象后，把这个handler封装到HandlerExecutionChain中并加上拦截器&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;protected HandlerExecutionChain getHandlerExecutionChain(Object handler, HttpServletRequest request) {
    HandlerExecutionChain chain = (handler instanceof HandlerExecutionChain ?
            (HandlerExecutionChain) handler : new HandlerExecutionChain(handler));

    String lookupPath = this.urlPathHelper.getLookupPathForRequest(request);
    for (HandlerInterceptor interceptor : this.adaptedInterceptors) {
        if (interceptor instanceof MappedInterceptor) {
            MappedInterceptor mappedInterceptor = (MappedInterceptor) interceptor;
            if (mappedInterceptor.matches(lookupPath, this.pathMatcher)) {
                chain.addInterceptor(mappedInterceptor.getInterceptor());
            }
        }
        else {
            chain.addInterceptor(interceptor);
        }
    }
    return chain;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;现在我们完成了对HandlerExecutionChain的封装工作，为handler对http请求响应做好了准备。&lt;/p&gt;

&lt;p&gt;DispatcherServlet是HttpServlet的子类，和其他的HttpServlet一样，通过doService方法来响应HTTP请求（再调用doDispatch）。DispatcherServlet通过getHandler得到一个HandlerExecutionChain后，通过HandlerAdapter来验证这个handler的合法性（handler instanceof Controller，如果是Controller的对象则返回true，反之返回false），合法后执行handler方法获取结果数据，这些数据都封装在ModelAndView中返回给前端进行视图呈现，对视图呈现的处理是通过调用入口：render方法来实现的。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception {
    HttpServletRequest processedRequest = request;
    HandlerExecutionChain mappedHandler = null;
    boolean multipartRequestParsed = false;

    WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);

    try {
        ModelAndView mv = null;
        Exception dispatchException = null;

        try {
            processedRequest = checkMultipart(request);
            multipartRequestParsed = (processedRequest != request);

            // Determine handler for the current request.
            mappedHandler = getHandler(processedRequest);
            if (mappedHandler == null || mappedHandler.getHandler() == null) {
                noHandlerFound(processedRequest, response);
                return;
            }

            // Determine handler adapter for the current request.
            HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler());

            // Process last-modified header, if supported by the handler.
            String method = request.getMethod();
            boolean isGet = &quot;GET&quot;.equals(method);
            if (isGet || &quot;HEAD&quot;.equals(method)) {
                long lastModified = ha.getLastModified(request, mappedHandler.getHandler());
                if (logger.isDebugEnabled()) {
                    logger.debug(&quot;Last-Modified value for [&quot; + getRequestUri(request) + &quot;] is: &quot; + lastModified);
                }
                if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;amp;&amp;amp; isGet) {
                    return;
                }
            }

            if (!mappedHandler.applyPreHandle(processedRequest, response)) {
                return;
            }

            // Actually invoke the handler.
            mv = ha.handle(processedRequest, response, mappedHandler.getHandler());

            if (asyncManager.isConcurrentHandlingStarted()) {
                return;
            }

            applyDefaultViewName(processedRequest, mv);
            mappedHandler.applyPostHandle(processedRequest, response, mv);
        }
        catch (Exception ex) {
            dispatchException = ex;
        }
        catch (Throwable err) {
            // As of 4.3, we're processing Errors thrown from handler methods as well,
            // making them available for @ExceptionHandler methods and other scenarios.
            dispatchException = new NestedServletException(&quot;Handler dispatch failed&quot;, err);
        }
        processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException);
    }
    catch (Exception ex) {
        triggerAfterCompletion(processedRequest, response, mappedHandler, ex);
    }
    catch (Throwable err) {
        triggerAfterCompletion(processedRequest, response, mappedHandler,
                new NestedServletException(&quot;Handler processing failed&quot;, err));
    }
    finally {
        if (asyncManager.isConcurrentHandlingStarted()) {
            // Instead of postHandle and afterCompletion
            if (mappedHandler != null) {
                mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response);
            }
        }
        else {
            // Clean up any resources used by a multipart request.
            if (multipartRequestParsed) {
                cleanupMultipart(processedRequest);
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-MVC处理HTTP分发请求&quot; 图片1=&quot;&quot; src=&quot;http://img.mukewang.com/597f3b22000129d617520768.png&quot; style=&quot;width:100%&quot; alt=&quot;MVC处理HTTP分发请求&quot; /&gt;&lt;/p&gt;

&lt;p&gt;参考文献：&lt;/p&gt;

&lt;p&gt;《Spring技术内幕 深入解析Spring架构与设计原理》&lt;/p&gt;

</description>
        <pubDate>Wed, 26 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/java/2017/07/26/%E6%AD%BB%E7%A3%95Spring%E6%BA%90%E7%A0%81%E4%B9%8BSpring-MVC.html</link>
        <guid isPermaLink="true">http://localhost:4000/java/2017/07/26/%E6%AD%BB%E7%A3%95Spring%E6%BA%90%E7%A0%81%E4%B9%8BSpring-MVC.html</guid>
        
        <category>java</category>
        
        <category>Spring</category>
        
        <category>源码</category>
        
        <category>Spring MVC</category>
        
        
        <category>Java</category>
        
      </item>
    
      <item>
        <title>死磕Spring源码-AOP</title>
        <description>&lt;p&gt;在上一篇Spring源码的依赖注入总结中，我们可以清楚的知道DI有助于应用对象之间的解耦，这章我们来聊聊另外一种常见且有用的解耦方式，在比较大的系统中的日志管理、事务管理等功能，我们可以使用用面向切面编程的思想。在软件开发中，像日志这种散布在应用中多处的功能就是横切关注点，而AOP可以实现横切关注点与它们所影响的对象之间的解耦。&lt;/p&gt;

&lt;p&gt;在面向切面编程中，我们只需在一个地方定义通用的功能，然后以声明的方式定义这个功能（Advice）何时（Before、After or Around）要以何种方式在何处（Pointcut）应用，并且我们无需改变使用这个通用功能的类。这样做有两个好处：第一是把每个关注点集中在一个地方而不是分散到项目的各个地方去；第二是代码结构极其简洁，非常好维护，这对于骨子里就有极简主义的程序猿来说真是一大幸事！不得不佩服Spring团队（迷弟脸）….&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;AOP三个基本点&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Advice：通知，这定义了切入点的具体要干的事情，分为BeforeAdvice、AfterAdvice以及ThrowsAdvice。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;@Around(&quot;timeCost()”)//这时的timeCost()就是一个通知&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Pointcut：切点，这定义了切入点的位置，将需要增加的地方用某个正则表达式进行表示，或根据某个方法名来匹配。利用MethodMatcher中的matches方法来进行匹配判断，在JdkRegexpMethodPointcut中，matches方法实际上是通过JDK来实现正则表达式的匹配。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;@Pointcut(&quot;execution(public * com.intelligentler.shuitu.controller.*.*(..))”)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Advisor：通知器，把具体操作（通知）和待增强的位置（切点）结合起来，定义在哪一个关注点使用哪一个通知。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Aspect
@Component
@Order(-5)
public class TimeCostAspect {
    …….
} 这里的`TimeCostAspect`就不单单是一个POJO，而且还是一个切面。
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;这里有个单例模式的彩蛋：&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class DefaultPointcutAdvisor extends AbstractGenericPointcutAdvisor implements Serializable {
     private Pointcut pointcut = Pointcut.TRUE;
     public DefaultPointcutAdvisor() {
     }
     public DefaultPointcutAdvisor(Advice advice) {
          this(Pointcut.TRUE, advice);
     }
     public DefaultPointcutAdvisor(Pointcut pointcut, Advice advice) {
          this.pointcut = pointcut;
          setAdvice(advice);
     }
     public void setPointcut(Pointcut pointcut) {
          this.pointcut = (pointcut != null ? pointcut : Pointcut.TRUE);
     }
     @Override
     public Pointcut getPointcut() {
          return this.pointcut;
     }
     @Override
     public String toString() {
          return getClass().getName() + &quot;: pointcut [&quot; + getPointcut() + &quot;]; advice [&quot; + getAdvice() + &quot;]&quot;;
     }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;在DefaultPointcutAdvisor类中Pointcut被设置为Pointcut.TRUE;Pointcut.TRUE在Pointcut的定义如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//Pointcut.class
Pointcut TRUE = TruePointcut.INSTANCE;
//TruePointcut.class
class TruePointcut implements Pointcut, Serializable {
     public static final TruePointcut INSTANCE = new TruePointcut();
     private TruePointcut() {
     }
     @Override
     public ClassFilter getClassFilter() {
          return ClassFilter.TRUE;
     }
     @Override
     public MethodMatcher getMethodMatcher() {
          return MethodMatcher.TRUE;
     }
     private Object readResolve() {
          return INSTANCE;
     }
     @Override
     public String toString() {
          return &quot;Pointcut.TRUE&quot;;
     }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;重点来了：这里的TruePointcut INSTANCE是一个单例模式，使用static类变量来持有单例，再使用private私有构造函数来确保单例不会被再次创建和实例化。在这个类中的MethodMatcher.TRUE也是类似的单例实现。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;AOP的设计与实现&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Spring的AOP采用的是&lt;a href=&quot;https://zhoum1118.github.io/java/2017/06/22/%E6%AD%BB%E7%A3%95%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A7%82%E9%80%82%E4%BB%A3%E8%A3%85.html&quot;&gt;动态代理模式&lt;/a&gt;，Spring在代理类中包裹切面，在运行期间把切面织入到Bean中，也就是说Spring用代理类封装了目标类，同时拦截了被通知方法的调用，处理完通知（Advice）后，再把调用转发给真正的目标Bean，也正因为是动态代理，所以Spring的AOP只支持到方法连接点而无法提供字段和构造器接入点（AspectJ和JBoss可以），所以Spring无法创建细粒度的通知。&lt;/p&gt;

&lt;p&gt;根据Spring AOP的动态代理的过程，我们可以把AOP的设计分为两大块：第一，需要为目标对象建立代理对象（如何生成代理对象？）；第二，需要启动代理对象的拦截器来完成各种横切面的织入（如何织入横切面同时如何拦截对目标对象方法的调用？）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;什么是代理对象–AOP的动态代理&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Spring AOP的核心技术是动态代理，对于增强的对象方法，在用户调用这个对象方法（request）的时候其实是调用Spring AOP提前为其生成好的代理对象（Proxy）的相应方法，这个代理对象的方法实现就包含了preOperation—request—postOperation，通过对对象方法的这种拦截，增强了目标对象的方法操作，这种方式就是代理。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如何生成代理对象？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-AOP分析&quot; 图片1=&quot;&quot; src=&quot;http://img.mukewang.com/597dad5c00012f2713520784.png&quot; style=&quot;width:100%&quot; alt=&quot;死磕Spring源码-AOP分析&quot; /&gt;&lt;/p&gt;

&lt;p&gt;通过继承ProxyConfig、AdvisedSupport和ProxyCreatorSupport等基类的功能实现，具体的AOP代理对象的生成，根据不同的需要，分别由AspectJProxyFactory、ProxyFactoryBean和ProxyFactory来完成。对于需要AspectJ的AOP应用，AspectJProxyFactory起到了集成Spring和AspectJ的作用；对于使用Spring AOP的应用，ProxyFactoryBean和ProxyFactory都提供了AOP功能的封装，其中对于ProxyFactoryBean，可以在IOC容器中完成声明配置，而对于ProxyFactory则需要编程式地使用Spring AOP的功能。Spring的AspectJProxyFactory、ProxyFactoryBean和ProxyFactory封装了代理对象AopProxy的生成过程，代理对象的生成实现过程由JDK的Proxy和CGLIB第三方来实现。&lt;/p&gt;

&lt;p&gt;下面我们具体分析下ProxyFactoryBean，ProxyFactoryBean是一个FactoryBean，FactoryBean一般是如何生成Bean的呢？在调用getBean方法-&amp;gt;doGetBean方法中，我们可以看到无论是直接取单例的bean，还是创建单例、多例、自定义生命周期的bean，都会经过bean = getObjectForBeanInstance(sharedInstance, name, beanName, null);这个方法，深入进去会发现最终会调用FactoryBean的getObject方法生产指定Bean的实例对象（Spring中具体的getObject的实现方法有70多个），也就是说对于FactoryBean而言，调用getBean(String BeanName)得到的是具体某个Bean对象（在getObject中具体实现的）而不是FactoryBean对象本身，如果想得到FactoryBean对象本身，只需要加上&amp;amp;符号即可。在FactoryBean的实现原理中我们可以发现工厂模式和装饰器模式的具体应用。&lt;/p&gt;

&lt;p&gt;对于ProxyFactoryBean来说，生成代理对象，也是通过getObject方法封装（修饰）了对目标对象增加的增强处理。那么我们具体分析下ProxyFactoryBean中的getObject方法。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Override
public Object getObject() throws BeansException {
    //初始化通知器链
    initializeAdvisorChain();
    //区分singleton和prototype，生成对应的proxy代理对象
    if (isSingleton()) {
        return getSingletonInstance();
    }
    else {
        if (this.targetName == null) {
            logger.warn(&quot;Using non-singleton proxies with singleton targets is often undesirable. &quot; +
                    &quot;Enable prototype proxies by setting the 'targetName' property.&quot;);
        }
        return newPrototypeInstance();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里的初始化通知器链只发生在第一次通过ProxyFactoryBean去获取代理对象的时候，在initializeAdvisorChain方法里有一个标志位advisorChainInitialized来保证这一点。&lt;/p&gt;

&lt;p&gt;生成单例代理对象是在getSingletonInstance方法中完成的，它是生成AopProxy代理对象的调用入口。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private synchronized Object getSingletonInstance() {
    if (this.singletonInstance == null) {
        this.targetSource = freshTargetSource();
        if (this.autodetectInterfaces &amp;amp;&amp;amp; getProxiedInterfaces().length == 0 &amp;amp;&amp;amp; !isProxyTargetClass()) {
            // Rely on AOP infrastructure to tell us what interfaces to proxy.
            Class&amp;lt;?&amp;gt; targetClass = getTargetClass();
            if (targetClass == null) {
                throw new FactoryBeanNotInitializedException(&quot;Cannot determine target class for proxy&quot;);
            }
            setInterfaces(ClassUtils.getAllInterfacesForClass(targetClass, this.proxyClassLoader));
        }
        // Initialize the shared singleton instance.
        super.setFrozen(this.freezeProxy);
        //通过代理工厂来生成对应的代理对象
        this.singletonInstance = getProxy(createAopProxy());
    }
    return this.singletonInstance;
}

protected Object getProxy(AopProxy aopProxy) {
    return aopProxy.getProxy(this.proxyClassLoader);
}

protected final synchronized AopProxy createAopProxy() {
    if (!this.active) {
        activate();
    }
    //通过AopProxyFactory工厂类来获取Aop的代理对象AopProxy，生成什么样的代理对象由AdivisedSupport决定，AdivisedSupport作为参数传入createAopProxy方法中，这里表示为this。
    return getAopProxyFactory().createAopProxy(this);
}

@Override
public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException {
    if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) {
        //从AdvisedSupport中获取目标对象class
        Class&amp;lt;?&amp;gt; targetClass = config.getTargetClass();
        if (targetClass == null) {
            throw new AopConfigException(&quot;TargetSource cannot determine target class: &quot; +
                    &quot;Either an interface or a target is required for proxy creation.&quot;);
        }
        //如果targetClass是接口类则使用JDK来生成代理对象，否则使用CGLIB来生成。
        if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) {
            return new JdkDynamicAopProxy(config);
        }
        return new ObjenesisCglibAopProxy(config);
    }
    else {
    	//默认使用JDK来生成代理对象
        return new JdkDynamicAopProxy(config);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-AOP分析&quot; 图片2=&quot;&quot; src=&quot;http://img.mukewang.com/597dadc80001f1ff09520680.png&quot; style=&quot;width:100%&quot; alt=&quot;死磕Spring源码-AOP分析&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如何拦截对目标对象方法的调用？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;对于JDK的代理对象，拦截使用的是InvocationHandler的invoke回调入口；对于CGLIB的代理对象，拦截是有设置好的回调callback方法（intercept方法）来完成的。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Override
public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
    MethodInvocation invocation;
    Object oldProxy = null;
    boolean setProxyContext = false;

    TargetSource targetSource = this.advised.targetSource;
    Class&amp;lt;?&amp;gt; targetClass = null;
    Object target = null;

    try {
        if (!this.equalsDefined &amp;amp;&amp;amp; AopUtils.isEqualsMethod(method)) {
            // The target does not implement the equals(Object) method itself.
            return equals(args[0]);
        }
        else if (!this.hashCodeDefined &amp;amp;&amp;amp; AopUtils.isHashCodeMethod(method)) {
            // The target does not implement the hashCode() method itself.
            return hashCode();
        }
        else if (method.getDeclaringClass() == DecoratingProxy.class) {
            // There is only getDecoratedClass() declared -&amp;gt; dispatch to proxy config.
            return AopProxyUtils.ultimateTargetClass(this.advised);
        }
        else if (!this.advised.opaque &amp;amp;&amp;amp; method.getDeclaringClass().isInterface() &amp;amp;&amp;amp;
                method.getDeclaringClass().isAssignableFrom(Advised.class)) {
            // Service invocations on ProxyConfig with the proxy config...
            return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args);
        }

        Object retVal;

        if (this.advised.exposeProxy) {
            // Make invocation available if necessary.
            oldProxy = AopContext.setCurrentProxy(proxy);
            setProxyContext = true;
        }

        // 获取目标对象
        target = targetSource.getTarget();
        if (target != null) {
            targetClass = target.getClass();
        }

        // 获取拦截器链
        List&amp;lt;Object&amp;gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);

        // 如果没有设定拦截器则直接调用目标对象的对应方法
        if (chain.isEmpty()) {
            Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args);
            retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse);
        }
        else {
            // We need to create a method invocation...
            invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain);
            // Proceed to the joinpoint through the interceptor chain.
            retVal = invocation.proceed();
        }

        // Massage return value if necessary.
        Class&amp;lt;?&amp;gt; returnType = method.getReturnType();
        if (retVal != null &amp;amp;&amp;amp; retVal == target &amp;amp;&amp;amp; returnType.isInstance(proxy) &amp;amp;&amp;amp;
                !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) {
            // Special case: it returned &quot;this&quot; and the return type of the method
            // is type-compatible. Note that we can't help if the target sets
            // a reference to itself in another returned object.
            retVal = proxy;
        }
        else if (retVal == null &amp;amp;&amp;amp; returnType != Void.TYPE &amp;amp;&amp;amp; returnType.isPrimitive()) {
            throw new AopInvocationException(
                    &quot;Null return value from advice does not match primitive return type for: &quot; + method);
        }
        return retVal;
    }
    finally {
        if (target != null &amp;amp;&amp;amp; !targetSource.isStatic()) {
            // Must have come from TargetSource.
            targetSource.releaseTarget(target);
        }
        if (setProxyContext) {
            // Restore old proxy.
            AopContext.setCurrentProxy(oldProxy);
        }
    }
}

@Override
public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable {
    Object oldProxy = null;
    boolean setProxyContext = false;
    Class&amp;lt;?&amp;gt; targetClass = null;
    Object target = null;
    try {
        if (this.advised.exposeProxy) {
            // Make invocation available if necessary.
            oldProxy = AopContext.setCurrentProxy(proxy);
            setProxyContext = true;
        }
        // May be null. Get as late as possible to minimize the time we
        // &quot;own&quot; the target, in case it comes from a pool...
        target = getTarget();
        if (target != null) {
            targetClass = target.getClass();
        }
        //获取AOP通知
        List&amp;lt;Object&amp;gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);
        Object retVal;
        // 如果没有配置AOP通知，则直接调用目标对象的对应方法
        if (chain.isEmpty() &amp;amp;&amp;amp; Modifier.isPublic(method.getModifiers())) {
            Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args);
            retVal = methodProxy.invoke(target, argsToUse);
        }
        else {
            // 启动AOP通知
            retVal = new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed();
        }
        retVal = processReturnType(proxy, target, method, retVal);
        return retVal;
    }
    finally {
        if (target != null) {
            releaseTarget(target);
        }
        if (setProxyContext) {
            // Restore old proxy.
            AopContext.setCurrentProxy(oldProxy);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;不管用什么方法生成的代理对象，（在invoke或intercept方法中）对拦截器的调用都是通过proceed方法实现的，在proceed方法中完成对目标对象的增强功能，这种实现是通过运行逐个具体的拦截器的拦截方法来完成的。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Override
public Object proceed() throws Throwable {
    // 从索引为-1的拦截器开始调用，并按序递增，拦截器方法调用完毕则开始调用目标对象的方法
    if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) {
        return invokeJoinpoint();
    }

    Object interceptorOrInterceptionAdvice =
            this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex);
    if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) {
        InterceptorAndDynamicMethodMatcher dm =
                (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice;
        // 判断拦截器的拦截方法是否匹配当前的调用方法，匹配则调用拦截器（invoke）方法方法
        if (dm.methodMatcher.matches(this.method, this.targetClass, this.arguments)) {
            return dm.interceptor.invoke(this);
        }
        else {
            // 不匹配则递归调用proceed
            return proceed();
        }
    }
    else {
        return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;首先会根据配置来判断拦截器是否与当前的调用方法相匹配（matches），如果当前的调用方法与配置的拦截器相匹配，那么相应的拦截器就开始发挥作用。这个过程是一个递归遍历的过程，它会遍历在代理对象中设置的拦截器链中所有的拦截器，被匹配的拦截器被逐一调用，直到所有的拦截器都被遍历完，才是对目标对象的方法调用，这样就完成了对目标对象方法调用的增强。&lt;/p&gt;

&lt;p&gt;应该注意到，Advice通知不是直接对目标对象作用来完成增强的，而是对不同种类的通知通过AdviceAdapter适配器来实现的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考文献：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;《Spring实战》&lt;/p&gt;

&lt;p&gt;《Spring技术内幕 深入解析Spring架构与设计原理》&lt;/p&gt;

</description>
        <pubDate>Fri, 21 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/java/2017/07/21/%E6%AD%BB%E7%A3%95Spring%E6%BA%90%E7%A0%81%E4%B9%8BAOP.html</link>
        <guid isPermaLink="true">http://localhost:4000/java/2017/07/21/%E6%AD%BB%E7%A3%95Spring%E6%BA%90%E7%A0%81%E4%B9%8BAOP.html</guid>
        
        <category>java</category>
        
        <category>Spring</category>
        
        <category>源码</category>
        
        <category>AOP</category>
        
        
        <category>Java</category>
        
      </item>
    
      <item>
        <title>死磕设计模式-工厂模式</title>
        <description>&lt;p&gt;上篇我们讲了观察者模式、适配器模式和代理模式，在Java中应用很多的还有一个工厂模式，工厂模式分很多种，所以我们单列一篇文章来总结。&lt;/p&gt;

&lt;p&gt;工厂模式&lt;/p&gt;

&lt;p&gt;1、 传统方式&lt;/p&gt;

&lt;p&gt;传统要获取一个类的对象，通常的方法是在本类中通过一个new操作符产生一个指定类的对象实例。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class Produce1 {  
    public Produce1(){  
        //Produce1的构造函数
    }  
}  

public class Produce2 {  
    public Produce2(){  
        //Produce2的构造函数
    }  
}  

public class Client {  
    public static void main(String[] args) {  
        Produce1 p1 = new Produce1();  
        Produce2 p2 = new Produce2();  
    }  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;很显然如果用上面的方式获取少数的Produce的对象是可行的，但多了就不行了，而且会导致类与类之间的耦合度非常高，于是出现了工厂模式，工厂模式就是屏蔽创建对象的具体过程，用户只需要调用工厂方法就可以得到对象的实例。&lt;/p&gt;

&lt;p&gt;工厂模式按其复杂程度分为三类：简单工厂、工厂、抽象工厂模式。&lt;/p&gt;

&lt;p&gt;2、  简单工厂模式&lt;/p&gt;

&lt;p&gt;特点：&lt;/p&gt;

&lt;p&gt;一个抽象产品类，可以派生出多个具体产品类。&lt;/p&gt;

&lt;p&gt;一个具体工厂类，用于生产产品。&lt;/p&gt;

&lt;p&gt;简单工厂模式的类图如下：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕设计模式-工厂模式&quot; 图片1=&quot;&quot; src=&quot;http://img.mukewang.com/597869370001b2f717940376.png&quot; style=&quot;width:100%&quot; alt=&quot;简单工厂模式的类图&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Java代码如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;abstract class Produce {  
    public create();
}  

public class Produce1 extends Produce {  
    public create() {  
        System.out.println(&quot;生产Produce1&quot;);  
    }  
}  
public class Produce2 extends Produce{  
    public create(){  
        System.out.println(&quot;生产Produce2&quot;);  
    }  
}  

public class Factory {  
    public Produce createProduce(int type) {  
        switch (type) {  

        case 1:  
            return new Produce1().create();  

        case 2:  
            return new Produce2().create();  

        default:  
            break;  
        }  
        return null;  
    }  
}  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;3、 工厂模式&lt;/p&gt;

&lt;p&gt;特点：&lt;/p&gt;

&lt;p&gt;一个抽象产品类，可以派生出多个具体产品类。&lt;/p&gt;

&lt;p&gt;一个抽象工厂类，可以派生出多个具体工厂类。&lt;/p&gt;

&lt;p&gt;每个具体工厂类只能创建一个具体产品类的实例。&lt;/p&gt;

&lt;p&gt;工厂模式的类图如下：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕设计模式-工厂模式&quot; 图片2=&quot;&quot; src=&quot;http://img.mukewang.com/5978697c00011f5820700340.png&quot; style=&quot;width:100%&quot; alt=&quot;工厂模式的类图&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Java代码如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;abstract class Produce {  
    public create();
}  
public class Produce1 extends Produce {  
    public create() {  
        System.out.println(&quot;生产Produce1&quot;);  
    }  
}  
public class Produce2 extends Produce{  
    public create(){  
        System.out.println(&quot;生产Produce2&quot;);  
    }  
}  
interface Factory {  
    Produce createProduce();  
}  

public class Factory1 implements Factory{  

    public void createProduce() {  
        return new Produce1().create();  
    }  

}  
public class Factory2 implements Factory {  

    public void createProduce() {  
        return new Produce2().create();  
    }  
} 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;4、 抽象工厂模式&lt;/p&gt;

&lt;p&gt;特点：&lt;/p&gt;

&lt;p&gt;多个抽象产品类，每个抽象产品类可以派生出多个具体产品类。&lt;/p&gt;

&lt;p&gt;一个抽象工厂类，可以派生出多个具体工厂类。&lt;/p&gt;

&lt;p&gt;每个具体工厂类可以创建多个具体产品类的实例。&lt;/p&gt;

&lt;p&gt;抽象工厂模式的类图如下：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕设计模式-工厂模式&quot; 图片3=&quot;&quot; src=&quot;http://img.mukewang.com/597869ae000133b021240638.png&quot; style=&quot;width:100%&quot; alt=&quot;抽象工厂模式的类图&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Java代码如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;interface ProductA {

    void create();
}

interface ProductB {

    void create();
}

class ProductA1 implements ProductA{

    public void create() {
        System.out.println(&quot;生产ProductA1&quot;);
    }

}

class ProductA2 implements ProductA{

    public void create() {
        System.out.println(&quot;生产ProductA2&quot;);
    }

}

class ProductB1 implements ProductB{

    public void create() {
        System.out.println(&quot;生产ProductB1&quot;);
    }

}

class ProductB2 implements ProductB{

    public void create() {
        System.out.println(&quot;生产ProductB2&quot;);
    }

}
public interface Factory {

    ProductA createProductA();

    ProductB createProductB();

}
public class Factory1 implements Factory{

    public ProductA createProductA() {
        return new ProductA1();
    }

    public ProductB createProductB() {
        return new ProductB1();
    }

}

public class Factory2 implements Factory{

    public ProductA createProductA() {
        return new ProductA2();
    }

    public ProductB createProductB() {
        return new ProductB2();
    }

}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;在Java的JDK中，我们能找到一个很典型的抽象工厂模型：迭代器。在Java JDK 1.2 引进了一个容器类接口，其中包含了一个iterator()方法，所有容器类均实现了该方法，iterator方法是一个工厂方法，它使得调用者不知道iterator对象是由哪个类实例化的。&lt;/p&gt;

&lt;p&gt;比如list.iterator()；set.iterator()；我们不必关心iterator方法返回值是什么，只需要知道迭代器支持什么样的容器接口，才能遍历出集合中的元素。&lt;/p&gt;

&lt;p&gt;List的Iterator的抽象工厂模式类图：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕设计模式-工厂模式&quot; 图片4=&quot;&quot; src=&quot;http://img.mukewang.com/597869df0001fc1019820516.png&quot; style=&quot;width:100%&quot; alt=&quot;List的Iterator的抽象工厂模式类图&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 18 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/java/2017/07/18/%E6%AD%BB%E7%A3%95%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F.html</link>
        <guid isPermaLink="true">http://localhost:4000/java/2017/07/18/%E6%AD%BB%E7%A3%95%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F.html</guid>
        
        <category>java</category>
        
        <category>设计模式</category>
        
        <category>工厂模式</category>
        
        
        <category>Java</category>
        
      </item>
    
      <item>
        <title>死磕Spring源码-依赖注入</title>
        <description>&lt;p&gt;上篇文章我们分析了IOC容器的初始化，可以看出初始化其实就是在IoC容器中建立BeanDefinition数据映射，但并没有对Bean的依赖关系进行注入，依赖注入是用户第一次向IoC容器索要Bean的时候触发的，调用BeanFactory的getBean方法将触发依赖注入，这个时候才会创建对象实例，也可以通过设置bean的lazy-init属性来让bean的实例化过程在容器初始化的过程就完成，如果通过设置Bean的lazy-init属性，那么在容器初始化这个bean的时候就会调用getBean去触发依赖注入。&lt;/p&gt;

&lt;p&gt;如果doGetBean方法在当前的IoC容器中找不到Bean，会到双亲BeanFactory中去取，如果当前的双亲容器找不到那就再顺着双亲BeanFactory链一直向上寻找。&lt;/p&gt;

&lt;p&gt;get某一个Bean的时候会依赖注入其所依赖的所有的Bean，触发getBean的递归调用，直到取到一个没有任何依赖的bean为止。&lt;/p&gt;

&lt;p&gt;依赖注入实现过程图：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-依赖注入&quot; 图片1=&quot;&quot; src=&quot;http://img.mukewang.com/59770a0900018d2e17240986.png&quot; style=&quot;width:100%&quot; alt=&quot;依赖注入实现过程图&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final Object[] args) {
     // BeanWrapper是用来持有创建出来的Bean对象的
     BeanWrapper instanceWrapper = null;
     //如果是单例，则将缓存中的同名Bean清除
     if (mbd.isSingleton()) {
          instanceWrapper = this.factoryBeanInstanceCache.remove(beanName);
     }
     if (instanceWrapper == null) {
     		//创建Bean实例对象
          instanceWrapper = createBeanInstance(beanName, mbd, args);
     }
     final Object bean = (instanceWrapper != null ? instanceWrapper.getWrappedInstance() : null);
     Class&amp;lt;?&amp;gt; beanType = (instanceWrapper != null ? instanceWrapper.getWrappedClass() : null);

     // Allow post-processors to modify the merged bean definition.
     synchronized (mbd.postProcessingLock) {
          if (!mbd.postProcessed) {
               applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName);
               mbd.postProcessed = true;
          }
     }

     // Eagerly cache singletons to be able to resolve circular references
     // even when triggered by lifecycle interfaces like BeanFactoryAware.
     boolean earlySingletonExposure = (mbd.isSingleton() &amp;amp;&amp;amp; this.allowCircularReferences &amp;amp;&amp;amp;
               isSingletonCurrentlyInCreation(beanName));
     if (earlySingletonExposure) {
          if (logger.isDebugEnabled()) {
               logger.debug(&quot;Eagerly caching bean '&quot; + beanName +
                         &quot;' to allow for resolving potential circular references&quot;);
          }
          addSingletonFactory(beanName, new ObjectFactory&amp;lt;Object&amp;gt;() {
               @Override
               public Object getObject() throws BeansException {
                    return getEarlyBeanReference(beanName, mbd, bean);
               }
          });
     }

     // 初始化Bean实例，执行依赖注入
     Object exposedObject = bean;
     try {
          populateBean(beanName, mbd, instanceWrapper);
          if (exposedObject != null) {
               exposedObject = initializeBean(beanName, exposedObject, mbd);
          }
     }
     catch (Throwable ex) {
          if (ex instanceof BeanCreationException &amp;amp;&amp;amp; beanName.equals(((BeanCreationException) ex).getBeanName())) {
               throw (BeanCreationException) ex;
          }
          else {
               throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Initialization of bean failed&quot;, ex);
          }
     }

     if (earlySingletonExposure) {
          Object earlySingletonReference = getSingleton(beanName, false);
          if (earlySingletonReference != null) {
               if (exposedObject == bean) {
                    exposedObject = earlySingletonReference;
               }
               else if (!this.allowRawInjectionDespiteWrapping &amp;amp;&amp;amp; hasDependentBean(beanName)) {
                    String[] dependentBeans = getDependentBeans(beanName);
                    Set&amp;lt;String&amp;gt; actualDependentBeans = new LinkedHashSet&amp;lt;String&amp;gt;(dependentBeans.length);
                    for (String dependentBean : dependentBeans) {
                         if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) {
                              actualDependentBeans.add(dependentBean);
                         }
                    }
                    if (!actualDependentBeans.isEmpty()) {
                         throw new BeanCurrentlyInCreationException(beanName,
                                   &quot;Bean with name '&quot; + beanName + &quot;' has been injected into other beans [&quot; +
                                   StringUtils.collectionToCommaDelimitedString(actualDependentBeans) +
                                   &quot;] in its raw version as part of a circular reference, but has eventually been &quot; +
                                   &quot;wrapped. This means that said other beans do not use the final version of the &quot; +
                                   &quot;bean. This is often the result of over-eager type matching - consider using &quot; +
                                   &quot;'getBeanNamesOfType' with the 'allowEagerInit' flag turned off, for example.&quot;);
                    }
               }
          }
     }

     // Register bean as disposable.
     try {
          registerDisposableBeanIfNecessary(beanName, bean, mbd);
     }
     catch (BeanDefinitionValidationException ex) {
          throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Invalid destruction signature&quot;, ex);
     }

     return exposedObject;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;依赖注入比较重要的两个方法：createBeanInstance和populateBean&lt;/p&gt;

&lt;p&gt;createBeanInstance实例化Bean对象的方法调用栈：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-依赖注入&quot; 图片2=&quot;&quot; src=&quot;http://img.mukewang.com/597706160001eb1617380344.png&quot; style=&quot;width:100%&quot; alt=&quot;createBeanInstance方法调用栈&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, Object[] args) {
    // Make sure bean class is actually resolved at this point.
    Class&amp;lt;?&amp;gt; beanClass = resolveBeanClass(mbd, beanName);

    if (beanClass != null &amp;amp;&amp;amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;amp;&amp;amp; !mbd.isNonPublicAccessAllowed()) {
        throw new BeanCreationException(mbd.getResourceDescription(), beanName,
                &quot;Bean class isn't public, and non-public access not allowed: &quot; + beanClass.getName());
    }

    if (mbd.getFactoryMethodName() != null)  {
        return instantiateUsingFactoryMethod(beanName, mbd, args);
    }

    // Shortcut when re-creating the same bean...
    boolean resolved = false;
    boolean autowireNecessary = false;
    if (args == null) {
        synchronized (mbd.constructorArgumentLock) {
            if (mbd.resolvedConstructorOrFactoryMethod != null) {
                resolved = true;
                autowireNecessary = mbd.constructorArgumentsResolved;
            }
        }
    }
    if (resolved) {
        if (autowireNecessary) {
            return autowireConstructor(beanName, mbd, null, null);
        }
        else {
            return instantiateBean(beanName, mbd);
        }
    }

    // Need to determine the constructor...
    Constructor&amp;lt;?&amp;gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName);
    if (ctors != null ||
            mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR ||
            mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args))  {
        return autowireConstructor(beanName, mbd, ctors, args);
    }

    // No special handling: simply use no-arg constructor.
    return instantiateBean(beanName, mbd);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;createBeanInstance中生成了Bean所包含的Java对象，Spring中用SimpleInstantiationStrategy类来生成Bean对象的实例，实例化Java对象的方法有两种：&lt;/p&gt;

&lt;p&gt;1、通过BeanUtils，它使用了JVM的反射功能来生成Java对象实例&lt;/p&gt;

&lt;p&gt;2、用CGLIB来生成，CGLIB是一种常用的字节码生成器的类库&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Override
public Object instantiate(RootBeanDefinition bd, String beanName, BeanFactory owner) {
     // Don't override the class with CGLIB if no overrides.
     if (bd.getMethodOverrides().isEmpty()) {
          Constructor&amp;lt;?&amp;gt; constructorToUse;
          synchronized (bd.constructorArgumentLock) {
               constructorToUse = (Constructor&amp;lt;?&amp;gt;) bd.resolvedConstructorOrFactoryMethod;
               if (constructorToUse == null) {
                    final Class&amp;lt;?&amp;gt; clazz = bd.getBeanClass();
                    if (clazz.isInterface()) {
                         throw new BeanInstantiationException(clazz, &quot;Specified class is an interface&quot;);
                    }
                    try {
                         if (System.getSecurityManager() != null) {
                              constructorToUse = AccessController.doPrivileged(new PrivilegedExceptionAction&amp;lt;Constructor&amp;lt;?&amp;gt;&amp;gt;() {
                                   @Override
                                   public Constructor&amp;lt;?&amp;gt; run() throws Exception {
                                        return clazz.getDeclaredConstructor((Class[]) null);
                                   }
                              });
                         }
                         else {
                              constructorToUse =     clazz.getDeclaredConstructor((Class[]) null);
                         }
                         bd.resolvedConstructorOrFactoryMethod = constructorToUse;
                    }
                    catch (Throwable ex) {
                         throw new BeanInstantiationException(clazz, &quot;No default constructor found&quot;, ex);
                    }
               }
          }
		  //通过BeanUtils进行实例化，从这个方法中可以看到具体调用了ctor.newInstance()方法
          return BeanUtils.instantiateClass(constructorToUse);
     }
     else {
          // 使用CGLIB来实例化对象
          return instantiateWithMethodInjection(bd, beanName, owner);
     }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Bean对象生成好了之后，Spring用BeanWrapper来持有创建出来的Bean对象，接下来Spring通过populateBean方法来把这些Bean对象的依赖关系设置好，以完成整个依赖注入的过程。&lt;/p&gt;

&lt;p&gt;依赖注入的发生是在BeanWrapper的setPropertyValues中，具体的实现过程在其子类BeanWrapperImpl；createBeanInstance方法返回值就是一个BeanWrapper对象。再把BeanWrapper对象作为一个形参传入populateBean中。populateBean是对Bean的初始化，依赖注入就发生在这里。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;protected void populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw) {
     //这里通过解析BeanDefinition来获取property值
     PropertyValues pvs = mbd.getPropertyValues();

     if (bw == null) {
          if (!pvs.isEmpty()) {
               throw new BeanCreationException(
                         mbd.getResourceDescription(), beanName, &quot;Cannot apply property values to null instance&quot;);
          }
          else {
               // Skip property population phase for null instance.
               return;
          }
     }

     // Give any InstantiationAwareBeanPostProcessors the opportunity to modify the
     // state of the bean before properties are set. This can be used, for example,
     // to support styles of field injection.
     boolean continueWithPropertyPopulation = true;

     if (!mbd.isSynthetic() &amp;amp;&amp;amp; hasInstantiationAwareBeanPostProcessors()) {
          for (BeanPostProcessor bp : getBeanPostProcessors()) {
               if (bp instanceof InstantiationAwareBeanPostProcessor) {
                    InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp;
                    if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) {
                         continueWithPropertyPopulation = false;
                         break;
                    }
               }
          }
     }

     if (!continueWithPropertyPopulation) {
          return;
     }
     //开始进行依赖注入的过程，先处理autowire的注入，可以根据Bean的名字或类型来完成Bean的autowire
     if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME ||
               mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) {
          MutablePropertyValues newPvs = new MutablePropertyValues(pvs);

          // Add property values based on autowire by name if applicable.
          if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME) {
               autowireByName(beanName, mbd, bw, newPvs);
          }

          // Add property values based on autowire by type if applicable.
          if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) {
               autowireByType(beanName, mbd, bw, newPvs);
          }

          pvs = newPvs;
     }

     boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors();
     boolean needsDepCheck = (mbd.getDependencyCheck() != RootBeanDefinition.DEPENDENCY_CHECK_NONE);

     if (hasInstAwareBpps || needsDepCheck) {
          PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching);
          if (hasInstAwareBpps) {
               for (BeanPostProcessor bp : getBeanPostProcessors()) {
                    if (bp instanceof InstantiationAwareBeanPostProcessor) {
                         InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp;
                         pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName);
                         if (pvs == null) {
                              return;
                         }
                    }
               }
          }
          if (needsDepCheck) {
               checkDependencies(beanName, mbd, filteredPds, pvs);
          }
     }
     //对属性进行注入
     applyPropertyValues(beanName, mbd, bw, pvs);
}

protected void applyPropertyValues(String beanName, BeanDefinition mbd, BeanWrapper bw, PropertyValues pvs) {
     if (pvs == null || pvs.isEmpty()) {
          return;
     }

     MutablePropertyValues mpvs = null;
     List&amp;lt;PropertyValue&amp;gt; original;

     if (System.getSecurityManager() != null) {
          if (bw instanceof BeanWrapperImpl) {
               ((BeanWrapperImpl) bw).setSecurityContext(getAccessControlContext());
          }
     }

     if (pvs instanceof MutablePropertyValues) {
          mpvs = (MutablePropertyValues) pvs;
          if (mpvs.isConverted()) {
               // Shortcut: use the pre-converted values as-is.
               try {
                    bw.setPropertyValues(mpvs);
                    return;
               }
               catch (BeansException ex) {
                    throw new BeanCreationException(
                              mbd.getResourceDescription(), beanName, &quot;Error setting property values&quot;, ex);
               }
          }
          original = mpvs.getPropertyValueList();
     }
     else {
          original = Arrays.asList(pvs.getPropertyValues());
     }

     TypeConverter converter = getCustomTypeConverter();
     if (converter == null) {
          converter = bw;
     }
     //对BeanDefinition的解析是在这个valueResolver中完成的
     BeanDefinitionValueResolver valueResolver = new BeanDefinitionValueResolver(this, beanName, mbd, converter);

     // Create a deep copy, resolving any references for values.
     List&amp;lt;PropertyValue&amp;gt; deepCopy = new ArrayList&amp;lt;PropertyValue&amp;gt;(original.size());
     boolean resolveNecessary = false;
     for (PropertyValue pv : original) {
          if (pv.isConverted()) {
               deepCopy.add(pv);
          }
          else {
               String propertyName = pv.getName();
               Object originalValue = pv.getValue();
               //解析BeanDefinition
               Object resolvedValue = valueResolver.resolveValueIfNecessary(pv, originalValue);
               Object convertedValue = resolvedValue;
               boolean convertible = bw.isWritableProperty(propertyName) &amp;amp;&amp;amp;
                         !PropertyAccessorUtils.isNestedOrIndexedProperty(propertyName);
               if (convertible) {
                    convertedValue = convertForProperty(resolvedValue, propertyName, bw, converter);
               }
               // Possibly store converted value in merged bean definition,
               // in order to avoid re-conversion for every created bean instance.
               if (resolvedValue == originalValue) {
                    if (convertible) {
                         pv.setConvertedValue(convertedValue);
                    }
                    deepCopy.add(pv);
               }
               else if (convertible &amp;amp;&amp;amp; originalValue instanceof TypedStringValue &amp;amp;&amp;amp;
                         !((TypedStringValue) originalValue).isDynamic() &amp;amp;&amp;amp;
                         !(convertedValue instanceof Collection || ObjectUtils.isArray(convertedValue))) {
                    pv.setConvertedValue(convertedValue);
                    deepCopy.add(pv);
               }
               else {
                    resolveNecessary = true;
                    deepCopy.add(new PropertyValue(pv, convertedValue));
               }
          }
     }
     if (mpvs != null &amp;amp;&amp;amp; !resolveNecessary) {
          mpvs.setConverted();
     }

     // Set our (possibly massaged) deep copy.
     try {
          bw.setPropertyValues(new MutablePropertyValues(deepCopy));
     }
     catch (BeansException ex) {
          throw new BeanCreationException(
                    mbd.getResourceDescription(), beanName, &quot;Error setting property values&quot;, ex);
     }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;populateBean解析BeanDefinition中设置的property值，获取到Bean的依赖信息并设置Bean的依赖关系。通过使用BeanDefinitionResolver对BeanDefinition进行解析，然后注入到property中。&lt;/p&gt;

&lt;p&gt;resolveValueIfNecessary方法包含了对所有的注入类型的处理，里面包含各种instanceof的判断，比如RuntimeBeanReference，Array，List，Map等数据类型，RuntimeBeanReference是在对BeanDefinition进行解析时生成的数据对象，是在载入BeanDefinition时根据配置生成的，如果RuntimeBeanReference是在双亲容器中则从双亲容器中去获取Bean（通过getBean方法）。&lt;/p&gt;

&lt;p&gt;完成解析过程后就已经是为依赖注入做好了准备条件，依赖注入的发生是在BeanWrapper的setPropertyValues中，具体的实现过程在其子类BeanWrapperImpl。&lt;/p&gt;

&lt;p&gt;setPropertyValue的方法调用栈：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-依赖注入&quot; 图片3=&quot;&quot; src=&quot;http://img.mukewang.com/597707120001cc6617260690.png&quot; style=&quot;width:100%&quot; alt=&quot;setPropertyValue的方法调用栈&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;总结：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一、依赖注入的概念和触发方法（getBean）&lt;/p&gt;

&lt;p&gt;二、依赖注入有两个重要的方法：createBeanInstance和populateBean&lt;/p&gt;

&lt;p&gt;—&amp;gt;以beanName、BeanDefinition等作为输入，执行
&lt;code class=&quot;highlighter-rouge&quot;&gt;BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, Object[] args)&lt;/code&gt;
创建BeanWrapper实例，BeanWrapper持有创建出来的Bean对象，在方法中调用&lt;code class=&quot;highlighter-rouge&quot;&gt;Object instantiate(RootBeanDefinition bd, String beanName, BeanFactory owner) &lt;/code&gt;来生成Bean对象。Spring有两种方式生成Bean对象，
第一是通过BeanUtils，它使用了JVM的反射功能来生成Java对象实例。
第二是用CGLIB来生成，CGLIB是一种常用的字节码生成器的类库。&lt;/p&gt;

&lt;p&gt;—&amp;gt;以createBeanInstance生成好的BeanWrapper对象作为输入，执行&lt;code class=&quot;highlighter-rouge&quot;&gt;void populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw)&lt;/code&gt;
完成依赖注入过程；&lt;/p&gt;

&lt;p&gt;—&amp;gt;在方法populateBean中， 通过&lt;code class=&quot;highlighter-rouge&quot;&gt;PropertyValues pvs = mbd.getPropertyValues();&lt;/code&gt;
解析BeanDefinition来获取property值；&lt;/p&gt;

&lt;p&gt;—&amp;gt;以上一步获得的PropertyValues和BeanWrapper对象等作为输入，执行&lt;code class=&quot;highlighter-rouge&quot;&gt;void applyPropertyValues(String beanName, BeanDefinition mbd, BeanWrapper bw, PropertyValues pvs)&lt;/code&gt;完成属性的注入；&lt;/p&gt;

&lt;p&gt;—&amp;gt;在方法applyPropertyValues中，调用&lt;code class=&quot;highlighter-rouge&quot;&gt;bw.setPropertyValues(mpvs);&lt;/code&gt;完成属性的注入；以beanName和BeanDefinition作为输入，调用&lt;code class=&quot;highlighter-rouge&quot;&gt;BeanDefinitionValueResolver valueResolver = new BeanDefinitionValueResolver(this, beanName, mbd, converter);&lt;/code&gt;生成BeanDefinitionValueResolver对象，这个对象用来解析BeanDefinition；调用
&lt;code class=&quot;highlighter-rouge&quot;&gt;Object resolvedValue = valueResolver.resolveValueIfNecessary(pv, originalValue);&lt;/code&gt;解析BeanDefinition，然后通过&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Object convertedValue = resolvedValue;
pv.setConvertedValue(convertedValue);
deepCopy.add(pv);
bw.setPropertyValues(new MutablePropertyValues(deepCopy)); 注入到BeanWrapper对象的property中。
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;至此我们就完成了BeanDefinition的依赖注入，生成了Bean的持有对象BeanWrapper，用getWrappedInstance()方法就可以得到这个封装的bean的实例。BeanWrapperImpl里面的Object就是BeanWrapper“包裹”的bean，通过getWrappedInstance()方法对外提供。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考文献：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;1、Spring 4.3.3源码&lt;/p&gt;

&lt;p&gt;2、《Spring技术内幕 深入解析Spring架构与设计原理》&lt;/p&gt;

</description>
        <pubDate>Thu, 13 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/java/2017/07/13/%E6%AD%BB%E7%A3%95Spring%E6%BA%90%E7%A0%81%E4%B9%8B%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5.html</link>
        <guid isPermaLink="true">http://localhost:4000/java/2017/07/13/%E6%AD%BB%E7%A3%95Spring%E6%BA%90%E7%A0%81%E4%B9%8B%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5.html</guid>
        
        <category>java</category>
        
        <category>Spring</category>
        
        <category>源码</category>
        
        <category>依赖注入</category>
        
        
        <category>Java</category>
        
      </item>
    
      <item>
        <title>死磕Spring源码-IoC容器</title>
        <description>&lt;p&gt;我们都知道IoC（Inversion of control）是控制反转，控制反转的核心是依赖反转，那到底什么是“依赖反转”，“哪些方面的控制被反转了？”－－依赖对象的获得被反转了。通过依赖注入的方式获取类对象实例而不是传统的在类自身通过新建（new）类对象来获取。所以这种反转是“责任”的反转，传统的这种对对象的管理是由java类自身来管理，而Spring通过IoC容器来管理，这种对对象的依赖关系的管理被反转了，转到IoC容器来了。对象之间的相互依赖关系由IoC容器进行管理，并由IoC容器完成对象的注入。这种做法降低了类之间的耦合度，同时提高了代码的可测试性。&lt;/p&gt;

&lt;p&gt;IoC容器主要有两个容器系列：BeanFactory和ApplicationContext。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;IoC容器主要的接口设计图：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-IoC源码&quot; 图片1=&quot;&quot; src=&quot;http://img.mukewang.com/59744b1b0001c33d17101006.png&quot; style=&quot;width:100%&quot; alt=&quot;死磕Spring源码-IoC源码&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;一、BeanFactory&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;接口类BeanFactory提供了Spring中所有IOC容器的最基本的功能规范，来看看&lt;strong&gt;BeanFactory的组织结构图&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-IoC源码&quot; 图片2=&quot;&quot; src=&quot;http://img.mukewang.com/597444f50001bb0106261194.png&quot; style=&quot;width:50%&quot; alt=&quot;死磕Spring源码-IoC源码&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public interface BeanFactory {
    //如果我们加了这个转义字符，则得到的是这个IOC容器本身，否则得到的是IOC容器的实例
     String FACTORY_BEAN_PREFIX = “&amp;amp;”;
     Object getBean(String name) throws BeansException;
     &amp;lt;T&amp;gt; T getBean(String name, Class&amp;lt;T&amp;gt; requiredType) throws BeansException;
     &amp;lt;T&amp;gt; T getBean(Class&amp;lt;T&amp;gt; requiredType) throws BeansException;
     Object getBean(String name, Object... args) throws BeansException;
     &amp;lt;T&amp;gt; T getBean(Class&amp;lt;T&amp;gt; requiredType, Object... args) throws BeansException;
     boolean containsBean(String name);
     boolean isSingleton(String name) throws NoSuchBeanDefinitionException;
     boolean isPrototype(String name) throws NoSuchBeanDefinitionException;
     boolean isTypeMatch(String name, ResolvableType typeToMatch) throws NoSuchBeanDefinitionException;
     boolean isTypeMatch(String name, Class&amp;lt;?&amp;gt; typeToMatch) throws NoSuchBeanDefinitionException;
     Class&amp;lt;?&amp;gt; getType(String name) throws NoSuchBeanDefinitionException;
     String[] getAliases(String name);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;所有的IoC容器都需要满足BeanFactory这个基本的接口定义，Spring通过定义BeanDefinition来管理基于Spring的应用中的各种对象以及它们之间的相互依赖关系。对IoC容器来说，BeanDefinition抽象了对Bean的定义的一种数据类型。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;BeanDefinition的组织结构如下图：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-IoC源码&quot; 图片3=&quot;&quot; src=&quot;http://img.mukewang.com/59744544000144cd06161220.png&quot; style=&quot;width:50%&quot; alt=&quot;死磕Spring源码-IoC源码&quot; /&gt;&lt;/p&gt;

&lt;p&gt;BeanFactory是一个接口类，我们来看看一个BeanFactory的具体实现类XmlBeanFactory，从名字上就能看出来这是一个与xml相关的BeanFactory，它是一个可以读取以XML文件方式定义的BeanDefinition的IoC容器。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-IoC源码&quot; 图片4=&quot;&quot; src=&quot;http://img.mukewang.com/597445bc000120d818280524.png&quot; style=&quot;width:100%&quot; alt=&quot;死磕Spring源码-IoC源码&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class XmlBeanFactory extends DefaultListableBeanFactory {

     private final XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(this);

     public XmlBeanFactory(Resource resource) throws BeansException {
          this(resource, null);
     }

     public XmlBeanFactory(Resource resource, BeanFactory parentBeanFactory) throws BeansException {
          super(parentBeanFactory);
          this.reader.loadBeanDefinitions(resource);
     }

}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;在XmlBeanFactory这个IOC容器中，初始化了一个XmlBeanDefinitionReader，用这个XmlBeanDefinitionReader来处理XML中的BeanDefinition对象。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;手工创建IOC容器&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class XmlIOCTest {

     public static void main(String[] args) {
//定义BeanDefinition的信息来源，在XmlBeanFactory中作为构造函数的参数传给XmlBeanFactory     
		  ClassPathResource resource = new ClassPathResource(&quot;config\\beans.xml”);
//创建一个BeanFactory的IoC容器
          DefaultListableBeanFactory factory = new DefaultListableBeanFactory();
//创建一个加载BeanDefinition的读取器，通过一个回调配置给BeanFactory
          XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(factory);
//从信息来源中加载BeanDefinition
          reader.loadBeanDefinitions(resource);
          Admin admin = (Admin)factory.getBean(&quot;admin&quot;);
          admin.setName(&quot;ming.zhou&quot;);
          admin.setPassword(&quot;123&quot;);
          admin.setStatus(1);
          System.out.println(admin);
     }

}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;输入结果：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Admin{id=null, name='ming.zhou', password='123', status=1}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;由上我们可以总结IoC容器的初始化过程（refresh()方法来启动）：（源码查看可以通过loadBeanDefinitions逐步查看）
Resource定位过程－－BeanDefinition的载入－－向IoC容器注册BeanDefinition（调用BeanDefinitionRegistry接口来实现，每个bean放在hashMap中存储）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;二、ApplicationContext&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;接口类ApplicationContext是高级形态意义的IOC容器。&lt;/p&gt;

&lt;p&gt;IoC容器的初始化是由refresh()方法来启动的，它标志这IoC容器的正式启动，启动过程包含BeanDefinition的Resource定位、载入和注册三个基本过程。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.1 Resource定位&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Resource接口设计图：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-IoC源码&quot; 图片5=&quot;&quot; src=&quot;http://img.mukewang.com/597450100001ace507340894.png&quot; style=&quot;width:50%&quot; alt=&quot;死磕Spring源码-IoC源码&quot; /&gt;&lt;/p&gt;

&lt;p&gt;FileSystemApplicationContext，支持XML定义的BeanDefinition的ApplicationContext，可指定以文件形式的BeanDefinition的读入，文件放在本地文件系统中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;FileSystemApplicationContext的继承关系图:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-IoC源码&quot; 图片6=&quot;&quot; src=&quot;http://img.mukewang.com/597447b90001efaa07380916.png&quot; style=&quot;width:50%&quot; alt=&quot;死磕Spring源码-IoC源码&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;getResourceByPath()的调用栈：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-IoC源码&quot; 图片7=&quot;&quot; src=&quot;http://img.mukewang.com/597447e10001335817380988.png&quot; style=&quot;width:100%&quot; alt=&quot;死磕Spring源码-IoC源码&quot; /&gt;&lt;/p&gt;

&lt;p&gt;通过查看FileSystemApplicationContext中的getResourceByPath()的方法调用栈可以发现这个&lt;strong&gt;IOC容器资源定位的实现过程：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-IoC源码&quot; 图片8=&quot;&quot; src=&quot;http://img.mukewang.com/597447fa0001cf1e17800904.png&quot; style=&quot;width:100%&quot; alt=&quot;死磕Spring源码-IoC源码&quot; /&gt;&lt;/p&gt;

&lt;p&gt;类AbstractRefreshableApplicationContext对容器初始化源码分析:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Override
protected final void refreshBeanFactory() throws BeansException {
//如果已经建立了BeanFactory，则销毁并关闭该BeanFactory，保证refresh以后使用的是新建立起来的IoC容器
    if (hasBeanFactory()) {
        destroyBeans();
        closeBeanFactory();
    }
    try {
        DefaultListableBeanFactory beanFactory = createBeanFactory();
        beanFactory.setSerializationId(getId());
        customizeBeanFactory(beanFactory);
        loadBeanDefinitions(beanFactory);
        synchronized (this.beanFactoryMonitor) {
            this.beanFactory = beanFactory;
        }
    }
    catch (IOException ex) {
        throw new ApplicationContextException(&quot;I/O error parsing bean definition source for &quot; + getDisplayName(), ex);
    }
}

@Override
public Resource getResource(String location) {
    Assert.notNull(location, &quot;Location must not be null&quot;);

    for (ProtocolResolver protocolResolver : this.protocolResolvers) {
        Resource resource = protocolResolver.resolve(location, this);
        if (resource != null) {
            return resource;
        }
    }

    if (location.startsWith(&quot;/&quot;)) {
        return getResourceByPath(location);
    }
    //处理带有classpath标识的Resource
    else if (location.startsWith(CLASSPATH_URL_PREFIX)) {
        return new ClassPathResource(location.substring(CLASSPATH_URL_PREFIX.length()), getClassLoader());
    }
    else {
        try {
            // 处理URL标识的Resource
            URL url = new URL(location);
            return new UrlResource(url);
        }
        catch (MalformedURLException ex) {
            // No URL -&amp;gt; resolve as resource path.
            return getResourceByPath(location);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;整个过程起源于FileSystemApplicationContext的构造函数的初始化，通过构造函数中的refresh()方法来启动整个应用，在AbstractRefreshableApplicationContext中的refreshBeanFactory()方法中我们可以看到使用了createBeanFactory构建了一个DefaultListableBeanFactory的IOC容器，同时启动资源载入（AbstractRefreshableApplicationContext中的loadBeanDefinitions()方法是抽象方法，因为载入的方式有很多种，具体的载入操作交由其子类去具体实现，这里的子类就是
XmlWebApplicationContext
）；具体的资源载入在XmlWebApplicationContext的loadBeanDefinitions()中读入BeanDefinition时完成（loadBeanDefinitions方法在方法调用栈中第一次出现是在XmlWebApplicationContext中的），载入的具体实现在XmlWebApplicationContext的基类AbstractBeanDefinitionReader中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.2 BeanDefinition的载入与解析&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;loadBeanDefinitions的调用方法栈:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-IoC源码&quot; 图片9=&quot;&quot; src=&quot;http://img.mukewang.com/597449790001262916520684.png&quot; style=&quot;width:100%&quot; alt=&quot;死磕Spring源码-IoC源码&quot; /&gt;&lt;/p&gt;

&lt;p&gt;有了Resource定位对象后，开始BeanDefinition的载入与解析的工作，按照Spring的Bean定义规则来对这个XML的文档树进行解析了，解析工作是交给BeanDefinitionParserDelegate来完成的。BeanDefinition的载入分为两部分：首先是通过调用XML的解析器得到document对象，但这些document对象并没有按照Spring的Bean规则进行解析；然后在完成通用的XML解析后，才开始按照Spring的Bean规则进行解析。按照Spring的Bean规则进行解析过程是在documentReader中实现的，把Bean的id、name、aliase等属性元素读取出来后设置到生成的BeanDefinitionHolder中去。BeanDefinitionHolder是BeanDefinition的封装类，封装了BeanDefinition，Bean的名字和别名，用它来完成向IoC容器注册。&lt;/p&gt;

&lt;p&gt;BeanDefinition的载入与解析过程源码解析如下，有点长，但不难，耐心看下去思路还是很清晰的。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Override
//调用入口
public int loadBeanDefinitions(Resource resource) throws BeanDefinitionStoreException {
    return loadBeanDefinitions(new EncodedResource(resource));
}
//载入XML形式的BeanDefinition
public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException {
    Assert.notNull(encodedResource, &quot;EncodedResource must not be null&quot;);
    if (logger.isInfoEnabled()) {
        logger.info(&quot;Loading XML bean definitions from &quot; + encodedResource.getResource());
    }

    Set&amp;lt;EncodedResource&amp;gt; currentResources = this.resourcesCurrentlyBeingLoaded.get();
    if (currentResources == null) {
        currentResources = new HashSet&amp;lt;EncodedResource&amp;gt;(4);
        this.resourcesCurrentlyBeingLoaded.set(currentResources);
    }
    if (!currentResources.add(encodedResource)) {
        throw new BeanDefinitionStoreException(
                &quot;Detected cyclic loading of &quot; + encodedResource + &quot; - check your import definitions!&quot;);
    }
    //得到XML文件，并获取IO的InputSource准备进行读取
    try {
        InputStream inputStream = encodedResource.getResource().getInputStream();
        try {
            InputSource inputSource = new InputSource(inputStream);
            if (encodedResource.getEncoding() != null) {
                inputSource.setEncoding(encodedResource.getEncoding());
            }
            return doLoadBeanDefinitions(inputSource, encodedResource.getResource());
        }
        finally {
            inputStream.close();
        }
    }
    catch (IOException ex) {
        throw new BeanDefinitionStoreException(
                &quot;IOException parsing XML document from &quot; + encodedResource.getResource(), ex);
    }
    finally {
        currentResources.remove(encodedResource);
        if (currentResources.isEmpty()) {
            this.resourcesCurrentlyBeingLoaded.remove();
        }
    }
}
//具体的读取过程
protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource)
            throws BeanDefinitionStoreException {
    try {
        //调用XML的解析器得到document对象
        Document doc = doLoadDocument(inputSource, resource);
        //启动对BeanDefinition解析过程
        return registerBeanDefinitions(doc, resource);
    }
    catch (BeanDefinitionStoreException ex) {
        throw ex;
    }
    catch (SAXParseException ex) {
        throw new XmlBeanDefinitionStoreException(resource.getDescription(),
                &quot;Line &quot; + ex.getLineNumber() + &quot; in XML document from &quot; + resource + &quot; is invalid&quot;, ex);
    }
    catch (SAXException ex) {
        throw new XmlBeanDefinitionStoreException(resource.getDescription(),
                &quot;XML document from &quot; + resource + &quot; is invalid&quot;, ex);
    }
    catch (ParserConfigurationException ex) {
        throw new BeanDefinitionStoreException(resource.getDescription(),
                &quot;Parser configuration exception parsing XML from &quot; + resource, ex);
    }
    catch (IOException ex) {
        throw new BeanDefinitionStoreException(resource.getDescription(),
                &quot;IOException parsing XML document from &quot; + resource, ex);
    }
    catch (Throwable ex) {
        throw new BeanDefinitionStoreException(resource.getDescription(),
                &quot;Unexpected exception parsing XML document from &quot; + resource, ex);
    }
}
public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException {
    //得到BeanDefinitionDocumentReader来对XML的BeanDefinition进行解析
    BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader();
    int countBefore = getRegistry().getBeanDefinitionCount();
    //调用BeanDefinitionDocumentReader的registerBeanDefinitions完成具体的解析过程
    documentReader.registerBeanDefinitions(doc, createReaderContext(resource));
    return getRegistry().getBeanDefinitionCount() - countBefore;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;BeanDefinitionDocumentReader类的registerBeanDefinitions方法&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Override
public void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) {
    this.readerContext = readerContext;
    logger.debug(&quot;Loading bean definitions&quot;);
    Element root = doc.getDocumentElement();
    doRegisterBeanDefinitions(root);
}
protected void doRegisterBeanDefinitions(Element root) {
    BeanDefinitionParserDelegate parent = this.delegate;
    this.delegate = createDelegate(getReaderContext(), root, parent);

    if (this.delegate.isDefaultNamespace(root)) {
        String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE);
        if (StringUtils.hasText(profileSpec)) {
            String[] specifiedProfiles = StringUtils.tokenizeToStringArray(
                    profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS);
            if (!getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) {
                if (logger.isInfoEnabled()) {
                    logger.info(&quot;Skipped XML bean definition file due to specified profiles [&quot; + profileSpec +
                            &quot;] not matching: &quot; + getReaderContext().getResource());
                }
                return;
            }
        }
    }

    preProcessXml(root);
    parseBeanDefinitions(root, this.delegate);
    postProcessXml(root);

    this.delegate = parent;
}
protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) {
    //BeanDefinitionHolder是BeanDefinition的封装类，封装了BeanDefinition，Bean的名字和别名，用它来完成向IoC容器注册
    BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele);
    if (bdHolder != null) {
        bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder);
        try {
            //向IoC容器注册解析得到的BeanDefinition
            BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry());
        }
        catch (BeanDefinitionStoreException ex) {
            getReaderContext().error(&quot;Failed to register bean definition with name '&quot; +
                    bdHolder.getBeanName() + &quot;'&quot;, ele, ex);
        }
        // Send registration event.
        getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder));
    }
}
//BeanDefinitionParserDelegate类方法，具体的解析过程，把Bean的id、name、aliase等属性元素读取出来后设置到生成的BeanDefinitionHolder中去
public BeanDefinitionHolder parseBeanDefinitionElement(Element ele, BeanDefinition containingBean) {
    //取得&amp;lt;Bean&amp;gt;元素中的id、name、aliase属性的值
    String id = ele.getAttribute(ID_ATTRIBUTE);
    String nameAttr = ele.getAttribute(NAME_ATTRIBUTE);

    List&amp;lt;String&amp;gt; aliases = new ArrayList&amp;lt;String&amp;gt;();
    if (StringUtils.hasLength(nameAttr)) {
        String[] nameArr = StringUtils.tokenizeToStringArray(nameAttr, MULTI_VALUE_ATTRIBUTE_DELIMITERS);
        aliases.addAll(Arrays.asList(nameArr));
    }

    String beanName = id;
    if (!StringUtils.hasText(beanName) &amp;amp;&amp;amp; !aliases.isEmpty()) {
        beanName = aliases.remove(0);
        if (logger.isDebugEnabled()) {
            logger.debug(&quot;No XML 'id' specified - using '&quot; + beanName +
                    &quot;' as bean name and &quot; + aliases + &quot; as aliases&quot;);
        }
    }

    if (containingBean == null) {
        checkNameUniqueness(beanName, aliases, ele);
    }
    //对Bean元素的详细解析，比如class、parent、init-method、destroy-method等
    AbstractBeanDefinition beanDefinition = parseBeanDefinitionElement(ele, beanName, containingBean);
    if (beanDefinition != null) {
        if (!StringUtils.hasText(beanName)) {
            try {
                if (containingBean != null) {
                    beanName = BeanDefinitionReaderUtils.generateBeanName(
                            beanDefinition, this.readerContext.getRegistry(), true);
                }
                else {
                    beanName = this.readerContext.generateBeanName(beanDefinition);
                    // Register an alias for the plain bean class name, if still possible,
                    // if the generator returned the class name plus a suffix.
                    // This is expected for Spring 1.2/2.0 backwards compatibility.
                    String beanClassName = beanDefinition.getBeanClassName();
                    if (beanClassName != null &amp;amp;&amp;amp;
                            beanName.startsWith(beanClassName) &amp;amp;&amp;amp; beanName.length() &amp;gt; beanClassName.length() &amp;amp;&amp;amp;
                            !this.readerContext.getRegistry().isBeanNameInUse(beanClassName)) {
                        aliases.add(beanClassName);
                    }
                }
                if (logger.isDebugEnabled()) {
                    logger.debug(&quot;Neither XML 'id' nor 'name' specified - &quot; +
                            &quot;using generated bean name [&quot; + beanName + &quot;]&quot;);
                }
            }
            catch (Exception ex) {
                error(ex.getMessage(), ele);
                return null;
            }
        }
        String[] aliasesArray = StringUtils.toStringArray(aliases);
        return new BeanDefinitionHolder(beanDefinition, beanName, aliasesArray);
    }

    return null;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;载入与解析的方法调用流程图：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-IoC源码&quot; 图片10=&quot;&quot; src=&quot;http://img.mukewang.com/59744a180001978917380986.png&quot; style=&quot;width:100%&quot; alt=&quot;死磕Spring源码-IoC源码&quot; /&gt;&lt;/p&gt;

&lt;p&gt;经过以上的载入过程，我们大致完成了IoC容器的Bean对象的数据准备工作或初始化工作，但现在IoC容器BeanDefinition中还只是存在些静态的配置信息，还不能供IoC容器直接使用，要想让IoC容器发挥作用还需要进行BeanDefinition的注册。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.3 BeanDefinition的注册&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;注册过程相对简单，这个过程是通过调用BeanDefinitionRegistry接口的实现来完成的，这个注册过程把载入过程中解析得到的BeanDefinition向IoC容器进行注册，通过源码分析，我们可以看到在IoC容器中是持有一个HashMap来装BeanDefinition数据的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;registerBeanDefinition的调用方法栈:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕Spring源码-IoC源码&quot; 图片11=&quot;&quot; src=&quot;http://img.mukewang.com/59744a4700014e0a17340788.png&quot; style=&quot;width:100%&quot; alt=&quot;死磕Spring源码-IoC源码&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private final Map&amp;lt;String, BeanDefinition&amp;gt; beanDefinitionMap = new ConcurrentHashMap&amp;lt;String, BeanDefinition&amp;gt;(256);
public static void registerBeanDefinition(
        BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry)
        throws BeanDefinitionStoreException {

    // Register bean definition under primary name.
    String beanName = definitionHolder.getBeanName();
    registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition());

    // Register aliases for bean name, if any.
    String[] aliases = definitionHolder.getAliases();
    if (aliases != null) {
        for (String alias : aliases) {
            registry.registerAlias(beanName, alias);
        }
    }
}

@Override
public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition)
        throws BeanDefinitionStoreException {

    Assert.hasText(beanName, &quot;Bean name must not be empty&quot;);
    Assert.notNull(beanDefinition, &quot;BeanDefinition must not be null&quot;);

    if (beanDefinition instanceof AbstractBeanDefinition) {
        try {
            ((AbstractBeanDefinition) beanDefinition).validate();
        }
        catch (BeanDefinitionValidationException ex) {
            throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName,
                    &quot;Validation of bean definition failed&quot;, ex);
        }
    }

    BeanDefinition oldBeanDefinition;

    //检查是不是有同名字的BeanDefinition已经在IoC容器中注册了，如果存在且不允许覆盖则抛出异常
    oldBeanDefinition = this.beanDefinitionMap.get(beanName);
    if (oldBeanDefinition != null) {
        if (!isAllowBeanDefinitionOverriding()) {
            throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName,
                    &quot;Cannot register bean definition [&quot; + beanDefinition + &quot;] for bean '&quot; + beanName +
                    &quot;': There is already [&quot; + oldBeanDefinition + &quot;] bound.&quot;);
        }
        else if (oldBeanDefinition.getRole() &amp;lt; beanDefinition.getRole()) {
            // e.g. was ROLE_APPLICATION, now overriding with ROLE_SUPPORT or ROLE_INFRASTRUCTURE
            if (this.logger.isWarnEnabled()) {
                this.logger.warn(&quot;Overriding user-defined bean definition for bean '&quot; + beanName +
                        &quot;' with a framework-generated bean definition: replacing [&quot; +
                        oldBeanDefinition + &quot;] with [&quot; + beanDefinition + &quot;]&quot;);
            }
        }
        else if (!beanDefinition.equals(oldBeanDefinition)) {
            if (this.logger.isInfoEnabled()) {
                this.logger.info(&quot;Overriding bean definition for bean '&quot; + beanName +
                        &quot;' with a different definition: replacing [&quot; + oldBeanDefinition +
                        &quot;] with [&quot; + beanDefinition + &quot;]&quot;);
            }
        }
        else {
            if (this.logger.isDebugEnabled()) {
                this.logger.debug(&quot;Overriding bean definition for bean '&quot; + beanName +
                        &quot;' with an equivalent definition: replacing [&quot; + oldBeanDefinition +
                        &quot;] with [&quot; + beanDefinition + &quot;]&quot;);
            }
        }
        this.beanDefinitionMap.put(beanName, beanDefinition);
    }
    else {
        if (hasBeanCreationStarted()) {
            //注册过程需要synchronized，保证数据的一致性
            synchronized (this.beanDefinitionMap) {
                this.beanDefinitionMap.put(beanName, beanDefinition);
                List&amp;lt;String&amp;gt; updatedDefinitions = new ArrayList&amp;lt;String&amp;gt;(this.beanDefinitionNames.size() + 1);
                updatedDefinitions.addAll(this.beanDefinitionNames);
                updatedDefinitions.add(beanName);
                this.beanDefinitionNames = updatedDefinitions;
                if (this.manualSingletonNames.contains(beanName)) {
                    Set&amp;lt;String&amp;gt; updatedSingletons = new LinkedHashSet&amp;lt;String&amp;gt;(this.manualSingletonNames);
                    updatedSingletons.remove(beanName);
                    this.manualSingletonNames = updatedSingletons;
                }
            }
        }
        else {
            // Still in startup registration phase
            this.beanDefinitionMap.put(beanName, beanDefinition);
            this.beanDefinitionNames.add(beanName);
            this.manualSingletonNames.remove(beanName);
        }
        this.frozenBeanDefinitionNames = null;
    }

    if (oldBeanDefinition != null || containsSingleton(beanName)) {
        resetBeanDefinition(beanName);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;注册过程会检查是不是有同名字的BeanDefinition已经在IoC容器中注册了，如果存在且不允许覆盖则抛出异常，注册过程需要synchronized，保证数据的一致性。&lt;/p&gt;

&lt;p&gt;完成了BeanDefinition的注册，IOC容器的初始化过程就结束了，在这个IOC容器中已经有了整个Bean的配置信息。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;总结：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;IoC的概念&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;BeanFactory&lt;/strong&gt;（提供IoC容器最基本的功能规范），BeanFactory接口的基本方法有哪些？从手工创建IOC容器中可以获悉IoC的建立与初始化过程（四步：资源定位-&amp;gt;创建BeanFactory的IoC容器-&amp;gt;创建一个加载BeanDefinition的读取器，通过一个回调配置给BeanFactory-&amp;gt;从已定位的资源中加载BeanDefinition）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ApplicationContext&lt;/strong&gt;（高级形态意义的IOC容器），以FileSystemApplicationContext为例解析ApplicationContext的初始化过程。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;资源定位&lt;/strong&gt;：Resource getResource(String location)，不同标识对应不同的Resource，classPath-&amp;gt;classPathResource；url-&amp;gt;ServletContextResource；否则调用容器本身的getResourceByPath方法获取Resource&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;载入与解析资源&lt;/strong&gt;：&lt;code class=&quot;highlighter-rouge&quot;&gt;int loadBeanDefinitions(Resource resource)&lt;/code&gt;，input是之前定位好的资源对象Resource，输出是这次加载了多少个BeanDefinition；载入与解析的工作分为两步：&lt;/p&gt;

&lt;p&gt;第一：通过调用XML的解析器得到document对象；&lt;/p&gt;

&lt;p&gt;第二：&lt;/p&gt;

&lt;p&gt;—&amp;gt;将得到的document对象作为输入传入&lt;code class=&quot;highlighter-rouge&quot;&gt;registerBeanDefinitions(Document doc, Resource resource)&lt;/code&gt;方法&lt;/p&gt;

&lt;p&gt;—&amp;gt;然后使用BeanDefinitionDocumentReader类来按照Spring的Bean规则解析Document对象，得到Document的Element对象，&lt;code class=&quot;highlighter-rouge&quot;&gt;Element root = doc.getDocumentElement()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;—&amp;gt;解析element对象，&lt;code class=&quot;highlighter-rouge&quot;&gt;BeanDefinitionHolder parseBeanDefinitionElement(Element ele, BeanDefinition containingBean)&lt;/code&gt;，将Element作为输入，在parseBeanDefinitionElement方法中解析，取得&lt;Bean&gt;元素中的id、name、aliase属性的值，对Bean元素的详细解析，比如class、parent、init-method、destroy-method等&lt;/Bean&gt;&lt;/p&gt;

&lt;p&gt;—&amp;gt;最终将解析的数据作为输入，生成BeanDefinitionHolder的实例，&lt;code class=&quot;highlighter-rouge&quot;&gt;return new BeanDefinitionHolder(beanDefinition, beanName, aliasesArray);&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;资源的注册&lt;/strong&gt;：这部分相对载入与解析要更简单一些，将这部分生成的BeanDefinitionHolder作为输入，传入&lt;code class=&quot;highlighter-rouge&quot;&gt;void registerBeanDefinition(BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;—&amp;gt;从BeanDefinitionHolder对象中获取beanName和BeanDefinition，&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;String beanName = definitionHolder.getBeanName();
registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition())&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;并以beanName和BeanDefinition作为输入去注册Bean，用一个&lt;code class=&quot;highlighter-rouge&quot;&gt;new ConcurrentHashMap&amp;lt;String, BeanDefinition&amp;gt;(256)&lt;/code&gt;的hashMap来维护Bean。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;1、Spring 4.3.3源码&lt;/p&gt;

&lt;p&gt;2、《Spring 技术内幕（深入解析Spring架构与设计原理）》&lt;/p&gt;

</description>
        <pubDate>Sun, 02 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/java/2017/07/02/%E6%AD%BB%E7%A3%95Spring%E6%BA%90%E7%A0%81%E4%B9%8BIoC.html</link>
        <guid isPermaLink="true">http://localhost:4000/java/2017/07/02/%E6%AD%BB%E7%A3%95Spring%E6%BA%90%E7%A0%81%E4%B9%8BIoC.html</guid>
        
        <category>java</category>
        
        <category>Spring</category>
        
        <category>源码</category>
        
        <category>IoC</category>
        
        
        <category>Java</category>
        
      </item>
    
      <item>
        <title>死磕设计模式-观适代装</title>
        <description>&lt;p&gt;最近看spring源码的时候会看到很多经典的设计模式，索性就把几个常用的经典的设计模式再复习总结遍。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;观察者模式&lt;/li&gt;
  &lt;li&gt;适配器模式&lt;/li&gt;
  &lt;li&gt;代理模式&lt;/li&gt;
  &lt;li&gt;装饰器模式&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;一、观察者模式&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;是什么：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;观察者模式是在维护多个对象之间的一对多的依赖关系，也就是说，当一个对象的状态发生了改变时会通知所有依赖于它的对象，好让这些对象对新的变化做出反应。观察者模式既可以有效的维护对象的一致性，又能最大限度的降低对象之间的耦合度。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;长什么样：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕设计模式&quot; src=&quot;http://img.mukewang.com/597098400001ecc520880750.png&quot; style=&quot;width:100%&quot; alt=&quot;死磕设计模式&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从上面的UML类图可以看出：有两个接口，一个是主体对象接口，一个是观察者接口。主体对象接口定义了通知的方法，实现它的类Boss中有新增/删除观察者的方法；观察者接口定义了更新的方法，当boss的状态改变后，boss会notify所有的观察者来执行update方法做相应的更新操作。这么说可能还有点抽象，下面直接上代码demo。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;怎么做：&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public interface BossInterface
{
    void notify();
}

public interface Observer
{
    void update();
}

public class Boss implements BossInterface
{
    private String bossSay;

    private List&amp;lt;Observer&amp;gt; observers = new ArrayList&amp;lt;Observer&amp;gt;();

    // 增加观察者
    public void addObserver(Observer observer)
    {
        this.observers.add(observer);
    }

    // 移除观察者
    public void deleteObserver(Observer observer)
    {
        this.observers.remove(observer);
    }

    //获取Boss状态
    public String getBossSay()
    {
        return bossSay;
    }

    //设置Boss状态
    public void setBossSay(String bossSay)
    {
        this.bossSay = bossSay;
    }

    //通知所有的观察者工作
    public void notify()
    {
        foreach (Observer observer in observers)
        {
            observer.update();
        }
    }
}

public class Coder implements Observer
{
    private Boss boss;

    public Coder(Boss boss)
    {
        this.boss = boss;
    }

    // 更新状态
    public void update()
    {
        if (boss.getBossSay() == &quot;兄弟们，为了世界和平，一起Hello,world吧！&quot;)
        {
            //开始写代码
        }
    }
}

public class UI extends Observer
{
    private Boss boss;

    public UI(Boss boss)
    {
        this.boss = boss;
    }

    // 更新状态
    public void update()
    {
        if (boss.getBossSay() == &quot;兄弟们，为了世界和平，一起Hello,world吧！&quot;)
        {
            //开始写UI
        }
    }
}

public class PM extends Observer
{
    private Boss boss;

    public PM(Boss boss)
    {
        this.boss = boss;
    }

    // 更新状态
    public void update()
    {
        if (boss.getBossSay() == &quot;兄弟们，为了世界和平，一起Hello,world吧！&quot;)
        {
            //开始写项目的各种文档，请程序员、测试、运维、美工吃饭
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;二、适配器模式&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;是什么：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;适配器模式就是将那些原本由于接口不兼容而不能一起工作的类适配成可以在一起工作的类，适配器是一种增强或转换的工具，将那些不符合我们的需求但已经存在的类的接口，在不修改这类接口本身的情况下适配成我们想要的类。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;长什么样：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕设计模式&quot; src=&quot;http://img.mukewang.com/5970988f000189c215220838.png&quot; style=&quot;width:100%&quot; alt=&quot;死磕设计模式&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;怎么做：&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// 已存在的、具有特殊功能、但不符合我们既有的标准接口的类
class ExistingClass {
    public void enhanceMethod() {
        System.out.println(&quot;被适配类具有 特殊功能...&quot;);
    }
}

// 目标接口，或称为标准接口
interface RequiredInterface {
    public void requiredMethod();
}

// 原本存在的类，只提供普通功能
class OriginalClass implements RequiredInterface {
    public void requiredMethod() {
        System.out.println(&quot;普通类 具有 普通功能...&quot;);
    }
}

// 适配器类，继承了被适配类，同时实现标准接口
class Adapter extends ExistingClass implements RequiredInterface{
    public void requiredMethod() {
        super.enhanceMethod();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;三、代理模式&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;代理模式顾名思义就是使用了一个代理人，有代理就有在代理背后的目标对象，代理模式的意义在你不直接对目标对象进行操作，而是通过代理对象来操作目标对象，那么在代理对象这一层你就可以对目标对象进行很多增强的工作并且不用改变目标对象的代码。在实际工作中也很有指导意义，就是永远别去改别人已经写好的上线测试过了的代码，你可以利用代理模式来扩展目标对象的功能。&lt;/p&gt;

&lt;p&gt;举个栗子：你购买了一个第三方的工具，当你在使用上问题的时候，你可能不能直接找到写这个工具的程序猿/媛，但你可以找到售后服务人员或技术支持人员，这个角色充当的就是代理对象，程序猿/媛就是目标对象，你找售后人员反映问题，售后把问题总结后集中反馈给程序猿/媛，他们去修改代码，给出个解决方案，具体的流程如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕设计模式&quot; 图片3=&quot;&quot; src=&quot;http://img.mukewang.com/5971caec0001d6c913360472.png&quot; style=&quot;width:100%&quot; alt=&quot;死磕设计模式&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从上图可以看出，用户先去调售后服务（代理对象），她是我们的程序猿/媛（目标对象）的代理，代理对象是对目标对象的扩展，同时代理对象会调用目标对象的方法来完成目的。&lt;/p&gt;

&lt;p&gt;代理模式根据其代理的方式分为三种：静态代理，动态代理和Cglib代理&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.1 静态代理&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;代理方式：代理对象和目标对象必须实现同一个接口或继承同一个父类，通过调用代理对象的相同的方法来调用目标对象的方法。&lt;/p&gt;

&lt;p&gt;代码实现：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
* 制定好的行业标准
*/
public interface OperationStandard {

    void operate();
}

/**
* 目标对象，实现相同的行业标准
*/
public class Coder implements OperationStandard {
    public void operate() {
        //调整代码，提出解决方案
    }
}

/**
* 代理对象，实现相同的行业标准
*/
public class Service implements OperationStandard{
    //接收保存目标对象
    private Coder target;
    public Service(Coder target){
        this.target=target;
    }

    public void operate() {
        System.out.println(“增强功能1...&quot;);
        target.operate();//执行目标对象的方法
        System.out.println(“增强功能2...&quot;);
    }
}

/**
* 用户
*/
public class Customer {
    public static void main(String[] args) {
        //目标对象
        Coder target = new Coder();

        //代理对象,把目标对象传给代理对象,建立代理关系
        Service proxy = new Service(target);

        proxy.operate();//执行的是代理的方法
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;静态代理虽然简单，但缺点也很明显：目标对象和代理对象都要实现相同的接口，一旦接口需要变动，目标类和代理类都需要维护。这很好理解，售后人员和程序猿/媛之间对项目都有明确的标准的需求或功能文档，程序猿/媛按照标准文档开发，售后人员按照标准文档对外提供服务，一旦公司的这些标准文档变化了，那么需要组织售后人员和程序猿/媛一起进行培训，这样无疑很耗时耗力。&lt;/p&gt;

&lt;p&gt;动态代理可以很好的解决这个问题。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.2 动态代理&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;动态代理利用JDK的API动态的在内存中构建代理对象(需要我们指定创建代理对象/目标对象实现的接口的类型)&lt;/p&gt;

&lt;p&gt;JDK中生成代理对象的API：
java.lang.reflect.Proxy.newProxyInstance
static Object newProxyInstance(ClassLoader loader, Class&amp;lt;?&amp;gt;[] interfaces,InvocationHandler h )&lt;/p&gt;

&lt;p&gt;注意该方法是在Proxy类中是静态方法,且接收的三个参数依次为:&lt;/p&gt;

&lt;p&gt;ClassLoader loader,:指定当前目标对象使用类加载器,获取加载器的方法是固定的&lt;/p&gt;

&lt;p&gt;Class&amp;lt;?&amp;gt;[] interfaces,:目标对象实现的接口的类型,使用泛型方式确认类型&lt;/p&gt;

&lt;p&gt;InvocationHandler h:事件处理,执行目标对象的方法时,会触发事件处理器的方法,会把当前执行目标对象的方法作为参数传入&lt;/p&gt;

&lt;p&gt;行业标准和目标类和静态代理是一样的，下面只写代理类的实现：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
* 创建动态代理对象
* 动态代理不需要实现接口,但是需要指定接口类型
*/
public class Service{

    //维护一个目标对象
    private Object target;
    public Service(Object target){
        this.target=target;
    }

   //给目标对象生成代理对象
    public Object getProxyInstance(){
        return Proxy.newProxyInstance(
                target.getClass().getClassLoader(),
                target.getClass().getInterfaces(),
                new InvocationHandler() {
                    @Override
                    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
                        System.out.println(&quot;增强功能1&quot;);
                        //执行目标对象方法
                        Object returnValue = method.invoke(target, args);
                        System.out.println(&quot;增强功能2&quot;);
                        return returnValue;
                    }
                }
        );
    }

}
/**
* 用户
*/
public class Customer {
    public static void main(String[] args) {
        // 目标对象
        OperationStandard target = new Coder();
        // 【原始的类型 class com.intelligentler.Controller.Coder】
        System.out.println(target.getClass());

        // 给目标对象，创建代理对象
        OperationStandard proxy = (OperationStandard) new Service(target).getProxyInstance();
        // class $Proxy0   内存中动态生成的代理对象
        System.out.println(proxy.getClass());

        // 执行代理对象的方法
        proxy.operate();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个时候售后人员就厉害了，她不需要依赖标准文档就可以对接不同类型的程序猿/媛，你想让她去代理哪个程序猿/媛都可以，因为她会动态的去调用不同目标对象的执行方法。但动态代理中的目标对象还是要实现标准接口，否则无法使用动态代理。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.3 Cglib代理&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;JDK的动态代理有一个限制,就是使用动态代理的对象必须实现一个或多个接口,如果想代理没有实现接口的类,就可以使用Cglib实现。有时候目标对象只是一个单独的对象,并没有实现任何的接口,这个时候就可以使用以目标对象子类的方式类实现代理,这种方法就叫做:Cglib代理。&lt;/p&gt;

&lt;p&gt;Cglib是一个强大的高性能的代码生成包,它可以在运行期扩展java类与实现java接口.它广泛的被许多AOP的框架使用,例如Spring AOP和synaop,为他们提供方法的interception(拦截)&lt;/p&gt;

&lt;p&gt;Cglib子类代理实现方法:&lt;/p&gt;

&lt;p&gt;1.需要引入cglib的jar文件,但是Spring的核心包中已经包括了Cglib功能,所以直接引入spring-core-3.2.5.jar即可.&lt;/p&gt;

&lt;p&gt;2.引入功能包后,就可以在内存中动态构建子类&lt;/p&gt;

&lt;p&gt;3.代理的类不能为final,否则报错&lt;/p&gt;

&lt;p&gt;4.目标对象的方法如果为final/static,那么就不会被拦截,即不会执行目标对象额外的业务方法.&lt;/p&gt;

&lt;p&gt;代码实现：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
* 目标对象,没有实现任何接口
*/
public class Coder {

    public void operate() {
        //调整代码，提出解决方案
    }
}
Cglib代理工厂:ServiceProxyFactory.java
/**
* Cglib子类代理工厂
* 对Coder在内存中动态构建一个子类对象
*/
public class ServiceProxyFactory implements MethodInterceptor{
    //维护目标对象
    private Object target;

    public ServiceProxyFactory(Object target) {
        this.target = target;
    }

    //给目标对象创建一个代理对象
    public Object getProxyInstance(){
        //1.工具类
        Enhancer en = new Enhancer();
        //2.设置父类
        en.setSuperclass(target.getClass());
        //3.设置回调函数
        en.setCallback(this);
        //4.创建子类(代理对象)
        return en.create();
    }

    @Override
    public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable {
        System.out.println(&quot;增强功能1&quot;);

        //执行目标对象的方法
        Object returnValue = method.invoke(target, args);

        System.out.println(&quot;增强功能1&quot;);

        return returnValue;
    }
}

/**
* 用户
*/
public class Customer {
    @Test
    public void test(){
        //目标对象
        Coder target = new Coder();
        //代理对象
        Coder proxy = (Coder)new ServiceProxyFactory(target).getProxyInstance();
        //执行代理对象的方法
        proxy.save();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Cglib代理中售后人员和程序猿/媛有着无比的默契，沟通不再需要标准文档。&lt;/p&gt;

&lt;p&gt;在Spring的AOP编程中:&lt;/p&gt;

&lt;p&gt;如果加入容器的目标对象有实现接口,用JDK代理&lt;/p&gt;

&lt;p&gt;如果目标对象没有实现接口,用Cglib代理&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;四、装饰器模式&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;装饰器模式可以在运行时增强或改变对象的功能。通常给对象增强功能，有三种方式：&lt;/p&gt;

&lt;p&gt;1、直接修改对象添加相应的功能&lt;/p&gt;

&lt;p&gt;2、派生对应的子类来扩展&lt;/p&gt;

&lt;p&gt;3、使用对象组合的方式&lt;/p&gt;

&lt;p&gt;显然，直接修改对应的类这种方式并不可取，它需要我们去修改以前的代码，这是程序猿的大忌。适配器模式就是派生对应的子类来扩展对象的功能。在面向对象的设计中，我们应该尽量使用对象组合，而不是对象继承来扩展和复用功能。装饰器模式就是基于对象组合的方式，可以很灵活的给对象添加所需要的功能。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;装饰器模式类图：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕设计模式-观适代装模式&quot; 图片4=&quot;&quot; src=&quot;http://img.mukewang.com/5979a7b50001c76b16540970.png&quot; width=&quot;100%&quot; alt=&quot;装饰器模式类图&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Component：待装饰对象的接口&lt;/p&gt;

&lt;p&gt;ConcreteComponent：待装饰对象的具体实现类&lt;/p&gt;

&lt;p&gt;Decorator：所有装饰器的父类，它也可以继承Component类，以便可以自己增强自己。&lt;/p&gt;

&lt;p&gt;ConcreteDecorator：具体的装饰器类&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Java代码实现：&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public abstract class Component {  
    /**
     * 待增强的方法
     */  
    public abstract void operation();  
}
public class ConcreteComponent extends Component {  

    public void operation() {}  

}  
public abstract class Decorator extends Component {  
    /**
     * 持有组件对象
     */  
    protected Component component;  

    /**
     * 构造方法，传入组件对象
     * @param component 组件对象
     */  
    public Decorator(Component component) {  
        this.component = component;  
    }  

    public void operation() {  
        //转发请求给组件对象，可以在转发前后执行一些附加动作  
        component.operation();  
    }  


}  
public class ConcreteDecoratorA extends Decorator {  
       public ConcreteDecoratorA(Component component) {  
            super(component);  
   }  
       private void operationFirst(){ } //在调用父类的operation方法之前需要执行的操作  
       private void operationLast(){ } //在调用父类的operation方法之后需要执行的操作  
       public void operation() {  
           //调用父类的方法，可以在调用前后执行一些增强功能
           operationFirst(); //添加的功能  
           //这里可以选择性的调用父类的方法，如果不调用则相当于完全改写了方法，实现了新的功能
           super.operation();
           operationLast(); //添加的功能  
   }  
}  
public class Client{  
   public static void main(String[] args){  
    Component c1 = new ConcreteComponent (); //首先创建需要被装饰的原始对象(即要被装饰的对象)  
    Decorator decoratorA = new ConcreteDecoratorA(c1); //给对象透明的增加功能A并调用  
    decoratorA .operation();  
    Decorator decoratorB = new ConcreteDecoratorB(c1); //给对象透明的增加功能B并调用  
    decoratorB .operation();
    //这里实现了自己装饰自己的功能，装饰器也可以装饰具体的装饰对象，此时相当于给对象在增加A的功能基础上在添加功能B  
    Decorator decoratorBandA = new ConcreteDecoratorB(decoratorA);  
    decoratorBandA.operation();  
  }  
}  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Java中的IO是明显的装饰器模式的运用。如FileInputStream是InputStream的一个子类，从文件中读取数据流，BufferedInputStream是继承自FilterInputStream的具体的装饰器类，该类提供一个内存的缓冲区类保存输入流中的数据。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BufferedInputStream bis = new BufferedInputStream(new FileInputStream(file));&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;参考文献：&lt;/p&gt;

&lt;p&gt;http://www.cnblogs.com/cenyu/p/6289209.html&lt;/p&gt;

&lt;p&gt;http://blog.csdn.net/hust_is_lcd/article/details/7884320&lt;/p&gt;
</description>
        <pubDate>Thu, 22 Jun 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/java/2017/06/22/%E6%AD%BB%E7%A3%95%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A7%82%E9%80%82%E4%BB%A3%E8%A3%85.html</link>
        <guid isPermaLink="true">http://localhost:4000/java/2017/06/22/%E6%AD%BB%E7%A3%95%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A7%82%E9%80%82%E4%BB%A3%E8%A3%85.html</guid>
        
        <category>java</category>
        
        <category>设计模式</category>
        
        <category>观察者</category>
        
        <category>适配器</category>
        
        <category>代理</category>
        
        <category>装饰器模式</category>
        
        
        <category>Java</category>
        
      </item>
    
      <item>
        <title>浅谈hashMap、hashTable、ConcurrentHashMap（1.6、1.8）</title>
        <description>&lt;p&gt;最近看Spring IoC源码的时候，发现Spring IoC中的BeanDefinition的注册采用ConcurrentHashMap&amp;lt;String, BeanDefinition&amp;gt;(256)来存储BeanDefinition，这让我想起了HashMap、HashTable以及ConcurrentHashMap的区别与联系，现在总结这三个类的实现原理和区别，在大脑里也重新再整理下这部分知识点。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;一、HashMap&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.1 HashMap的定义&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;HashMap是最常用的集合类框架之一，它实现了Map接口，所以存储的元素也是键值对映射的结构，并允许使用null值和null键，其内元素是无序的，如果要保证有序，可以使用LinkedHashMap。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;public class HashMap&amp;lt;K,V&amp;gt; extends AbstractMap&amp;lt;K,V&amp;gt;
    implements Map&amp;lt;K,V&amp;gt;, Cloneable, Serializable{}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.2 hashMap的基本方法&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//构造一个具有默认初始容量 (16) 和默认加载因子 (0.75) 的空 HashMap。
HashMap()
//构造一个带指定初始容量和默认加载因子 (0.75) 的空 HashMap。
HashMap(int initialCapacity)
//构造一个带指定初始容量和加载因子的空 HashMap。
HashMap(int initialCapacity, float loadFactor)
//构造一个映射关系与指定 Map 相同的 HashMap。
HashMap(Map&amp;lt;? extendsK,? extendsV&amp;gt; m)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;在hashMap的size达到initialCapacity*loadFactor时会对hashMap进行扩容，值得注意的是hashMap的size大小总是2的幂次方。初始容量和加载因子的选取也是影响HashMap性能的原因之一，加载因子过高虽然减少了空间开销，但同时也增加了查找某个条目的时间；加载因子过低也可能容易导致HashMap执行rehash操作。&lt;/p&gt;

&lt;p&gt;保证hashMap的size大小总为2的幂次方的方法：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;static final int tableSizeFor(int cap) {
    int n = cap - 1;
    n |= n &amp;gt;&amp;gt;&amp;gt; 1;
    n |= n &amp;gt;&amp;gt;&amp;gt; 2;
    n |= n &amp;gt;&amp;gt;&amp;gt; 4;
    n |= n &amp;gt;&amp;gt;&amp;gt; 8;
    n |= n &amp;gt;&amp;gt;&amp;gt; 16;
    return (n &amp;lt; 0) ? 1 : (n &amp;gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : 	n + 1;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;通过对（n - 1）无符号右移，最终会返回一个2的幂次方的值。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;为什么要保证hashMap的size的大小为2的幂次方？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在往hashMap中添加值(putVal())，要获取添加的值得index的时候，hashMap中使用了hashMap中Node数组的length:n与key的hash值‘相与’ &lt;code class=&quot;highlighter-rouge&quot;&gt;(n - 1) &amp;amp; hash&lt;/code&gt;来计算，当hashMap的size：n为2的幂时，n - 1 转化为全为1的二进制格式，和hash‘相与’时就是hash的值，因为做与运算要比做mod运算快很多，所以保证hashMap的size的大小为2的幂次方时会提高确定key的index位置的效率。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
    Node&amp;lt;K,V&amp;gt;[] tab; Node&amp;lt;K,V&amp;gt; p; int n, i;
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    if ((p = tab[i = (n - 1) &amp;amp; hash]) == null)
        tab[i] = newNode(hash, key, value, null);
    ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;HashMap能不能放入大于Integer_Max_Value个元素？&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;static final int MAXIMUM_CAPACITY = 1 &amp;lt;&amp;lt; 30;//1073741824 我们知道hashMap中的最大的size为1073741824，而Integer的Max_Value为2147483647，那么还能放Integer_Max_Value个元素吗？研究源码发现是可以的。

final Node&amp;lt;K,V&amp;gt;[] resize() {
    Node&amp;lt;K,V&amp;gt;[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    if (oldCap &amp;gt; 0) {
        if (oldCap &amp;gt;= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
    ...
    }
    ...
} 在扩容的resize()方法中，如果`oldCap &amp;gt;= MAXIMUM_CAPACITY`，不会对threshold扩容，而是直接将其赋值为Integer.MAX_VALUE，将冲突的值放在链表或红黑树中。
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;当链表的大小大于8的时候就一定会转化为红黑树吗？&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
    Node&amp;lt;K,V&amp;gt;[] tab; Node&amp;lt;K,V&amp;gt; p; int n, i;
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    if ((p = tab[i = (n - 1) &amp;amp; hash]) == null)
        tab[i] = newNode(hash, key, value, null);
    else {
        Node&amp;lt;K,V&amp;gt; e; K k;
        if (p.hash == hash &amp;amp;&amp;amp;
            ((k = p.key) == key || (key != null &amp;amp;&amp;amp; key.equals(k))))
            e = p;
        else if (p instanceof TreeNode)
            e = ((TreeNode&amp;lt;K,V&amp;gt;)p).putTreeVal(this, tab, hash, key, value);
        else {
            for (int binCount = 0; ; ++binCount) {
                if ((e = p.next) == null) {
                    p.next = newNode(hash, key, value, null);
                    //TREEIFY_THRESHOLD默认为8，当链表的大小大于8的时候就一定会转化为红黑树吗？
                    if (binCount &amp;gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        treeifyBin(tab, hash);
                    break;
                }
    ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;答案是不一定，hashMap在treeifyBin方法中将链表转换为红黑树，但会有一个判断，如果当前的hashMap长度小于64是，会对hashMap进行扩容resize()。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;final void treeifyBin(Node&amp;lt;K,V&amp;gt;[] tab, int hash) {
    int n, index; Node&amp;lt;K,V&amp;gt; e;
    //MIN_TREEIFY_CAPACITY 64
    if (tab == null || (n = tab.length) &amp;lt; MIN_TREEIFY_CAPACITY)
        resize();
    ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;在HashMap中我们直接接触的最常用的两个方法就是get和put方法&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}

public V get(Object key) {
    Node&amp;lt;K,V&amp;gt; e;
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}

static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h &amp;gt;&amp;gt;&amp;gt; 16);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;我们通过hashCode和equals方法来保证HashMap中的key值的唯一性。
当我们调用put存值时，HashMap首先会调用K的hashCode方法，获取哈希码，通过哈希码快速找到某个存放位置，这里需要注意的是，如果hashCode不同，equals一定为false，如果hashCode相同，equals不一定为true。所以理论上，hashCode可能存在冲突的情况，也就是碰撞，当碰撞发生时，计算出的hashCode是相同的，这时会比较对应hashCode位置的key，最终通过equals来比较。HashMap通过hashCode和equals最终判断出K是否已存在，如果两个hash值相等且key值相等(e.hash == hash &amp;amp;&amp;amp; ((k = e.key) == key || key.equals(k))),则用新的Entry的value覆盖原来节点的value。如果两个hash值相等但key值不等 ，则将该节点插入该链表的链头。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如果冲突发生的次数多了，链表的长度越来越长，该怎么办呢？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;随着HashMap中元素的数量越来越多，发生碰撞的概率也就越来越大，碰撞所产生的链表长度也就会越来越长，这样势必会影响HashMap的速度，因为原来找到数组的index就可以直接根据key取到值了，但是冲突严重，也就是说链表长，那就得循环链表了，时间就浪费在循环链表上了，也就慢了。为了保证HashMap的效率，系统必须要在某个临界点进行扩容处理。该临界点在当HashMap中元素的数量等于table数组长度*加载因子。但是扩容是一个非常耗时的过程，因为它需要重新计算这些数据在新table数组中的位置并进行复制处理。所以如果我们已经预知HashMap中元素的个数，那么预设元素的个数能够有效的提高HashMap的性能。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;hashMap为什么是线程不安全的？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;当hashMap扩容的时候会调用transfer方法，它是采用头插法来转移旧值到新的hashMap中去，假如转移前链表顺序是1-&amp;gt;2-&amp;gt;3，那么转移后就会变成3-&amp;gt;2-&amp;gt;1，那么在多线程的情况下就可能造成1-&amp;gt;2的同时2-&amp;gt;1的环形链表，进而形成死循环。&lt;/p&gt;

&lt;p&gt;那在多线程下使用HashMap我们可以采用如下几种方案：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在外部包装HashMap，实现同步机制&lt;/li&gt;
  &lt;li&gt;使用集合的工具类 Collections的静态方法synchronizedMap，在这个方法中创建了工具类 Collections中的内部类SynchronizedMap的实例来实现HashMap的线程安全：Map m = Collections.synchronizedMap(new HashMap(…));，这里就是对HashMap做了一次包装&lt;/li&gt;
  &lt;li&gt;使用java.util.HashTable，效率最低&lt;/li&gt;
  &lt;li&gt;使用java.util.concurrent.ConcurrentHashMap，相对安全，效率较高。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;二、HashTable&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.1 HashTable的定义&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;HashTable和HashMap很相似，但HashTable是线程安全的，同时HashTable中的key和value都不能为null。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;public class Hashtable&amp;lt;K,V&amp;gt;
    extends Dictionary&amp;lt;K,V&amp;gt;
    implements Map&amp;lt;K,V&amp;gt;, Cloneable, java.io.Serializable {}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.2 Hashtable的基本方法&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//构造一个具有默认初始容量 (11) 和默认加载因子 (0.75) 的空 Hashtable。
Hashtable()
//构造一个带指定初始容量和默认加载因子 (0.75) 的空 Hashtable。
Hashtable(int initialCapacity)
//构造一个带指定初始容量和加载因子的空 Hashtable。
Hashtable(int initialCapacity, float loadFactor)
//构造一个映射关系与指定 Map 相同的 Hashtable。
Hashtable(Map&amp;lt;? extends K, ? extends V&amp;gt; t)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;在Hashtable中很多操作Hashtable的方法都加上了synchronized关键字来保证线程安全，比如：get和put方法。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public synchronized V put(K key, V value) {}
public synchronized V get(Object key) {}
public synchronized V remove(Object key) {}
public synchronized void clear() {}
public synchronized Object clone() {}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;HashMap与HashTable的几点不同&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;1、HashMap是非线程安全的，而HashTable是线程安全的；&lt;/p&gt;

&lt;p&gt;2、HashMap的遍历一般使用Iterator，而HashTable一般使用的是Enumeration。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public interface Enumeration&amp;lt;E&amp;gt; {

    boolean hasMoreElements();

    E nextElement();
}

public interface Iterator&amp;lt;E&amp;gt; {
 
    boolean hasNext();

    E next();

    default void remove() {
        throw new UnsupportedOperationException(&quot;remove&quot;);
    }

    default void forEachRemaining(Consumer&amp;lt;? super E&amp;gt; action) {
        Objects.requireNonNull(action);
        while (hasNext())
            action.accept(next());
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;从上面JDK1.8版本中的Enumeration和Iterator的代码中可以看到，Iterator对集合的操作多了一个remove，也就是说在对HashMap进行遍历的时候可以调用Iterator的remove方法来删除HashMap中的值。值得注意的是，Iterator支持fail-fast机制，在用Iterator遍历一个集合时，如果另外的线程调用了该集合的remove方法，则会抛出ConcurrentModificationException(比较了modCount == expectedModCount)，但调用Iterator的remove方法则不会。Enumeration的遍历输出是先进后出的，而Iterator的遍历输出是先进先出的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;三、concurrentHashMap&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;从上面可以看出Hashtable和Collections.synchronizedMap(hashMap)基本上是对读写进行加锁操作，一个线程在读写元素，其余线程必须等待，性能是十分糟糕的，而且Hashtable已经过时了。为了提高高并发下的性能，我们来看下并发安全的ConcurrentHashMap。ConcurrentHashMap之所以高效是因为它更好的降低了锁的粒度，锁加在了每个Segment上而不是直接加在整个HashMap上，参数concurrencyLevel是用户估计的并发级别，就是说你觉得最多有多少线程共同修改这个map，根据这个来确定Segment数组的大小，concurrencyLevel默认为16。ConcurrentHashMap的key和value都不能为null。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.1 先来看下ConcurrentHashMap 在JDK1.6中的版本。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;ConcurrentHashMap采用分段锁的机制，实现并发的更新操作，底层采用数组+链表+红黑树的存储结构。&lt;/p&gt;

&lt;p&gt;其包含两个核心静态内部类 Segment和HashEntry。&lt;/p&gt;

&lt;p&gt;Segment继承ReentrantLock用来充当锁的角色，每个 Segment 对象守护每个散列映射表的若干个桶。&lt;/p&gt;

&lt;p&gt;HashEntry 用来封装映射表的键 / 值对；
每个桶是由若干个 HashEntry 对象链接起来的链表。&lt;/p&gt;

&lt;p&gt;一个 ConcurrentHashMap 实例中包含由若干个 Segment 对象组成的数组，如图所示：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;浅谈hashMap、hashTable、ConcurrentHashMap（1.6、1.8）&quot; 图片1=&quot;&quot; src=&quot;http://img.mukewang.com/598581d50001106005020537.png&quot; style=&quot;width:70%&quot; alt=&quot;ConcurrentHashMap 1.6&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.2 ConcurrentHashMap 在JDK1.8中的版本&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;而在JDK1.8中的实现已经抛弃了Segment分段锁机制，利用CAS+Synchronized来保证并发更新的安全，底层依然采用数组+链表+红黑树的存储结构。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.jianshu.com/p/fb6e91b013cc&quot;&gt;CAS&lt;/a&gt;，Compare and Swap即比较并替换，CAS有三个操作数：内存值V、旧的预期值A、要修改的值B，当且仅当预期值A和内存值V相同时，将内存值修改为B并返回true，如果不相同则证明内存值在并发的情况下被其它线程修改过了，则不作任何修改，返回false，等待下次再修改。&lt;/p&gt;

&lt;p&gt;table：默认为null，初始化发生在第一次插入操作，默认大小为16的数组，用来存储Node节点数据，扩容时大小总是2的幂次方。&lt;/p&gt;

&lt;p&gt;Node：保存key，value及key的hash值的数据结构。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;static class Node&amp;lt;K,V&amp;gt; implements Map.Entry&amp;lt;K,V&amp;gt; {
    final int hash;
    final K key;
    volatile V val;//保证并发的可见性
    volatile Node&amp;lt;K,V&amp;gt; next;//保证并发的可见性
    ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;table初始化操作会延缓到第一次put行为，但put方法是可以并发的，那么如何确保table只初始化一次？在initTable方法中用sizeCtl来确保，sizeCtl变量是用volatile修饰的。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private transient volatile int sizeCtl;

public V put(K key, V value) {
    return putVal(key, value, false);
}

/** Implementation for put and putIfAbsent */
final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    int hash = spread(key.hashCode());
    int binCount = 0;
    for (Node&amp;lt;K,V&amp;gt;[] tab = table;;) {
        Node&amp;lt;K,V&amp;gt; f; int n, i, fh;
        if (tab == null || (n = tab.length) == 0)
            //初始化table
            tab = initTable();
        //tabAt调用Unsafe.getObjectVolatile获取指定内存的数据f
        else if ((f = tabAt(tab, i = (n - 1) &amp;amp; hash)) == null) {
            //如果f为null，说明table中这个位置第一次插入元素，利用casTabAt调用Unsafe.compareAndSwapObject方法插入Node节点
            if (casTabAt(tab, i, null,
                         new Node&amp;lt;K,V&amp;gt;(hash, key, value, null)))
                break;                   // no lock when adding to empty bin
        }
        //如果hash为-1，意味有其它线程正在扩容，则一起进行扩容操作。
        else if ((fh = f.hash) == MOVED)
            tab = helpTransfer(tab, f);
        //其余情况把新的Node节点按链表或红黑树的方式插入到合适的位置，这个过程采用同步内置锁实现并发
        else {
            V oldVal = null;
            synchronized (f) {
                //比较当前内存中的值是否还是f，防止被其它线程修改
                if (tabAt(tab, i) == f) {
                    //如果f.hash &amp;gt;= 0，说明f是链表结构的头结点，遍历链表，如果找到对应的node节点，则修改value，否则在链表尾部加入节点
                    if (fh &amp;gt;= 0) {
                        binCount = 1;
                        for (Node&amp;lt;K,V&amp;gt; e = f;; ++binCount) {
                            K ek;
                            if (e.hash == hash &amp;amp;&amp;amp;
                                ((ek = e.key) == key ||
                                 (ek != null &amp;amp;&amp;amp; key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            Node&amp;lt;K,V&amp;gt; pred = e;
                            if ((e = e.next) == null) {
                                pred.next = new Node&amp;lt;K,V&amp;gt;(hash, key,
                                                          value, null);
                                break;
                            }
                        }
                    }
                    else if (f instanceof TreeBin) {
                        Node&amp;lt;K,V&amp;gt; p;
                        binCount = 2;
                        if ((p = ((TreeBin&amp;lt;K,V&amp;gt;)f).putTreeVal(hash, key,
                                                       value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                }
            }
            if (binCount != 0) {
                //如果链表中节点数binCount &amp;gt;= TREEIFY_THRESHOLD(默认是8)，则把链表转化为红黑树结构，提高遍历查询效率。
                if (binCount &amp;gt;= TREEIFY_THRESHOLD)
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    //检查当前容量是否需要进行扩容
    addCount(1L, binCount);
    return null;
}

private final Node&amp;lt;K,V&amp;gt;[] initTable() {
    Node&amp;lt;K,V&amp;gt;[] tab; int sc;
    while ((tab = table) == null || tab.length == 0) {
        //如果一个线程发现sizeCtl&amp;lt;0，意味着另外的线程执行CAS操作成功，当前线程只需要让出cpu时间片
        if ((sc = sizeCtl) &amp;lt; 0)
            Thread.yield(); // lost initialization race; just spin
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
            try {
                if ((tab = table) == null || tab.length == 0) {
                    int n = (sc &amp;gt; 0) ? sc : DEFAULT_CAPACITY;
                    @SuppressWarnings(&quot;unchecked&quot;)
                    Node&amp;lt;K,V&amp;gt;[] nt = (Node&amp;lt;K,V&amp;gt;[])new Node&amp;lt;?,?&amp;gt;[n];
                    table = tab = nt;
                    sc = n - (n &amp;gt;&amp;gt;&amp;gt; 2);
                }
            } finally {
                sizeCtl = sc;
            }
            break;
        }
    }
    return tab;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;sizeCtl默认为0，如果ConcurrentHashMap实例化时有传参数，sizeCtl会是一个2的幂次方的值。所以执行第一次put操作的线程会执行Unsafe.compareAndSwapInt方法修改sizeCtl为-1，有且只有一个线程能够修改成功，其它线程通过Thread.yield()让出CPU时间片等待table初始化完成。&lt;/p&gt;

&lt;p&gt;ConcurrentHashMap 是一个并发散列映射表的实现，它允许完全并发的读取，并且支持给定数量的并发更新。相比于 HashTable 和同步包装器包装的 HashMap，使用一个全局的锁来同步不同线程间的并发访问，同一时间点，只能有一个线程持有锁，也就是说在同一时间点，只能有一个线程能访问容器，这虽然保证多线程间的安全并发访问，但同时也导致对容器的访问变成串行化的了。&lt;/p&gt;

&lt;p&gt;1.6中采用ReentrantLock 分段锁的方式，使多个线程在不同的segment上进行写操作不会发现阻塞行为；1.8中直接采用了内置锁synchronized&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考文献：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;HashMap深度解析：http://blog.csdn.net/ghsau/article/details/16843543&lt;/p&gt;

&lt;p&gt;谈谈HashMap线程不安全的体现：http://www.importnew.com/22011.html&lt;/p&gt;

&lt;p&gt;JDK 1.8 ConcurrentHashMap 源码剖析：http://blog.csdn.net/lsgqjh/article/details/54867107&lt;/p&gt;

&lt;p&gt;java中的CAS：http://www.jianshu.com/p/fb6e91b013cc&lt;/p&gt;
</description>
        <pubDate>Tue, 13 Jun 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/java/2017/06/13/%E6%B5%85%E8%B0%88hashMap-hashTable-ConcurrentHashMap-1.6-1.8.html</link>
        <guid isPermaLink="true">http://localhost:4000/java/2017/06/13/%E6%B5%85%E8%B0%88hashMap-hashTable-ConcurrentHashMap-1.6-1.8.html</guid>
        
        <category>hashMap</category>
        
        <category>hashTable</category>
        
        <category>ConcurrentHashMap</category>
        
        
        <category>Java</category>
        
      </item>
    
      <item>
        <title>死磕redis-Spring使用redis存储sessionId</title>
        <description>&lt;p&gt;&lt;strong&gt;一、redis 储备知识&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Redis 是完全开源免费的一个高性能的key-value数据库。&lt;/p&gt;

&lt;p&gt;Redis支持五种数据类型：string（字符串），hash（哈希），list（列表），set（集合）及zset(sorted set：有序集合)。&lt;/p&gt;

&lt;p&gt;string类型是Redis最基本的数据类型，一个键最大能存储512MB。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;127.0.0.1:6379&amp;gt; set database “redis”&lt;/p&gt;

  &lt;p&gt;OK&lt;/p&gt;

  &lt;p&gt;127.0.0.1:6379&amp;gt; get database&lt;/p&gt;

  &lt;p&gt;“redis”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。每个 hash 可以存储 2^32 -1 键值对（40多亿）。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;127.0.0.1:6379&amp;gt; hmset user:1 zhoum 24 man coder&lt;/p&gt;

  &lt;p&gt;OK&lt;/p&gt;

  &lt;p&gt;127.0.0.1:6379&amp;gt; hgetall user:1&lt;/p&gt;

  &lt;p&gt;1) “zhoum”&lt;/p&gt;

  &lt;p&gt;2) “24”&lt;/p&gt;

  &lt;p&gt;3) “man”&lt;/p&gt;

  &lt;p&gt;4) “coder”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Redis List列表是简单的字符串列表，按照插入顺序排序。列表最多可存储 2^32 - 1 元素。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;127.0.0.1:6379&amp;gt; lpush databases redis&lt;/p&gt;

  &lt;p&gt;(integer) 1&lt;/p&gt;

  &lt;p&gt;127.0.0.1:6379&amp;gt; lpush databases mysql&lt;/p&gt;

  &lt;p&gt;(integer) 2&lt;/p&gt;

  &lt;p&gt;127.0.0.1:6379&amp;gt; lpush databases sqlite&lt;/p&gt;

  &lt;p&gt;(integer) 3&lt;/p&gt;

  &lt;p&gt;127.0.0.1:6379&amp;gt; lpush databases mongodb&lt;/p&gt;

  &lt;p&gt;(integer) 4&lt;/p&gt;

  &lt;p&gt;127.0.0.1:6379&amp;gt; lrange databases 0 10&lt;/p&gt;

  &lt;p&gt;1) “mongodb”&lt;/p&gt;

  &lt;p&gt;2) “sqlite”&lt;/p&gt;

  &lt;p&gt;3) “mysql”&lt;/p&gt;

  &lt;p&gt;4) “redis”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Redis的Set是string类型的无序集合。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;127.0.0.1:6379&amp;gt; sadd databases redis&lt;/p&gt;

  &lt;p&gt;(integer) 1&lt;/p&gt;

  &lt;p&gt;127.0.0.1:6379&amp;gt; sadd databases mysql&lt;/p&gt;

  &lt;p&gt;(integer) 1&lt;/p&gt;

  &lt;p&gt;127.0.0.1:6379&amp;gt; sadd databases sqlite&lt;/p&gt;

  &lt;p&gt;(integer) 1&lt;/p&gt;

  &lt;p&gt;127.0.0.1:6379&amp;gt; sadd databases sqlite&lt;/p&gt;

  &lt;p&gt;(integer) 0&lt;/p&gt;

  &lt;p&gt;127.0.0.1:6379&amp;gt; smembers databases&lt;/p&gt;

  &lt;p&gt;1) “sqlite”&lt;/p&gt;

  &lt;p&gt;2) “mysql”&lt;/p&gt;

  &lt;p&gt;3) “redis”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Redis zset 和 set 一样也是string类型元素的有序集合,且不允许重复的成员。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;127.0.0.1:6379&amp;gt; zadd databases 0 redis&lt;/p&gt;

  &lt;p&gt;(integer) 1&lt;/p&gt;

  &lt;p&gt;127.0.0.1:6379&amp;gt; zadd databases 0 mysql&lt;/p&gt;

  &lt;p&gt;(integer) 1&lt;/p&gt;

  &lt;p&gt;127.0.0.1:6379&amp;gt; zadd databases 0 sqlite&lt;/p&gt;

  &lt;p&gt;(integer) 1&lt;/p&gt;

  &lt;p&gt;127.0.0.1:6379&amp;gt; zadd databases 0 sqlite&lt;/p&gt;

  &lt;p&gt;(integer) 0&lt;/p&gt;

  &lt;p&gt;127.0.0.1:6379&amp;gt; ZRANGEBYSCORE databases 0 1000&lt;/p&gt;

  &lt;p&gt;1) “redis”&lt;/p&gt;

  &lt;p&gt;2) “mysql”&lt;/p&gt;

  &lt;p&gt;3) “sqlite”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;二、Spring使用redis存储sessionid&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;pom.xml中的redis部分&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.data&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-data-redis&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;

&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;redis.clients&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;jedis&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;配置文件：redis.properties&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;redis.maxIdle=100  
redis.maxActive=300  
redis.maxWait=1000  
redis.timeout=100000  
redis.maxTotal=1000  
redis.minIdle=8  
redis.testOnBorrow=true
redis.host=127.0.0.1
redis.port=6379
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Spring redis配置文件：redis-context.xml&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;beans&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;xmlns=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://www.springframework.org/schema/beans&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;xmlns:xsi=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;xmlns:p=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://www.springframework.org/schema/p&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;xsi:schemaLocation=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;

    &lt;span class=&quot;nt&quot;&gt;&amp;lt;bean&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;id=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;jedisPoolConfig&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;redis.clients.jedis.JedisPoolConfig&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;maxIdle&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;${redis.maxIdle}&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;maxTotal&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;${redis.maxTotal}&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;maxWaitMillis&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;${redis.maxWait}&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;testOnBorrow&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;${redis.testOnBorrow}&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/bean&amp;gt;&lt;/span&gt;

    &lt;span class=&quot;nt&quot;&gt;&amp;lt;bean&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;id=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;jedisConnectionFactory&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;org.springframework.data.redis.connection.jedis.JedisConnectionFactory&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;poolConfig&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;ref=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;jedisPoolConfig&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;hostName&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;${redis.host}&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;port&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;${redis.port}&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/bean&amp;gt;&lt;/span&gt;

    &lt;span class=&quot;nt&quot;&gt;&amp;lt;bean&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;id=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;redisTemplate&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;org.springframework.data.redis.core.RedisTemplate&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;connectionFactory&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;ref=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;jedisConnectionFactory&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;keySerializer&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;bean&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;org.springframework.data.redis.serializer.StringRedisSerializer&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;valueSerializer&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;bean&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;org.springframework.data.redis.serializer.JdkSerializationRedisSerializer&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;hashKeySerializer&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;bean&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;org.springframework.data.redis.serializer.StringRedisSerializer&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;hashValueSerializer&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;bean&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;org.springframework.data.redis.serializer.JdkSerializationRedisSerializer&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/bean&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/beans&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;java代码&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import org.springframework.data.redis.core.RedisTemplate;
import java.io.Serializable;

@Autowired
protected RedisTemplate&amp;lt;Serializable, Serializable&amp;gt; redisTemplate;

public void addAdminRedis(String sessionId, Integer aid) {
    if(null != sessionId &amp;amp;&amp;amp; null != aid){
        redisTemplate.opsForValue().set(sessionId+ADMIN_SUFFIX,aid);
    }
}

public AdministratorVo getAdminRedis(String sessionId) {
    if(null == sessionId){
        return  null;
    }
    if(null == redisTemplate.opsForValue().get(sessionId+ADMIN_SUFFIX)){
        return  null;
    }
    Integer aid = (Integer)redisTemplate.opsForValue().get(sessionId+ADMIN_SUFFIX);
    AdministratorVo admin = adminMapper.selectAdminById(aid);
    if(null != admin){
        admin.setPassword(null);
    }
    return admin;
}

public void deleteAdminRedis(String sessionId) {
    if(sessionId != null){
        AdministratorVo vo = getAdminRedis(sessionId+ADMIN_SUFFIX);
        if(null != vo){
            redisTemplate.delete(ADMIN_POWER_PREFIX+vo.getId().toString());
        }

        redisTemplate.delete(sessionId+ADMIN_SUFFIX);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Thu, 01 Jun 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/database/2017/06/01/%E6%AD%BB%E7%A3%95redis-Spring%E4%BD%BF%E7%94%A8redis%E5%AD%98%E5%82%A8sessionId.html</link>
        <guid isPermaLink="true">http://localhost:4000/database/2017/06/01/%E6%AD%BB%E7%A3%95redis-Spring%E4%BD%BF%E7%94%A8redis%E5%AD%98%E5%82%A8sessionId.html</guid>
        
        <category>redis</category>
        
        <category>Spring</category>
        
        <category>sessionId</category>
        
        
        <category>Database</category>
        
      </item>
    
      <item>
        <title>浅谈Java多线程</title>
        <description>&lt;p&gt;Java多线程是Java程序员必须掌握的基本的知识点，这块知识点比较复杂，知识点也比较多，今天我们一一来聊下Java多线程，系统的整理下这部分内容。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;一、Java中线程创建的三种方式：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;1．通过继承Thread类，重写Thread的run()方法，将线程运行的逻辑放在其中&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class MyThread extends Thread{  
    public void run(){  
        //do run something 
  }  
}  
public class ThreadDemo {  
    public static void main(String[] args) {  
        MyThread mt1= new MyThread();  
        MyThread mt2= new MyThread();  
        MyThread mt3= new MyThread();  
        mt1.start();  
        mt2.start();  
        mt3.start();  
    }  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;2．通过实现Runnable接口，实例化Thread类&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//构造一个实现了Runnable接口的类
class MyThread1 implements Runnable{ 
    public void run(){  
        //do run something 
    }  
}
public class RunnableDemo {  
    public static void main(String[] args) {  
    	//创建一个类对象
        MyThread1 mt = new MyThread1();  
        //由Runnable创建Thread对象
        Thread t1 = new Thread(mt);  
        Thread t2 = new Thread(mt);  
        Thread t3 = new Thread(mt);  
        //启动线程
        t1.start();  
        t2.start();  
        t3.start();  
    }  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;3．实现Callable接口，创建FutureTask包装器，实例化Thread类&lt;/p&gt;

&lt;p&gt;FutureTask实现接口类图：&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;浅谈Java多线程&quot; 图片1=&quot;&quot; src=&quot;http://img.mukewang.com/59b20e0e0001c1d704360178.png&quot; alt=&quot;FutureTask实现接口类图&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public interface Future&amp;lt;V&amp;gt; {
	//取消任务的运行
    boolean cancel(boolean mayInterruptIfRunning);
	//如果任务在完成前取消了返回true
    boolean isCancelled();
	//任务结束（正常结束、中途取消、发生异常）,返回true
    boolean isDone();
	//返回最终计算完成的结果
    V get() throws InterruptedException, ExecutionException;
	//返回在指定时间内计算的结果，如果超过指定时间没有结果则抛出TimeoutException异常
    V get(long timeout, TimeUnit unit)
        throws InterruptedException, ExecutionException, TimeoutException;
}

public interface Callable&amp;lt;V&amp;gt;{
    V call() throws Exception;
}

class MyThread2 implements Callable&amp;lt;Integer&amp;gt;{
    public Integer call(){
        //do call something
    }
}

public class CallableDemo{
    public static void main(String[] args){
        MyThread2 mt = new MyThread2();
        FutureTask&amp;lt;Integer&amp;gt; task = new FutureTask&amp;lt;&amp;gt;(mt);
        Thread t = new Thread(task);
        t.start();
        Integer result = task.get();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;注意：&lt;/p&gt;

&lt;p&gt;1、不要直接调用Thread类或Runnable接口的run方法，直接调用run方法单纯执行run方法体中的内容，而不会启动新线程，应该调用Thread的start方法，这个方法将创建一个执行run方法的新线程。&lt;/p&gt;

&lt;p&gt;2、尽量不要使用第一种方式来创建线程，因为有多个任务，这种方式需要为每个任务创建一个独立的线程（new MyThread()），这个代价太大。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;二、未捕获异常处理器&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们知道在run方法中无法抛出任何不可查的异常，但一旦run方法中出现了这类异常则会直接导致线程终止，在这种情况下，线程就GG了。通过分析，我们知道在线程死亡之前，异常会被传递到一个用于未捕获异常的处理器中，所以为了防止这种情况出现，我们可以为线程安装一个未捕获异常处理器。&lt;/p&gt;

&lt;p&gt;未捕获异常处理器必须实现Thread.UncaughtExceptionHanlder接口的类（这个接口类在Thread），这个类只有一个方法：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@FunctionalInterface
public interface UncaughtExceptionHandler {
    void uncaughtException(Thread t, Throwable e);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;通过Thread的静态方法&lt;code class=&quot;highlighter-rouge&quot;&gt;setDefaultUncaughtExceptionHandler(UncaughtExceptionHandler eh)&lt;/code&gt;为线程安装一个默认的处理器。&lt;/p&gt;

&lt;p&gt;当一个线程因为未捕获异常而终止时，通过uncaughtException方法的System.err.print打印异常信息。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public void uncaughtException(Thread t, Throwable e) {
    if (parent != null) {
        parent.uncaughtException(t, e);
    } else {
        Thread.UncaughtExceptionHandler ueh =
            Thread.getDefaultUncaughtExceptionHandler();
        if (ueh != null) {
            ueh.uncaughtException(t, e);
        } else if (!(e instanceof ThreadDeath)) {
            System.err.print(&quot;Exception in thread \&quot;&quot;
                             + t.getName() + &quot;\&quot; &quot;);
            e.printStackTrace(System.err);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;三、线程状态&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;线程的五个基本状态：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;新建（New）&lt;/li&gt;
  &lt;li&gt;可运行状态（Runnable）&lt;/li&gt;
  &lt;li&gt;运行时状态（Running）&lt;/li&gt;
  &lt;li&gt;阻塞状态（Blocked）&lt;/li&gt;
  &lt;li&gt;死亡状态（Dead）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;线程调用start()方法开始后，就进入到可运行状态，随着CPU的资源调度在运行和可运行之间切换；遇到阻塞则进入阻塞状态。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;这五种状态的相互之间转换图如下图所示：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;浅谈Java多线程&quot; 图片2=&quot;&quot; src=&quot;http://img.mukewang.com/59b20e2f0001c39a14580596.png&quot; style=&quot;width:100%&quot; alt=&quot;五种状态的相互之间转换图&quot; /&gt;&lt;/p&gt;

&lt;p&gt;线程被阻塞可能是由于下面五方面的原因：（《Thinking in Java》）&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;调用sleep(毫秒数)，使线程进入睡眠状态。在规定时间内，这个线程是不会运行的。&lt;/li&gt;
  &lt;li&gt;用suspend()暂停了线程的执行。除非收到resume()消息，否则不会返回“可运行”状态。这两个方法已经过时。&lt;/li&gt;
  &lt;li&gt;用wait()暂停了线程的执行。除非线程收到notify()或notifyAll()消息，否则不会变成“可运行”状态。&lt;/li&gt;
  &lt;li&gt;线程正在等候一些IO操作完成。&lt;/li&gt;
  &lt;li&gt;线程试图调用另一个对象的“同步”方法，但那个对象处于锁定状态，暂时无法使用。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;如果线程中有同步方法，那么线程状态图如下图所示：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;浅谈Java多线程&quot; 图片3=&quot;&quot; src=&quot;http://img.mukewang.com/59b20e430001126914620580.png&quot; style=&quot;width:100%&quot; alt=&quot;同步方法的线程状态图&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当互斥资源被一个线程访问时，互斥资源就上锁了，这时候其他线程访问该互斥资源就会进入了一个锁池（Lock pool）；当锁被释放，其他线程获得了锁，就变为可运行状态。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如果线程调用了wait()等方法，那么线程状态图如下图所示：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;浅谈Java多线程&quot; 图片4=&quot;&quot; src=&quot;http://img.mukewang.com/59b20e530001c4c914580592.png&quot; style=&quot;width:100%&quot; alt=&quot;线程相互作用的状态图&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们都知道线程调用了wait()（这个方法是Object的方法）方法之后，线程会释放掉锁，这个时候线程进入等待池（Wait pool）；等线程收到通知之后等待获取锁，获取锁之后才可以运行。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;四、线程同步&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在Java中线程同步分五种方式：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;synchronized&lt;/li&gt;
  &lt;li&gt;ReentrantLock与Condition&lt;/li&gt;
  &lt;li&gt;volatile&lt;/li&gt;
  &lt;li&gt;ThreadLocal&lt;/li&gt;
  &lt;li&gt;BlockingQueue&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;4.1 synchronized、wait与notify&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;当一个线程访问用synchronized关键字修饰的代码块，如果这个代码块被该线程第一个访问，则这个线程会获取到该Java对象的内部锁，其他线程访问的时候则会因为获取不到内部锁而阻塞。synchronized可以修饰类方法（static修饰的方法）、实例方法和类（Object.class），但是不能修饰抽象类的抽象方法和接口中的接口方法。&lt;/p&gt;

&lt;p&gt;线程在执行同步方法时是具有排它性的。当任意一个线程进入到一个对象的任意一个同步方法时，这个对象的所有同步方法都被锁定了，在此期间，其他任何线程都不能访问这个对象的任意一个同步方法，直到这个线程执行完它所调用的同步方法并从中退出，从而导致它释放了该对象的同步锁之后。在一个对象被某个线程锁定之后，其他线程是可以访问这个对象的所有非同步方法的。&lt;/p&gt;

&lt;p&gt;我们知道wait()和notify()方法只能在加锁的代码块中使用，因为调用wait()方法时会释放所持有的对象的lock，同时进入等待状态，notifyAll()方法会唤醒所有处入等待状态的线程，注意并不是给所有唤醒线程一个对象的锁，而是让它们竞争。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.2 ReentrantLock与Condition&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;ReentrantLock是可重入、互斥、实现了Lock接口的锁，它与使用synchronized方法和快具有相同的基本行为和语义，并且扩展了其能力。其lock和unlock必须成对出现，否则可能会出现死锁，通常在finally代码释放锁。ReentrantLock()还有一个可以创建公平锁的构造方法，但由于能大幅度降低程序运行效率，不推荐使用。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//fair为true时创建公平锁
public ReentrantLock(boolean fair) {
    sync = fair ? new FairSync() : new NonfairSync();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Condition代表条件对象，用于线程之间的通信，当一个线程A需要另一个线程B满足一定条件才可以继续操作时，A线程可以调用Condition的await()来阻塞当前线程，且放弃锁，等到B线程执行了某些操作并满足了一些条件后signalAll()唤醒阻塞的线程，当A线程重新强占了锁资源后再变成可运行状态。Condition条件对象对于一个对象来说可以有多个，但Object的wait()和notify()对于一个对象来说只有一个条件对象。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.3 volatile&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;对于volatile修饰的变量，jvm虚拟机保证从主内存加载到线程工作内存的值是最新的。volatile可保证变量的可见性，但无法保证原子性。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.4 ThreadLocal&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;多线程同步无非是让原本多个线程对某个操作并行变成串行，我们必须小心地对共享资源进行同步，同步不仅会带来一定的效能延迟，而且在处理同步的时候，又要注意对象的锁定与释放，稍有不慎就有可能产生死锁。&lt;/p&gt;

&lt;p&gt;既然这么麻烦，ThreadLocal不对共享资源加锁，而是为每个线程创造一个资源的复本。将每一个线程存取数据的行为加以隔离，实现的方法就是给予每个线程一个特定空间来保管该线程所独享的资源。&lt;/p&gt;

&lt;p&gt;当使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本。从线程的角度看，目标变量就象是线程的本地变量，这也是类名中“Local”所要表达的意思。在 ThreadLocal 类中有一个 ThreadLocalMap ，用于存储每一个线程的变量的副本。ThreadLocalMap是ThreadLocal类的一个静态内部类，它实现了键值对的设置和获取（对比Map对象来理解），每个线程中都有一个独立的ThreadLocalMap副本，它所存储的值，只能被当前线程读取和修改。ThreadLocal类通过操作每一个线程特有的ThreadLocalMap副本，从而实现了变量访问在不同线程中的隔离。&lt;/p&gt;

&lt;p&gt;锁是一种以时间换空间的机制，而ThreadLocal正好是以空间换时间的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.5 BlockingQueue&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;阻塞队列在&lt;a href=&quot;https://zhoum1118.github.io/java/2017/05/13/%E6%B5%85%E8%B0%88Java%E9%9B%86%E5%90%88Collection.html&quot;&gt;《浅谈Java集合Collection》&lt;/a&gt;有提到过：多线程操作共同的队列时不需要额外的同步，另外就是队列会自动平衡负载，即那边（生产与消费两边）处理快了就会被阻塞掉，从而减少两边的处理速度差距。&lt;/p&gt;

&lt;p&gt;参考文献：&lt;/p&gt;

&lt;p&gt;《Java核心技术》&lt;/p&gt;

&lt;p&gt;Java 多线程 线程状态图：http://www.cnblogs.com/mengdd/archive/2013/02/20/2917966.html&lt;/p&gt;

&lt;p&gt;JAVA中线程同步的方法：http://www.cnblogs.com/duanxz/p/3709608.html?utm_source=tuicool&amp;amp;utm_medium=referral&lt;/p&gt;
</description>
        <pubDate>Sun, 28 May 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/java/2017/05/28/%E6%B5%85%E8%B0%88Java%E5%A4%9A%E7%BA%BF%E7%A8%8B.html</link>
        <guid isPermaLink="true">http://localhost:4000/java/2017/05/28/%E6%B5%85%E8%B0%88Java%E5%A4%9A%E7%BA%BF%E7%A8%8B.html</guid>
        
        <category>Java</category>
        
        <category>多线程</category>
        
        
        <category>Java</category>
        
      </item>
    
      <item>
        <title>死磕JVM-垃圾收集器机制</title>
        <description>&lt;h2 id=&quot;引文&quot;&gt;&lt;strong&gt;引文&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Java GC主要可以由三个问题展开来讲&lt;/p&gt;

&lt;p&gt;1、哪些内存需要回收&lt;/p&gt;

&lt;p&gt;2、什么时候回收&lt;/p&gt;

&lt;p&gt;3、怎样回收&lt;/p&gt;

&lt;p&gt;这三个问题讲清楚后，至少在脑海里对Java GC有了一个比较清晰的理解，那接下来我们就一个个攻克这三个问题。&lt;/p&gt;

&lt;h2 id=&quot;1哪些内存需要回收&quot;&gt;&lt;strong&gt;1、哪些内存需要回收&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;就Java内存运行时区域来说，线程私有的程序计数器、虚拟机栈和本地方法栈随线程生而生，随线程亡而亡，因此这几个区域的内存分配和回收具备确定性，也就不需要过多考虑回收的问题，因为方法体结束或线程结束时，内存自然就跟着回收了。我们需要考虑的是线程共享的方法区和Java堆。&lt;/p&gt;

&lt;h2 id=&quot;2什么时候回收&quot;&gt;&lt;strong&gt;2、什么时候回收&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;下图是这一节的简介图
&lt;img title=&quot;死磕JVM-垃圾收集器机制_&quot; 图片1=&quot;&quot; src=&quot;http://img.mukewang.com/5922a76900018eae14500956.png&quot; alt=&quot;图片描述&quot; style=&quot;width:100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;“什么时候回收”这个问题对于&lt;strong&gt;Java堆&lt;/strong&gt;的直接的回答就是当对象死亡的时候，那对象什么死亡或者如何来标记一个对象是死是活呢？Java GC中有两种标志算法：引用计数算法和可达性分析算法。&lt;/p&gt;

&lt;h3 id=&quot;21-引用计数算法&quot;&gt;&lt;strong&gt;2.1 引用计数算法&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;算法思想：给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值加1，当引用失效时，计数器值减1。但触发一次GC的时候，对象的计数器的值为0的对象就说明该对象不可以再使用，可以被回收。&lt;/p&gt;

&lt;p&gt;这种标记的算法很简单高效，但就像&lt;a href=&quot;https://zhoum1118.github.io/javascript/2017/05/18/%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E6%9C%BA%E5%88%B6.html&quot;&gt;《死磕JavaScript-垃圾收集机制》&lt;/a&gt;中引用计数算法存在同样的弊端：相互循环引用。简单说就是对象A保有对象B的引用，同时对象B也保有对象A的引用，那么这两个对象的引用计数在任何时候都不会为0，也就是不会被GC回收。&lt;/p&gt;

&lt;h3 id=&quot;22-可达性分析算法&quot;&gt;&lt;strong&gt;2.2 可达性分析算法&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;算法思想：通过一系列的“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径为引用链，如果一个对象到每个GC Roots都不存在引用链，也即是说从GC Roots到这个对象不可达，那么就说明这个对象是死亡的，可以被GC回收的对象。&lt;/p&gt;

&lt;p&gt;在Java语言中，可以被当做GC Roots的对象有：&lt;/p&gt;

&lt;p&gt;1）虚拟机栈的本地变量表中的引用对象&lt;/p&gt;

&lt;p&gt;2）本地方法栈中引用的对象&lt;/p&gt;

&lt;p&gt;3）方法区中类静态属性引用对象&lt;/p&gt;

&lt;p&gt;4）方法区中常量引用对象&lt;/p&gt;

&lt;h3 id=&quot;23-引用的分类&quot;&gt;&lt;strong&gt;2.3 引用的分类&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;在Java1.2之前，对象只有被引用和未被引用两种状态，对象在未被引用的情况下就会在下一次触发GC的时候被GC回收，但我们有些对象当前可能没有被引用，但它可能经常被引用，那么在这个时刻由于它没有被引用则被GC回收了，在下次被重新引用的时候又需要加载进来，多次这样的操作后效率肯定是不高的，那么为了避免这种情况，在Java1.2之后，我们将引用分为4种。&lt;/p&gt;

&lt;h4 id=&quot;231-强引用&quot;&gt;&lt;strong&gt;2.3.1 强引用&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;这是普遍存在的一种引用，比如“Object obj = new Object()”，只要强引用存在，GC就不会回收这类引用的对象。&lt;/p&gt;

&lt;h4 id=&quot;232-软引用-softreference&quot;&gt;&lt;strong&gt;2.3.2 软引用 SoftReference&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;这是一种有用但非必需的对象，只有当内存不够用的时候，在抛出内存溢出之前才会将它列入GC回收的范围中（也就是说如果内存够用，这种引用的对象不会被列入GC回收的范围），只有在GC回收掉这些引用对象后内存还是不够用的情况下才会抛出内存溢出异常。&lt;/p&gt;

&lt;h4 id=&quot;233-弱引用-weakreference&quot;&gt;&lt;strong&gt;2.3.3 弱引用 WeakReference&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;弱引用关联的对象只能生存到下一次GC之前，当GC工作时，不管内存是否够用都会回收掉这部分对象&lt;/p&gt;

&lt;h4 id=&quot;234-虚引用-phantomreference&quot;&gt;&lt;strong&gt;2.3.4 虚引用 PhantomReference&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;这是最弱的一种引用关系，我们无法通过虚引用得到一个对象实例，为一个对象设置虚引用关联的唯一目的是在这个对象被GC的时候收到一个系统通知。&lt;/p&gt;

&lt;p&gt;上面讲的是Java堆的对象的回收，现在来讲下&lt;strong&gt;方法区中的回收&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;方法区（永久代）中的回收主要有两部分内容：废弃常量和无用的类。废弃常量指的是没有任何对象引用了这个常量；无用的类必需满足以下三个条件：&lt;/p&gt;

&lt;p&gt;1）这个类的所有实例都被回收&lt;/p&gt;

&lt;p&gt;2）该类的ClassLoader也被回收&lt;/p&gt;

&lt;p&gt;3）该类对应的java.lang.Class对象没有被引用，即无法通过反射来访问这个类的方法&lt;/p&gt;

&lt;h2 id=&quot;3怎样回收&quot;&gt;&lt;strong&gt;3、怎样回收&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;img title=&quot;死磕JVM-垃圾收集器机制_&quot; 图片2=&quot;&quot; src=&quot;http://img.mukewang.com/5922a7d80001891c14420992.png&quot; alt=&quot;图片描述&quot; style=&quot;width:100%&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 22 May 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/java/2017/05/22/%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E6%9C%BA%E5%88%B6.html</link>
        <guid isPermaLink="true">http://localhost:4000/java/2017/05/22/%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E6%9C%BA%E5%88%B6.html</guid>
        
        <category>java</category>
        
        <category>JVM</category>
        
        <category>GC</category>
        
        
        <category>Java</category>
        
      </item>
    
      <item>
        <title>死磕JVM-如何构造JVM内存溢出和栈溢出</title>
        <description>&lt;p&gt;为什么要写这个题目？我记得我在面试阿里的时候面试官问了我这个问题，当时没能答得很好，只说了些概念的东西，很是心虚，于是下定决心要把这个问题搞懂，现在终于把这个问题怼清楚了，分享给大家，希望你们以后面试问到这种问题能有所准备。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Java虚拟机中描述了两种异常：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;1、如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常；&lt;/p&gt;

&lt;p&gt;2、如果在虚拟机中无法申请到足够多的内存空间，将抛出OutOfMemoryError异常。&lt;/p&gt;

&lt;p&gt;我们都知道Java虚拟机各个内存区域（除了程序计数器）都有发生内存溢出的可能，但到底什么样的操作或程序才会导致内存溢出或栈溢出的异常呢？&lt;/p&gt;

&lt;p&gt;我们分不同的内存区域来解释这个问题。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;一、对于Java堆内存区域&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Java堆中只会产生OutOfMemoryError异常。&lt;/p&gt;

&lt;p&gt;先搞清楚Java堆内存放的是什么，还不清楚的可以回顾下这篇文章&lt;a href=&quot;https://zhoum1118.github.io/java/2017/05/16/Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B.html&quot;&gt;《死磕JVM-Java内存模型》&lt;/a&gt;，从这篇文章里我们知道Java堆内存存放的是对象实例，所以原理上只要我们不断创建对象，并且保证GC Roots到对象之间有可达路径来避免垃圾回收机制清楚这些对象，也就是说当Eden区满的时候，GC被触发时，让GC误以为内存中的对象还存活着，那么在对象数量达到最大堆容量限制的时候就会产生内存溢出的异常。如下代码就会产生内存溢出的异常：&lt;/p&gt;

&lt;pre class=&quot;prettyprint&quot;&gt;&lt;code&gt;&lt;span class=&quot;kwd&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;堆溢出&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;

     &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;static&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;OOMError&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;

     &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;static&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; main&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;[]&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; args&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;OOMError&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; list &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;OOMError&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;&amp;gt;();&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
               list&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;OOMError&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;());&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;运行结果：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Exception in thread “main” java.lang.OutOfMemoryError: Java heap space&lt;/p&gt;

  &lt;p&gt;at java.util.Arrays.copyOf(Arrays.java:3210)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;at java.util.Arrays.copyOf(Arrays.java:3181)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;at java.util.ArrayList.grow(ArrayList.java:261)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:235)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:227)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;at java.util.ArrayList.add(ArrayList.java:458)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;at com.intelligentler.jvm.堆溢出.main(堆溢出.java:13)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;“Java heap space”提示着产生OutOfMemoryError异常的Java虚拟机的内存区域，也就是Java堆内存。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如何解决发生在Java堆内存的OutOfMemoryError异常呢？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;首先我们要分清楚产生OutOfMemoryError异常的原因是内存泄露还是内存溢出，如果内存中的对象确实都必须存活着而不像上面那样不断地创建对象实例却不使用该对象，则是内存溢出，而像上面代码中的情况则是内存泄露。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如果是内存泄露&lt;/strong&gt;，我们可以通过一些内存查看工具来查看泄露对象到GC Roots的引用链，找到泄露对象是通过怎样的路径与GC Roots相关联并导致GC无法自动回收这些泄露对象，掌握了这些信息，我们就能比较准确地定位出泄露代码的位置。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如果不是内存泄露&lt;/strong&gt;，也就是说内存中的对象确实都还必须存活，那么应该检查虚拟机的堆参数，看看是否还可以将机器物理内存调大，同时在代码上检查是否存在某些对象生命周期过长、持有状态时间过长的情况。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;二、对于虚拟机栈和本地方法栈&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在这一部分内存区域，可能产生OutOfMemoryError异常和StackOverflowError异常。&lt;/p&gt;

&lt;p&gt;如果定义大量的本地变量，增大此方法帧中本地变量表的长度或者设置-Xss参数减少栈内存容量，这两种操作都会抛出StackOverflowError异常。&lt;/p&gt;

&lt;p&gt;如下面的代码：&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;&lt;code&gt;&lt;span class=&quot;kwd&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;栈溢出&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;private&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; stackLength &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;lit&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; addStackLength&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(){&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
          stackLength&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;++;&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
          addStackLength&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;();&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;static&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; main&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;[]&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; args&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;throws&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;Throwable&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;栈溢出&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; oom &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;栈溢出();&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
               oom&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;addStackLength&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;();&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;catch&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;Throwable&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; e&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
               &lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;str&quot;&gt;&quot;stack length:&quot;&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; oom&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;stackLength&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
               &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;throw&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; e&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;运行结果：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;stack length:18388&lt;/p&gt;

  &lt;p&gt;Exception in thread “main” java.lang.StackOverflowError&lt;/p&gt;

  &lt;p&gt;at com.intelligentler.jvm.栈溢出.addStackLength(栈溢出.java:9)&lt;/p&gt;

  &lt;p&gt;at com.intelligentler.jvm.栈溢出.addStackLength(栈溢出.java:9)&lt;/p&gt;

  &lt;p&gt;at com.intelligentler.jvm.栈溢出.addStackLength(栈溢出.java:9)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;所以，如果在单线程的情况下，无论是栈帧太大还是虚拟机栈容量太小，当内存无法再分配的时候，虚拟机抛出的是StackOverflowError异常。&lt;/p&gt;

&lt;p&gt;如果在多线程下，不断地建立线程可能会产生OutOfMemoryError异常。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;三、对于方法区&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;方法区中只会产生OutOfMemoryError异常。&lt;/p&gt;

&lt;p&gt;由于运行时常量池是方法区的一部分，我们可以通过String.intern()方法来构建一个运行时常量池的OutOfMemoryError异常。&lt;/p&gt;

&lt;p&gt;String.intern()是一个Native方法，它的作用是：如果字符串常量池中已经包含了一个等于该String对象的字符串，则返回这个String对象，否则，将此String对象包含的字符串添加到常量池中，并返回这个字符串的String对象的引用。如下面代码：&lt;/p&gt;

&lt;pre class=&quot;prettyprint&quot;&gt;&lt;code&gt;&lt;span class=&quot;kwd&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;方法区溢出&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;

     &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;static&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; main&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;[]&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; args&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; list &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;&amp;gt;();&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; i &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;lit&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
               list&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;valueOf&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;++).&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;intern&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;());&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;运行结果：&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Exception in thread “main” java.lang.OutOfMemoryError: PermGen space&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;at java.lang.String.intern(Native Method)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;PermGen space的全称是Permanent Generation space，是指内存的永久保存区域，也就是说运行时常量池属于方法区（也就是虚拟机永久代）中的一部分。&lt;/p&gt;

&lt;p&gt;另外，方法区是存放Class的相关信息的，运行时如果有大量的类来填满方法区，就会产生OutOfMemoryError异常。&lt;/p&gt;
</description>
        <pubDate>Fri, 19 May 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/java/2017/05/19/%E5%A6%82%E4%BD%95%E6%9E%84%E9%80%A0JVM%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%92%8C%E6%A0%88%E6%BA%A2%E5%87%BA.html</link>
        <guid isPermaLink="true">http://localhost:4000/java/2017/05/19/%E5%A6%82%E4%BD%95%E6%9E%84%E9%80%A0JVM%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%92%8C%E6%A0%88%E6%BA%A2%E5%87%BA.html</guid>
        
        <category>java</category>
        
        <category>JVM</category>
        
        <category>溢出</category>
        
        
        <category>Java</category>
        
      </item>
    
      <item>
        <title>死磕JavaScript-垃圾收集机制</title>
        <description>&lt;p&gt;JavaScript和Java一样具有自动垃圾收集机制。JavaScript的垃圾收集你机制的原理很简单：找出那些不再继续使用的变量，然后释放其占用的内存。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;标记清除：&lt;/strong&gt;这是最常用的垃圾收集方式。原理是：垃圾收集器在运行的时候会给存储在内存中的所有变量都加上标记—&amp;gt;然后，它会去掉环境中的变量以及被环境中的变量引用的变量的标记—&amp;gt;在此之后再被加上标记的变量将被视为准备删除的变量—&amp;gt;最后，垃圾收集器完成内存清除工作，销毁那些带标记的变量并回收它们所占用的内存空间。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;引用计数：&lt;/strong&gt;这是一种不太常见的垃圾收集方式，IE用的就是这种。引用计数是指追踪记录每个值被引用的次数，原理是：当声明一个变量并将一个引用类型值赋给该变量时，则这个值得引用次数初始化为1—&amp;gt;如果同一个值又被赋值给另一个变量，则该值的引用次数加1—&amp;gt;相反，如果包含对这个值引用的变量又取得了另外一个值，则这个值得引用次数减1—&amp;gt;当这个值得引用次数变为0时，说明无需再访问这个变量，可以被垃圾回收机制回收。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://img.mukewang.com/591d135e0001701703930115.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但引用计数存在循环引用的风险，循环引用指的是对象A包含一个指向对象B的指针，而对象B中也包含一个指向对象A的引用。比如：&lt;/p&gt;

&lt;p&gt;这里例子中，objectA和objectB通过各自的属性相互引用，也就是说，两个对象的引用次数都是2，尽管函数执行完毕后，objectA和objectB还将继续存在，因为它们的引用次数永远都不为0。&lt;/p&gt;

&lt;p&gt;IE因为采用了引用计数的垃圾收集而性能低下。&lt;/p&gt;

&lt;p&gt;当然，我们也可以通过解除变量的引用（解除引用）来消除循环引用现象，比如：objectA = null;和objectB = null。&lt;/p&gt;
</description>
        <pubDate>Thu, 18 May 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/javascript/2017/05/18/%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E6%9C%BA%E5%88%B6.html</link>
        <guid isPermaLink="true">http://localhost:4000/javascript/2017/05/18/%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E6%9C%BA%E5%88%B6.html</guid>
        
        <category>JavaScript</category>
        
        <category>垃圾收集</category>
        
        
        <category>Javascript</category>
        
      </item>
    
      <item>
        <title>死磕JVM-Java虚拟机对象</title>
        <description>&lt;p&gt;上篇文章我们了解了Java虚拟机的内存模型，也知道不同区域的内存都存储的是什么，现在我们进一步来探究内存上存储的数据是怎么创建的，内存大小又是怎么分配的，数据创建成功后怎么被访问的。我们以Java虚拟机中最大的内存块Java堆为例子来探究上面的三个问题。&lt;/p&gt;

&lt;h2 id=&quot;java堆上对象的创建&quot;&gt;&lt;strong&gt;Java堆上对象的创建&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Java虚拟机遇到一条new指令后，首先会去检查要创建的对象能否在常量池中定位到其对应类的符号引用，并且检查这个引用代表的类是否已经被加载、解析和初始化过，如果没有则先进行类加载过程。&lt;/p&gt;

&lt;p&gt;然后就是为这个对象分配内存，最后执行init方法，这样一个可用的对象创建完毕。&lt;/p&gt;
&lt;h2 id=&quot;java堆对象的内存分配&quot;&gt;&lt;strong&gt;Java堆对象的内存分配&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;在类加载检查通过之后，虚拟机就会为新生对象分配内存，分配方式因取决于Java堆中内存是否规整而分为“指针碰撞”和“空闲列表”。在Java堆中的内存是规整的情况下，内存分配方式采用“指针碰撞”，反之采用“空闲列表”。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;假设Java堆中的内存是绝对规整的&lt;/strong&gt;，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，分配内存的方式就是将这个指针往指向空闲空间那边挪动一段与对象大小相等的距离。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;假设Java堆中的内存不是规整的&lt;/strong&gt;，已使用的内存和空闲的内存相互交错，这样就无法进行简单地指针碰撞了，这时候虚拟机会维护一张列表，列表中记录哪些内存块是可用的，在分配内存的时候就从列表中找到一块足够大的空间划分给对象实例，同时更新列表上的记录，这种内存分配的方式叫做“空闲列表”。&lt;/p&gt;

&lt;p&gt;由此我们知道Java堆对象的内存分配策略是由Java堆内存是否规整来决定的，那么Java堆内存是否规整则由GC是否带有压缩整理功能决定的，所以一般在使用Serial、ParNew等带有压缩整理过程的收集器时，系统采用的是“指针碰撞”的分配策略，在使用CMS这种基于Mark-Sweep算法的收集器时，采用的是“空闲列表”的方式。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;由于Java堆是线程共享的，那么内存的分配在线程并发的情况下如何保证线程安全呢？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;不管采用哪种内存分配策略，在多线程下进行Java堆内存分配的时候，可能存在正在给A对象分配内存，但指针还没来得及修改而对象B又使用了原来的指针来分配内存的这种情况。&lt;/p&gt;

&lt;p&gt;有两种解决方案：第一是对分配内存空间的动作进行同步处理以保证操作的原子性，也就是说同一时刻只有一个线程能进行分配内存的操作；第二是把内存分配的操作按照线程划分在不同的空间中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲（Thread Local Allocation Buffer, TLAB）,线程在自己的TLAB中分配内存，只有在TLAB用完了，在分配新的TLAB时才需要同步锁定。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;讲完了Java堆对象的内存分配策略，那存储的对象到底存储的是什么呢？对象中都包含哪些内容呢？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;对象在内存中主要存储这三个信息：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。&lt;/p&gt;

&lt;p&gt;对象头，存储对象自身的运行时数据：哈希码，GC分代年龄，锁状态标志等。&lt;/p&gt;

&lt;p&gt;实例数据，存储对象真正有效的信息。&lt;/p&gt;

&lt;p&gt;对齐填充，起到占位符的作用，当实例数据部分没有对齐时，就需要对齐填充来补全。&lt;/p&gt;

&lt;h2 id=&quot;java堆对象的访问定位&quot;&gt;&lt;strong&gt;Java堆对象的访问定位&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;对象创建并分配好了内存，那么接下来就可以访问对象了，Java程序是通过栈中的reference数据来操作堆上的具体对象，虚拟机提供了两种机制来访问堆中的实例对象：句柄和直接指针。
使用句柄：Java堆中会划分一块区域作为句柄池，Java栈中的本地变量表中的reference数据存储的就是对象的句柄地址，而句柄中则包含的是到对象实例数据的指针和对象类型数据的指针。
&lt;img title=&quot;死磕JVM-Java虚拟机对象_&quot; 图片1=&quot;&quot; src=&quot;http://img.mukewang.com/591d078d0001d19915940584.png&quot; style=&quot;width:100%&quot; alt=&quot;图片描述&quot; /&gt;&lt;/p&gt;

&lt;p&gt;直接指针：reference数据存储是的对象的实例数据的引用地址和到对象类型数据的指针。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕JVM-Java虚拟机对象_&quot; 图片1=&quot;&quot; src=&quot;http://img.mukewang.com/591d079d0001210016240586.png&quot; style=&quot;width:100%&quot; alt=&quot;图片描述&quot; /&gt;&lt;/p&gt;

&lt;p&gt;使用句柄的好处是Java栈中的本地变量表中的reference数据是相对稳定的，不需要经常变动，比如在执行GC操作时移动对象，这个时候需要改变对象在堆中的地址，在句柄机制中，只需要改动句柄池中的实例数据的指针，而不需要修改reference数据。但缺点是增加了一次指针定位的开销，对于对象访问比较频繁的时候，这种开销累计起来也是很大的，所以对于HotSpot而言，使用的是直接指针的方式。&lt;/p&gt;
</description>
        <pubDate>Thu, 18 May 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/java/2017/05/18/Java%E5%A0%86%E4%B8%8A%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA.html</link>
        <guid isPermaLink="true">http://localhost:4000/java/2017/05/18/Java%E5%A0%86%E4%B8%8A%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA.html</guid>
        
        <category>java</category>
        
        <category>JVM</category>
        
        <category>虚拟机对象</category>
        
        
        <category>Java</category>
        
      </item>
    
      <item>
        <title>死磕JVM-Java内存模型</title>
        <description>&lt;p&gt;Java虚拟机是Java工程师必学的进阶功课，这段时间开始死磕JVM。今天把JVM的基础知识点Java的内存模型怼清楚，废话不多说，干货走起！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://img.mukewang.com/591a5ed500016f8704170268.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;程序计数器&quot;&gt;&lt;strong&gt;程序计数器&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;是什么&lt;/strong&gt;：程序计数器是很小的一块内存空间，它是当前线程所执行的字节码的行号指示器。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;有什么用：&lt;/strong&gt;解释器通过这个计数器来选取下一条需要执行的字节码指令。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;存储什么内容：&lt;/strong&gt;如果线程执行的是Java方法，存储的是正在执行的虚拟机字节码指令的地址；如果是native方法，计数器值为空（undefined）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;为什么是线程私有的：&lt;/strong&gt;多线程是线程轮流切换并分配处理器执行时间片的方式来实现的，在任何确定的时刻，一个处理器（对于多核处理器来说就是一个内核）都只会执行一条线程，所以，为了线程在切换后能恢复到正确的执行位置，每个线程应该独立拥有一个程序计数器。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;会出现什么异常情况：&lt;/strong&gt;唯一一个无内存溢出异常的区域。&lt;/p&gt;
&lt;h2 id=&quot;java虚拟机栈&quot;&gt;&lt;strong&gt;Java虚拟机栈&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;是什么：&lt;/strong&gt;虚拟机栈是Java方法的内存模型，每一个Java方法从调用到执行完成就对应着一个栈帧在虚拟机栈中的入栈和出栈。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;存储什么内容：&lt;/strong&gt;每个方法的执行就会创建一个栈帧，这个栈帧会存储这个Java方法的局部变量表，操作数栈，动态链接，方法出口等信息。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;为什么是线程私有的：&lt;/strong&gt;每个线程所执行的方法可能是不一样的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;会出现什么异常情况：&lt;/strong&gt;如果线程请求的栈深度&amp;gt;虚拟机允许的深度，抛出栈溢出异常；如果扩展时无法申请到足够的内存，抛出内存溢出异常。&lt;/p&gt;
&lt;h2 id=&quot;本地方法栈&quot;&gt;&lt;strong&gt;本地方法栈&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;是什么：&lt;/strong&gt;本地方法栈的作用和虚拟机栈非常相似，只不过本地方法栈是native方法的内存模型，每一个native方法从调用到执行完成就对应着一个栈帧在本地方法栈中的入栈和出栈。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;存储什么内容：&lt;/strong&gt;同虚拟机栈。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;为什么是线程私有的：&lt;/strong&gt;同虚拟机栈。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;会出现什么异常情况：&lt;/strong&gt;同虚拟机栈。&lt;/p&gt;
&lt;h2 id=&quot;java堆&quot;&gt;&lt;strong&gt;Java堆&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;是什么：&lt;/strong&gt;Java堆是Java虚拟机管理的内存中最大的一块，Java堆是在虚拟机启动的时候创建的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;存储什么内容：&lt;/strong&gt;存放对象实例，几乎所有的对象实例都在这个内存区域分配内存。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;为什么是线程共享的：&lt;/strong&gt;所有的线程都可以访问不同的对象。其实从内存分配的角度来看，线程共享的Java堆可能其实是多个线程私有的分配缓冲区，不同的线程将各自的对象实例放在看似共享的Java堆的各自的缓冲区上，这样划分可以更好的回收内存，也可以更好点分配内存。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;会出现什么异常情况：&lt;/strong&gt;Java堆可以处于物理上不连续的内存空间上，但逻辑上一定是连续的，在堆中没有内存可以完成对象实例的分配，且无法再扩展时，会抛出内存溢出异常。&lt;/p&gt;
&lt;h2 id=&quot;方法区&quot;&gt;&lt;strong&gt;方法区&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;是什么：&lt;/strong&gt;和堆一样，是各个线程共享的内存区域。很多人把方法区称为永久代，但是本质上这两个不等价，Java虚拟机将GC分代收集扩展至方法区，使用永久代来实现方法区，这样GC收集器就能像管理Java堆一样管理方法区而不需要再写一套GC收集来管理方法区。当然在方法区里也可以设置不进行GC收集。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;存储什么内容：&lt;/strong&gt;已被虚拟机加载的类信息，类常量，类的静态变量，即时编译器编译后的代码等。运行时常量池也是方法区的一部分。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;为什么是线程共享的：&lt;/strong&gt;各个线程都可以访问虚拟机加载的类。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;会出现什么异常情况：&lt;/strong&gt;内存溢出异常。&lt;/p&gt;
&lt;h2 id=&quot;直接内存&quot;&gt;&lt;strong&gt;直接内存&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;是什么：&lt;/strong&gt;直接内存并不是虚拟机运行时数据区的一部分，也不是Java虚拟机定义的内存区域，但也经常被使用。JDK1.4加入了NIO类，一种基于通道与缓冲区的新I/O方式，NIO可以使用native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为直接内存的引用来操作直接内存，这样可以避免在Java堆和native堆来回复制数据，从而提高了性能。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;会出现什么异常情况：&lt;/strong&gt;受机器总内存的影响，会出现内存溢出异常。&lt;/p&gt;
</description>
        <pubDate>Tue, 16 May 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/java/2017/05/16/Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B.html</link>
        <guid isPermaLink="true">http://localhost:4000/java/2017/05/16/Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B.html</guid>
        
        <category>java</category>
        
        <category>JVM</category>
        
        <category>内存模型</category>
        
        
        <category>Java</category>
        
      </item>
    
      <item>
        <title>死磕JavaScript-函数按值传递参数</title>
        <description>&lt;p&gt;早起打卡，今天死磕函数按值传递参数，干货走起……&lt;/p&gt;

&lt;p&gt;基本类型的变量传递是将值A复制一份给被传递的变量B，两个变量值得变化是互不干扰的；而引用类型的变量传递是将引用类型变量A的引用传递给被传递的变量B，这个B的变化会反映到A上。例如：&lt;/p&gt;

&lt;p&gt;例1：&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;&lt;code&gt;&lt;span class=&quot;kwd&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; addTen&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;){&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
     num &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;lit&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; num&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; count &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;lit&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; result &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; addTen&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
console&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;com&quot;&gt;//20&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
console&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;com&quot;&gt;//30&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;例2：&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;&lt;code&gt;&lt;span class=&quot;kwd&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; setName&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;obj&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;){&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
     obj&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;name &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;str&quot;&gt;&quot;javaScript&quot;&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; language &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;();&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
setName&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;language&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
console&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;language&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;com&quot;&gt;//javaScript&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这两种函数的值传递是比较好理解的，在例1中，num其实是addTen的局部变量，在调用addTen函数的时候，count将值复制给了局部变量num，虽然函数内部num的值加了10，但是这一变化不会影响给函数外部的count变量。复制前后栈的变化图如下：
&lt;img title=&quot;死磕JavaScript-函数按值传递参数_&quot; 图片1=&quot;&quot; src=&quot;http://img.mukewang.com/59165ced00011b7f19201338.jpg&quot; alt=&quot;图片描述&quot; style=&quot;width:100%&quot; /&gt;
在例2中你可能有所疑惑，因为这看起来就像是引用传递啊，不像是标题所说的函数按值传递，这里language的引用复制传递给了obj局部变量，所以是引用传递呀。那我们来看下一个例子：&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;&lt;code&gt;&lt;span class=&quot;kwd&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; setName&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;obj&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;){&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
     obj&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;name &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;str&quot;&gt;&quot;javaScript&quot;&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
     obj &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;();&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
     obj&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;name &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;str&quot;&gt;&quot;new JavaScript&quot;&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; language &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;();&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
setName&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;language&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
console&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;language&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;com&quot;&gt;//javaScript&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果说language是按引用传递的，那么language就会自动被修改为指向其name属性值为“new JavaScript”的新对象，但结果确实“javaScript”，我们看下复制前后的栈和堆的变化图就能更清楚了。&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;死磕JavaScript-函数按值传递参数_&quot; 图片1=&quot;&quot; src=&quot;http://img.mukewang.com/59165d240001d2e019201756.jpg&quot; alt=&quot;图片描述&quot; style=&quot;width:100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这下应该能明白了，也就是说这里的函数按值传递中的“值”指的是栈中的值，所以对于引用类型，是将栈中的language的值复制到obj中，也就是说这两个值对应的堆地址是一样的，其在堆中对应的对象是一样的，对obj中的改变对反映到language中，但如果改变了obj的堆地址那么obj和language就没什么关系了。&lt;/p&gt;

</description>
        <pubDate>Sun, 14 May 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/javascript/2017/05/14/%E5%87%BD%E6%95%B0%E6%8C%89%E5%80%BC%E4%BC%A0%E9%80%92%E5%8F%82%E6%95%B0.html</link>
        <guid isPermaLink="true">http://localhost:4000/javascript/2017/05/14/%E5%87%BD%E6%95%B0%E6%8C%89%E5%80%BC%E4%BC%A0%E9%80%92%E5%8F%82%E6%95%B0.html</guid>
        
        <category>JavaScript</category>
        
        <category>函数</category>
        
        <category>传递参数</category>
        
        
        <category>Javascript</category>
        
      </item>
    
      <item>
        <title>浅谈Java集合Collection</title>
        <description>&lt;p&gt;一直想找个时间系统的整理下Java的集合类，毕竟Collection包含了很多我们在实际项目中要用到的数据结构，比如列表、set、队列等，下面我们直接来看看Java集合类中各大数据结构。&lt;/p&gt;

&lt;p&gt;Collection部分层次结构如下所示：&lt;/p&gt;

&lt;p&gt;Collection &lt;br /&gt;
├List &lt;br /&gt;
│├LinkedList &lt;br /&gt;
│├ArrayList &lt;br /&gt;
│└Vector &lt;br /&gt;
│　└Stack &lt;br /&gt;
├Set &lt;br /&gt;
│├HashSet &lt;br /&gt;
│├TreeSet  &lt;br /&gt;
├Queue&lt;br /&gt;
│├BlockingQueue &lt;br /&gt;
│├ArrayDeque &lt;br /&gt;
│└PriorityQueue&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;一、Collection&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;子接口：Set，List，Queue&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;public interface Collection&amp;lt;E&amp;gt; extends Iterable&amp;lt;E&amp;gt; {}&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//获取该集合的大小
int size();
//判空
boolean isEmpty();
//判断集合是否包含某元素
boolean contains(Object o);
//获取集合的迭代器，迭代器的具体实现在子类中用内部类实现
Iterator&amp;lt;E&amp;gt; iterator();
//返回该集合的元素数组
Object[] toArray();
//添加元素
boolean add(E e);
//删除指定元素值的元素
boolean remove(Object o);
//判断集合是否包含指定集合中所有的元素
boolean containsAll(Collection&amp;lt;?&amp;gt; c);
//向当前集合添加指定集合中所有的元素
boolean addAll(Collection&amp;lt;? extends E&amp;gt; c);
//在当前集合中移除指定集合中所有的元素
boolean removeAll(Collection&amp;lt;?&amp;gt; c);
//保留指定集合中的元素，删除当前集合中不在指定集合中的元素
boolean retainAll(Collection&amp;lt;?&amp;gt; c);
//清空集合
void clear();
//Comparison and hashing
boolean equals(Object o);
int hashCode(); 还有一些复写Iterable接口的方法
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;二、List&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;实现类包括：LinkedList,Vector,ArrayList。&lt;/p&gt;

&lt;p&gt;继承Collection，可以按索引的顺序访问，元素顺序均是按添加的先后进行排列的，允许重复的元素,允许多个null元素。&lt;/p&gt;

&lt;p&gt;除了包含Collection中的方法，还有一些自己的方法。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;public interface List&amp;lt;E&amp;gt; extends Collection&amp;lt;E&amp;gt; {}&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//获取指定索引的元素
E get(int index);
//替代指定索引位置的元素
E set(int index, E element);
//添加指定索引位置的元素
void add(int index, E element);
//移除指定索引位置的元素
E remove(int index);
//获取指定元素在集合中第一次出现的索引值
int indexOf(Object o);
//获取指定元素在集合中最后一次出现的索引值
int lastIndexOf(Object o);
//获取ListIterator迭代器，迭代器的具体实现在子类中用内部类实现
ListIterator&amp;lt;E&amp;gt; listIterator();
//获取集合中从fromIndex到toIndex的值
List&amp;lt;E&amp;gt; subList(int fromIndex, int toIndex);
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;ListIterator&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;List除了具备Collection接口的iterator方法外，还提供了listIterator，listIterator相对iterator，允许添加、设定元素，前后向遍历。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;public interface ListIterator&amp;lt;E&amp;gt; extends Iterator&amp;lt;E&amp;gt; {}&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;boolean hasNext();
E next();
boolean hasPrevious();
E previous();
int nextIndex();
int previousIndex();
void remove();
void set(E e);
void add(E e);
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;2.1 ArrayList&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;ArrayList依赖于数组实现的，初始长度为10的Object[]，并且可随需要而增加的动态数组。当元素超过10，采用ensureCapacity方法来扩容，ArrayList底层会新生成一个数组，长度为原来的1.5倍+1, 也就是自动增长了差不多是原来的一半，然后将原数组内容复制到新数组中，并且后续增加的内容会放到新数组中。&lt;/p&gt;

&lt;p&gt;ArrayList对随机访问性能很好，但进行大量插入，删除操作，性能很差，因为操作之后后续元素需要移动。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;public class ArrayList&amp;lt;E&amp;gt; extends AbstractList&amp;lt;E&amp;gt;
        implements List&amp;lt;E&amp;gt;, RandomAccess, Cloneable, java.io.Serializable{}&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private static final int DEFAULT_CAPACITY = 10;
private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;构造方法&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public ArrayList(int initialCapacity) {}
public ArrayList() {}
public ArrayList(Collection&amp;lt;? extends E&amp;gt; c) {}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;扩容方法&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public void ensureCapacity(int minCapacity) {}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;2.2 Vector&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;特点与ArrayList相同， 不同的是Vector操作元素的方法是同步（对集合操作的方法都用synchronized关键字）的，同一时刻只能有一个线程访问，由于Vector是线程同步的，那么性能上要比ArrayList要低。Vector也是依赖数组实现的，在需要对Vector扩容时，自动增长为原来数组长度的一倍。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;public class Vector&amp;lt;E&amp;gt;
    extends AbstractList&amp;lt;E&amp;gt;
    implements List&amp;lt;E&amp;gt;, RandomAccess, Cloneable, java.io.Serializable{}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;**构造方法  **&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//默认初始容量为10
public Vector()  
//默认增量为0
public Vector(int initialCapacity)
public Vector(int initialCapacity,int capacityIncrement)  
        第一个参数是初始容量,第二个参数是当Vector满时的增量  
public Vector(Collection&amp;lt;? extends E&amp;gt; c) {}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;2.2.1 Stack&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Stack类继承了Vector，实现了一个后进先出的堆栈，Stack提供了5个额外的方法实现栈的操作。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;public
class Stack&amp;lt;E&amp;gt; extends Vector&amp;lt;E&amp;gt; {}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;构造方法&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public Stack() {}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;实现栈的方法&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public E push(E item) {}
//调用了peek操作，获取栈顶元素，并删除栈顶元素
public synchronized E pop() {}
//获取栈顶元素，不删除栈顶元素
public synchronized E peek() {}
public boolean empty() {}
public synchronized int search(Object o) {}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;2.3 LinkedList&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;LinkedList功能与ArrayList，Vector相同，但内部是依赖双向链表实现的，也就是说每个结点都存放着指向前驱结点和后驱结点的引用，因此有很好的插入和删除性能,但随机访问元素的性能很差。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;public class LinkedList&amp;lt;E&amp;gt;
    extends AbstractSequentialList&amp;lt;E&amp;gt;
    implements List&amp;lt;E&amp;gt;, Deque&amp;lt;E&amp;gt;, Cloneable, java.io.Serializable
{}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;构造方法&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public LinkedList() {}
public LinkedList(Collection&amp;lt;? extends E&amp;gt; c) {}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;LinkedList类的元素表示：Node内部类&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private static class Node&amp;lt;E&amp;gt; {
    E item;
    Node&amp;lt;E&amp;gt; next;
    Node&amp;lt;E&amp;gt; prev;

    Node(Node&amp;lt;E&amp;gt; prev, E element, Node&amp;lt;E&amp;gt; next) {
        this.item = element;
        this.next = next;
        this.prev = prev;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;正序遍历链表&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private static void printList(List link) {  
    // 得到链表的迭代器,位置指向链头  
    ListIterator li = link.listIterator();  
    // 判断迭代器中是否有下一个元素  
    while (li.hasNext()) {  
        // 返回下个元素  
        System.out.println(li.next() + &quot; &quot;);  
    }  
}  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;逆序遍历链表&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private static void printReversedList(List link) {  
    // 得到链表的迭代器,位置指向link.size()结尾  
    ListIterator li = link.listIterator(link.size());  
    // 判断迭代器中是否有前一个元素  
    while (li.hasPrevious()) {  
        // 返回前一个元素  
        System.out.println(li.previous() + &quot; &quot;);  
    }  
}  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;在链表中任意位置插入元素&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;链表是一个有序集合，调用LinkedList.add方法将对象插入到链表的尾部，如何添加元素到链表中的任意位置呢？这种操作可以交由迭代器负责。ListIterator的add即可实现。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public static void addElement(){
	List&amp;lt;String&amp;gt; list = new LinkedList&amp;lt;String&amp;gt;();
	list.add(&quot;aaa&quot;);
	list.add(&quot;bbb&quot;);
	list.add(&quot;ccc&quot;);
	System.out.println(list);//[aaa, bbb, ccc]
	ListIterator&amp;lt;String&amp;gt; iterator = list.listIterator();
	iterator.next();//跳过第一个元素
	iterator.add(&quot;111&quot;);//在第二个位置插入元素111
	System.out.println(list);//[aaa, 111, bbb, ccc]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;少用list.get(i)，用list.listIterator(i)代替&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;LinkedList提供了一个用来访问某个特定元素的get方法，但这种方式的效率是非常低的，在代码中应该尽量少用这种方式，因为链表中每次查找一个元素都要从链表的头部重新开始搜索，如果索引值i大于size()/2则从列表尾端开始搜索元素。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public E get(int index) {
    checkElementIndex(index);
    return node(index).item;
}

Node&amp;lt;E&amp;gt; node(int index) {
    // assert isElementIndex(index);

    if (index &amp;lt; (size &amp;gt;&amp;gt; 1)) {// &amp;gt;&amp;gt; 1 相当于除以2
        Node&amp;lt;E&amp;gt; x = first;
        for (int i = 0; i &amp;lt; index; i++)
            x = x.next;
        return x;
    } else {
        Node&amp;lt;E&amp;gt; x = last;
        for (int i = size - 1; i &amp;gt; index; i--)
            x = x.prev;
        return x;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;还是之前的例子&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;System.out.println(list.get(2));//bbb
ListIterator&amp;lt;String&amp;gt; iterator2 = list.listIterator(2);
System.out.println(iterator2.next());//bbb
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;三、Set&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;不包含重复元素，最多包含一个null，元素没有顺序。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;public interface Set&amp;lt;E&amp;gt; extends Collection&amp;lt;E&amp;gt; {}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.1 HashSet&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;实现了Set接口，底层用hashMap来实现，hashSet的大部分方法也都是调用hashMap来实现的。散列表是用链表数组来实现的，每个列表称之为桶，当桶被占满的时候，就会出现散列冲突。散列表是无序的(hashMap和hashSet都是)。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;public class HashSet&amp;lt;E&amp;gt;
    extends AbstractSet&amp;lt;E&amp;gt;
    implements Set&amp;lt;E&amp;gt;, Cloneable, java.io.Serializable{}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;构造方法&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public HashSet() {
    map = new HashMap&amp;lt;&amp;gt;();
}
public HashSet(Collection&amp;lt;? extends E&amp;gt; c) {
    map = new HashMap&amp;lt;&amp;gt;(Math.max((int) (c.size()/.75f) + 1, 16));
    addAll(c);
}
public HashSet(int initialCapacity, float loadFactor) {
    map = new HashMap&amp;lt;&amp;gt;(initialCapacity, loadFactor);
}
public HashSet(int initialCapacity) {
    map = new HashMap&amp;lt;&amp;gt;(initialCapacity);
}
HashSet(int initialCapacity, float loadFactor, boolean dummy) {
    map = new LinkedHashMap&amp;lt;&amp;gt;(initialCapacity, loadFactor);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;HashSet保证了当前集合对于某一元素的唯一存在性，集合中是否存在一个对象是通过equals()和hashCode()协同判断。&lt;/p&gt;

&lt;p&gt;HashSet的add()方法详解:&lt;/p&gt;

&lt;p&gt;判断已经存储在集合中的对象hashCode值是否与增加对象的hashCode值一致&lt;br /&gt;
如果不一致,直接加进去&lt;br /&gt;
如果一致,再进行equals()比较&lt;br /&gt;
    如果equals()返回true,对象已经存在不增加进去&lt;br /&gt;
    如果equals()返回false,把对象增加进去&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.2 TreeSet&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;树集合HashSet散列集很像，但树集是有序集合。在树集中可以任意插入元素到集合中，但对集合进行遍历的时候，每个值会自动地按照排序后的顺序呈现。底层实现是采用红黑树来存储元素。&lt;/p&gt;

&lt;p&gt;添加元素的效率：hashMap &amp;gt; treeSet &amp;gt; linkedList &amp;gt; arrayList&lt;/p&gt;

&lt;p&gt;treeSet中的元素如何排序的呢？&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;treeSet中的元素实现Comparable接口&lt;/li&gt;
  &lt;li&gt;将Comparator对象传递给TreeSet构造器实现集合中元素的排序&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;treeSet中的元素实现Comparable接口&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public interface Comparable&amp;lt;T&amp;gt; {
    public int compareTo(T o);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;比如简单的Integer&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public int compareTo(Integer anotherInteger) {
   return compare(this.value, anotherInteger.value);
}
public static int compare(int x, int y) {
   return (x &amp;lt; y) ? -1 : ((x == y) ? 0 : 1);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;如果集合中存放的是某些自定义的对象，那么需要让你实现Comparable接口，并重写compareTo方法。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;将Comparator对象传递给TreeSet构造器实现集合中元素的排序&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;使用Comparable接口定义排列排序有一定的局限性，如果需要对某一特定的类的不同属性进行排序，Comparable就不能很好的满足这一需求，这个时候我们可以通过将Comparator对象传递给TreeSet构造器实现集合中元素的排序。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public interface Comparator&amp;lt;T&amp;gt; {
	int compare(T o1, T o2);
}

SortedSet&amp;lt;Item&amp;gt; sortByDescription = new TreeSet&amp;lt;&amp;gt;(new Comparator&amp;lt;Item&amp;gt;(){
	public int compare(Item a, Item b){
		String descrA = a.getDescription;
		String descrB = b.getDescription;
		return descrA.compareTo(descrB);
	}
});
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;四、Queue&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Queue接口与List、Set同一级别，都是继承了Collection接口。Queue不允许包含NULL元素。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;public interface Queue&amp;lt;E&amp;gt; extends Collection&amp;lt;E&amp;gt; {}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;队列方法&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//增加一个元素，队列满则抛出IIIegaISlabEepeplian异常
boolean add(E e);
//添加一个元素，队列满则返回false
boolean offer(E e);
//移除并返回队列头部的元素，队列空则抛出一个NoSuchElementException异常
E remove();
//移除并返问队列头部的元素，队列空则返回null
E poll();
//返问但不移除队列头部的元素，队列空则抛出一个NoSuchElementException异常
E element();
//返问但不移除队列头部的元素，队列空则返回null
E peek();
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;4.1 BlockingQueue&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;用阻塞队列两个显著的好处就是：多线程操作共同的队列时不需要额外的同步，另外就是队列会自动平衡负载，即那边（生产与消费两边）处理快了就会被阻塞掉，从而减少两边的处理速度差距。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;public interface BlockingQueue&amp;lt;E&amp;gt; extends Queue&amp;lt;E&amp;gt; {}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;阻塞队列的方法&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//增加一个元素，队列满则阻塞当前线程
void put(E e) throws InterruptedException;
//移除并返问队列头部的元素，队列空则阻塞当前线程
E take() throws InterruptedException;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;4.2 ArrayDeque&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Java SE6中引入了Deque接口，提供了双端队列一系列实现。ArrayDeque中用初始容量16的数组或给定初始容量来构造一个无限双端队列。值得注意的是LinkedList也是Deque的一个实现类，也可以用来构造双端队列。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;public class ArrayDeque&amp;lt;E&amp;gt; extends AbstractCollection&amp;lt;E&amp;gt;
                           implements Deque&amp;lt;E&amp;gt;, Cloneable, Serializable
{}&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public ArrayDeque() {
    elements = new Object[16];
}
public ArrayDeque(int numElements) {
    allocateElements(numElements);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;4.3 PriorityQueue&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;优先队列，队列中的元素可以按照任意的顺序输入，但却可以按照指定的顺序进行检索（TreeSet），优先队列使用了堆数据结构，堆是自我调整的二叉树，对树进行一系列的添加删除等操作，让最小（大）的元素移动到根，而不必浪费时间对元素进行排序。&lt;/p&gt;

&lt;p&gt;和TreeSet一样，优先队列可以保存实现了Comparable接口的类对象，也可以保存在构造器中提供比较器（Comparator）的对象。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;public class PriorityQueue&amp;lt;E&amp;gt; extends AbstractQueue&amp;lt;E&amp;gt;
    implements java.io.Serializable {}&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//优先队列默认初始值大小为11
private static final int DEFAULT_INITIAL_CAPACITY = 11;

public PriorityQueue() {
    this(DEFAULT_INITIAL_CAPACITY, null);
}
public PriorityQueue(int initialCapacity) {
    this(initialCapacity, null);
}
public PriorityQueue(Comparator&amp;lt;? super E&amp;gt; comparator) {
    this(DEFAULT_INITIAL_CAPACITY, comparator);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;五、Collection与Collections的区别&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;java.util.Collection 是一个集合接口。它提供了对集合对象进行基本操作的通用接口方法。Collection接口在Java 类库中有很多具体的实现。Collection接口的意义是为各种具体的集合提供了最大化的统一操作方式。&lt;/p&gt;

&lt;p&gt;java.util.Collections 是一个包装类。它包含有各种有关集合操作的静态多态方法。此类不能实例化，因为内部的构造函数被私有化了就像一个工具类，服务于Java的Collection框架。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;private Collections() {}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Java - Collection：http://blog.csdn.net/itlwc/article/details/10148321&lt;/p&gt;

&lt;p&gt;java中queue的使用：http://www.cnblogs.com/end/archive/2012/10/25/2738493.html&lt;/p&gt;
</description>
        <pubDate>Sat, 13 May 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/java/2017/05/13/%E6%B5%85%E8%B0%88Java%E9%9B%86%E5%90%88Collection.html</link>
        <guid isPermaLink="true">http://localhost:4000/java/2017/05/13/%E6%B5%85%E8%B0%88Java%E9%9B%86%E5%90%88Collection.html</guid>
        
        <category>Collection</category>
        
        
        <category>Java</category>
        
      </item>
    
      <item>
        <title>死磕JavaScript-松散类型、js变量存储模型、变量提升</title>
        <description>&lt;p&gt;好久没来慕课网学习了，上研究生之后，发现突然又变回学生后对自己的要求也松很多，开始到处旅游，做些没计划的事情，也很少写技术博客了，最近静下心来开始研究底层的东西，以后就在这写了，希望能死磕自己，坚持下去。好了，干货走起……&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;什么是松散类型&lt;/li&gt;
  &lt;li&gt;JavaScript两种变量类型的内存模型&lt;/li&gt;
  &lt;li&gt;预加载&lt;/li&gt;
  &lt;li&gt;变量提升&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;javascript里的变量和其他语言有很大的不同，javascript的变量是一个松散的类型，松散类型变量的特点是变量定义时候不需要指定变量的类型，变量在运行时候可以随便改变数据的类型，但是这种特性并不代表javascript变量没有类型，当变量类型被确定后javascript的变量也是有类型的。&lt;/p&gt;

&lt;p&gt;但是在现实中，很多程序员把javascript松散类型理解为了javascript变量是可以随意定义即你可以不用var定义，也可以使用var定义，其实在javascript语言里变量定义没有使用var，变量必须有赋值操作，只有赋值操作的变量是赋予给window，这其实是javascript语言设计者提升javascript安全性的一个做法。&lt;/p&gt;

&lt;p&gt;此外javascript语言的松散类型的特点以及运行时候随时更改变量类型的特点，很多程序员会认为javascript变量的定义是在运行期进行的，更有甚者有些人认为javascript代码只有运行期，其实这种理解是错误的，javascript代码在运行前还有一个过程就是：预加载，预加载的目的是要事先构造运行环境例如全局环境，函数运行环境，还要构造作用域链，而环境和作用域的构造的核心内容就是指定好变量属于哪个范畴，因此在javascript语言里变量的定义是在预加载完成而非在运行时期。&lt;/p&gt;

&lt;p&gt;讲一个例子来讲解：&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;&lt;code&gt;&lt;span class=&quot;kwd&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; a &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;lit&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; test&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(){&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
    console&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;com&quot;&gt;//undefined&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; a &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;lit&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
    console&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;com&quot;&gt;//2&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
test&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;();&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是一个令人诧异的结果，为什么第一个弹出框显示的是undefined，而不是1呢？这种疑惑的原理我描述如下：&lt;/p&gt;

&lt;p&gt;一个页面里直接定义在script标签下的变量是全局变量即属于window对象的变量，按照javascript作用域链的原理，当一个变量在当前作用域下找不到该变量的定义，那么javascript引擎就会沿着作用域链往上找直到在全局作用域里查找，按上面的代码所示，虽然函数内部重新定义了变量的值，但是内部定义之前函数使用了该变量，那么按照作用域链的原理在函数内部变量定义之前使用该变量，javascript引擎应该会在全局作用域里找到变量定义，而实际情况却是变量未定义，这到底是怎么回事呢？&lt;/p&gt;

&lt;p&gt;这里我要先讲一个知识点，就是&lt;strong&gt;JavaScript的变量存储模型&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;javascript语言和java语言一样变量是分为两种类型：基本数据类型和引用类型。基本类型是指：Undefined、Null、Boolean、Number和String；而引用类型是指对象，所以javascript的对象指的是引用类型。但是实际开发里如果我们对基本类型和引用类型的区别不是很清晰，就会碰到我们很多不能理解的问题，下面我们来看看下面的代码：&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;&lt;code&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; str &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;“&lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;Sharpxiajun&lt;/span&gt;&lt;span class=&quot;str&quot;&gt;&quot;;
 var num = 1;
 var xxx;
 console.log(str);//运行结果：sharpxiajun
 console.log(num);//运行结果：1
 console.log(xxx);//运行结果：undefined&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当我们使用引用类型时候，结果就和上面完全不同了，大家请看下面的代码：&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;&lt;code&gt;&lt;span class=&quot;kwd&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; obj1 &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kwd&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;typ&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;();&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;
obj1&lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;name &lt;/span&gt;&lt;span class=&quot;pun&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt; &lt;/span&gt;&lt;span class=&quot;str&quot;&gt;&quot;obj1 name”;
console.log(obj1.name);// 运行结果：obj1 name&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Javascript里的基本变量是存放在栈区的（栈区指内存里的栈内存），它的存储结构如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://img.mukewang.com/591552cf0001746703950149.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;javascript里引用变量的存储就比基本类型存储要复杂多，引用类型的存储需要内存的栈区和堆区（堆区是指内存里的堆内存）共同完成，如下图所示：
&lt;img src=&quot;http://img.mukewang.com/591552f20001700e05650292.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;理解基本类型变量和引用类型变量的存储结构后，结合上面开始讲的预加载的知识点，我们就能分析出开始那个例子的深层原因了。&lt;/p&gt;

&lt;p&gt;引子里的代码在函数的局部作用域下变量a被重新定义了，在预加载时候a的作用域范围也就被框定了，a变量不再属于全局变量，而是属于函数作用域，只不过赋值操作是在运行期执行（这就是为什么javascript语言在运行时候会改变变量的类型，因为赋值操作是在运行期进行的），所以第一次使用a变量时候，a变量在局部作用域里没有被赋值，只有栈区的标示名称，因此结果就是undefined了。（这也就是js里的变量提升的原理）&lt;/p&gt;

&lt;p&gt;不过赋值操作也不是完全不对预加载产生影响，预加载时候javascript引擎会扫描所有代码，但不会运行它，当预加载扫描到了赋值操作，但是赋值操作的变量有没有被var定义，那么该变量就会被赋予全局变量即window对象。&lt;/p&gt;
</description>
        <pubDate>Fri, 12 May 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/javascript/2017/05/12/%E6%9D%BE%E6%95%A3%E7%B1%BB%E5%9E%8B-js%E5%8F%98%E9%87%8F%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9E%8B-%E5%8F%98%E9%87%8F%E6%8F%90%E5%8D%87.html</link>
        <guid isPermaLink="true">http://localhost:4000/javascript/2017/05/12/%E6%9D%BE%E6%95%A3%E7%B1%BB%E5%9E%8B-js%E5%8F%98%E9%87%8F%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9E%8B-%E5%8F%98%E9%87%8F%E6%8F%90%E5%8D%87.html</guid>
        
        <category>JavaScript</category>
        
        <category>松散类型</category>
        
        <category>变量存储模型</category>
        
        <category>变量提升</category>
        
        
        <category>Javascript</category>
        
      </item>
    
      <item>
        <title>Java知识点大扫盲</title>
        <description>&lt;p&gt;在Java的学习过程中，多多少少会遗漏掉一些基本的知识点，而这些基本的知识点往往是奠定Java基础很重要的部分，里面的很多知识点我们编程中往往用不到，但理解它们能帮助我们更好地掌握Java，本文是一个长期贴，会不定时更新。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1、函数的形参到底获取的是实参的值还是实参的引用地址？&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class Main17{     
     String str = &quot;start&quot;;
     char ch[] = {'a','b','c'};
     Integer a = 1;
     float f = 1.0f;
     double d = 1.0;     
     public void change(String str,char[] ch){
          str = &quot;end&quot;;
          ch[0] = 'e';
     }     
     public void change(Integer a){
          a = 2;
     }     
     public void change(float f){
          f = 2.0f;
     }
     public void change(double d){
          d = 2.0;
     }     
     public static void main(String[] args) {
          Main17 m17 = new Main17();
          m17.change(m17.str, m17.ch);
          System.out.print(m17.str + &quot; and &quot;);
          System.out.println(m17.ch);
          m17.change(m17.a);
          System.out.println(m17.a);
          m17.change(m17.f);
          System.out.println(m17.f);
          m17.change(m17.d);
          System.out.println(m17.d);
     }
}
result：
start and ebc
1
1.0
1.0
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;我们可以发现String，float，double，这些值changea后都没变，但是char的值改变了，也就是说String，float，double给形参传入的是实参的值，因为这些类都是final类（还有：Integer，Long，Short）；而char给形参传入的是实参的引用地址，所以change中改变了char的值会反映到类的全局变量。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2、Java中&amp;amp;&amp;amp;和&amp;amp;以及||和|的区别&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&amp;amp;&amp;amp;和&amp;amp;都是表示与，区别是&amp;amp;&amp;amp;只要第一个条件为false，后面条件就不再判断。而&amp;amp;要对所有的条件都进行判断。&lt;/p&gt;

&lt;p&gt;但是||和|都是表示“或”，区别是||只要第一个条件为true，后面的条件就不再判断，而|要对所有的条件进行判断。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3、==与equals&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;String s = &quot;hello&quot;；
String t = “hello”；
char c [] = {'h','e','l','l','o'}；

s == t //true
s.equals(c)//false
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;首先==与equals是有明显区别的。&lt;/p&gt;

&lt;p&gt;==强调栈中的比较，可以理解为地址比较&lt;/p&gt;

&lt;p&gt;equals强调对象的内容比较&lt;/p&gt;

&lt;p&gt;String s=“hello”；会在栈中生成hello字符串，并存入字符串常量池中。&lt;/p&gt;

&lt;p&gt;String t=“hello” ；创建时，会在字符串常量池中寻找，当找到需要的hello时，不进行字符串的创建，引用已有的。 所以，s==t返回true，s.equals(t)也是true。&lt;/p&gt;

&lt;p&gt;char c[]={‘h’,’e’,’l’,’l’,’o’}; c==s这个是不存在的，==两边类型不同，t.equals(c)这个语句在anObject instanceof String这步判断不会通过，也就是cha[] 压根不能与String相比较，类型不是相同的。返回false。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4、静态成员变量或静态代码块&amp;gt;mian方法&amp;gt;非静态成员变量或非静态代码块&amp;gt;构造方法&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;静态方法或静态块会比构造方法（包括父类的构造函数）先加载，且只加载一次。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class Test{
     public Test(){
          System.out.println(&quot;I'm 构造器&quot;);
     }
     static{
          System.out.println(&quot;I'm static&quot;);
     }
}
result：
I'm static
I'm 构造器
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;5、String的replaceAll方法&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;String classFile = &quot;com.jd.&quot;. replaceAll(&quot;.&quot;, &quot;/&quot;) 
	+ &quot;MyClass.class&quot;;
System.out.println(classFile);
result：
/////////MyClass.class
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;由于replaceAll方法的第一个参数是一个正则表达式，而”.”在正则表达式中表示任何字符，所以会把前面字符串的所有字符都替换成”/”。如果想替换的只是”.”，那么要写成”\.”。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;6、try-catch-finally&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public static int func (){
    try{
        return 1;
    }catch (Exception e){
        return 2;
    }finally{
        return 3;
    }
}
result：
3
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Try catch finally获取异常错误的结构，try中没有异常时，但是有return等跳转语句，这样会引发程序控制流离开当前的try，即在return语句执行之后返回之前去完成finally中资源的释放。 由于代码中的finally中有return语句，将try中的return语句覆盖，程序直接跳出。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;7、匿名内部类&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;匿名内部类也就是没有名字的内部类。&lt;/p&gt;

&lt;p&gt;正因为没有名字，所以匿名内部类只能使用一次，它通常用来简化代码编写
但使用匿名内部类还有个前提条件：必须继承一个父类或实现一个接口。&lt;/p&gt;

&lt;p&gt;实例1:不使用匿名内部类来实现抽象方法&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;abstract class Person {
    public abstract void eat();
}
class Child extends Person {
    public void eat() {
        System.out.println(&quot;eat something&quot;);
    }
}
public class Demo {
    public static void main(String[] args) {
        Person p = new Child();
        p.eat();
    }
}
运行结果：eat something
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;可以看到，我们用Child继承了Person类，然后实现了Child的一个实例，将其向上转型为Person类的引用。&lt;/p&gt;

&lt;p&gt;但是，如果此处的Child类只使用一次，那么将其编写为独立的一个类岂不是很麻烦？&lt;/p&gt;

&lt;p&gt;这个时候就引入了匿名内部类。&lt;/p&gt;

&lt;p&gt;实例2：匿名内部类的基本实现&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;abstract class Person {
    public abstract void eat();
}
public class Demo {
    public static void main(String[] args) {
        Person p = new Person() {
            public void eat() {
                System.out.println(&quot;eat something&quot;);
            }
        };
        p.eat();
    }
}
运行结果：eat something
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;可以看到，我们直接将抽象类Person中的方法在大括号中实现了。&lt;/p&gt;

&lt;p&gt;这样便可以省略一个类的书写。&lt;/p&gt;

&lt;p&gt;并且，匿名内部类还能用于接口上。&lt;/p&gt;

&lt;p&gt;实例3：在接口上使用匿名内部类&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;interface Person {
    public void eat();
}
public class Demo {
    public static void main(String[] args) {
        Person p = new Person() {
            public void eat() {
                System.out.println(&quot;eat something&quot;);
            }
        };
        p.eat();
    }
}
运行结果：eat something
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;由上面的例子可以看出，只要一个类是抽象的或是一个接口，那么其子类中的方法都可以使用匿名内部类来实现。&lt;/p&gt;

&lt;p&gt;最常用的情况就是在多线程的实现上，因为要实现多线程必须继承Thread类或是继承Runnable接口。&lt;/p&gt;

&lt;p&gt;实例4：Thread类的匿名内部类实现&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class Demo {
    public static void main(String[] args) {
        Thread t = new Thread() {
            public void run() {
                for (int i = 1; i &amp;lt;= 5; i++) {
                    System.out.print(i + &quot; &quot;);
                }
            }
        };
        t.start();
    }
}
运行结果：1 2 3 4 5
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;实例5：Runnable接口的匿名内部类实现&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class Demo {
    public static void main(String[] args) {
        Runnable r = new Runnable() {
            public void run() {
                for (int i = 1; i &amp;lt;= 5; i++) {
                    System.out.print(i + &quot; &quot;);
                }
            }
        };
        Thread t = new Thread(r);
        t.start();
    }
}
运行结果：1 2 3 4 5
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;8、Integer等的比较&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Integer i01 = 59;
int i02 = 59;
Integer i03 = Integer.valueOf(59);
Integer i04 = new Integer(59);

i01 == i02//true
i01 == i03//true
i02 == i03//true
i01 == i04//false
i02 == i04//true
i03 == i04//false
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Integer.valueOf(59)&lt;/code&gt;会从Integer中的私有静态类IntegerCache中获取Integer对象，所以与i01和i02对比都为&lt;code class=&quot;highlighter-rouge&quot;&gt;true&lt;/code&gt;，而&lt;code class=&quot;highlighter-rouge&quot;&gt;new Integer(59)&lt;/code&gt;是新创建Integer对象，新分配了内存，所以与i01和i03对比都为&lt;code class=&quot;highlighter-rouge&quot;&gt;false&lt;/code&gt;。int和Integer(只要值相等，无论new否)比，都为true，因为会把Integer自动拆箱为int再去比，所以i02与i04对比为&lt;code class=&quot;highlighter-rouge&quot;&gt;true&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;Byte,Short,Integer,Long,Character这5种整型的包装类在对应值小于等于127并且大于等于-128时会使用常量池，因为他们至占用一个字节(-128~127);超出这个范围将会返回一个新的包装类对象。&lt;/p&gt;

&lt;p&gt;比如&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public static Integer valueOf(int i) {
    if (i &amp;gt;= IntegerCache.low &amp;amp;&amp;amp; i &amp;lt;= IntegerCache.high)
        return IntegerCache.cache[i + (-IntegerCache.low)];
    return new Integer(i);
}
private static class IntegerCache {
    static final int low = -128;
    static final int high;
    static final Integer cache[];
}

public static Long valueOf(long l) {
    final int offset = 128;
    if (l &amp;gt;= -128 &amp;amp;&amp;amp; l &amp;lt;= 127) { // will cache
        return LongCache.cache[(int)l + offset];
    }
    return new Long(l);
}

public static Short valueOf(short s) {
    final int offset = 128;
    int sAsInt = s;
    if (sAsInt &amp;gt;= -128 &amp;amp;&amp;amp; sAsInt &amp;lt;= 127) { // must cache
        return ShortCache.cache[sAsInt + offset];
    }
    return new Short(s);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;所以&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public static void main(String[] args) {

    Integer a = 127;
    Integer b = 127;

    Integer c = 128;
    Integer d = 128;

    System.out.println(a == b);//true
    System.out.println(c == d);//false
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;9、Spring的事务传播特性&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;PROPAGATION_required–支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。&lt;/p&gt;

&lt;p&gt;PROPAGATION_supports–支持当前事务，如果当前没有事务，就以非事务方式执行。&lt;/p&gt;

&lt;p&gt;PROPAGATION_mandatory–支持当前事务，如果当前没有事务，就抛出异常。&lt;/p&gt;

&lt;p&gt;PROPAGATION_requires _new–新建事务，如果当前存在事务，把当前事务挂起。&lt;/p&gt;

&lt;p&gt;PROPAGATION_not _supported–以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。&lt;/p&gt;

&lt;p&gt;PROPAGATION_never–以非事务方式执行，如果当前存在事务，则抛出异常。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;10、i++与++i&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class Inc {
    public static void main(String[] args) {
       Inc inc = new Inc();
       int i = 0;
       inc.fermin(i); //查看知识点1
       i= i ++;
       System.out.println(i);  //0，这个结果是不是很意外
    }
    void fermin(int i){
       i++;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Java使用了中间缓存变量机制：&lt;/p&gt;

&lt;p&gt;i=i++;等同于：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;temp=i； (等号右边的i)
i=i+1;      (等号右边的i)
i=temp;   (等号左边的i)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;而i=++i;则等同于：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;i=i+1;
temp=i;
i=temp;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;但如果把“i= i ++; ”改为“i++”，结果会是1。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class Spike
{
    public static void main(String[] args)
    {
        Counter a = new Counter();
        System.out.println(a.increment());
        System.out.println(a.anotherIncrement());
        Counter b = new Counter();
        System.out.println(b.increment());
    }
}
class Counter
{
    private static int count = 0;
    public int increment()
    {
        return count++;
    }
    public int anotherIncrement()
    {
        return ++count;
    }
}
result：
0 2 2
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;increment()方法返回当前count值，然后count增加1&lt;/p&gt;

&lt;p&gt;antoherIncrement()方法让count增加1，然后返回count值&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;11、null&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class Main17{
  private static void testMethod(){
        System.out.println(&quot;testMethod&quot;);
   }
    public static void main(String args[]) {
      ((Main17)null).testMethod();
    }
}
result：
testMethod
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Java中，null是一个关键字，不是对象，也不是Objcet的实例，它用来标识一个不确定的对象。因此可以将null赋给引用类型变量，但不可以将null赋给基本类型变量。&lt;/p&gt;

&lt;p&gt;比如：int a = null;是错误的。Ojbect o = null是正确的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;12、类方法、类变量和实例方法、实例变量&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;用static修饰的方法和变量是类方法、类变量，可以直接用类名.的方法来调用；&lt;/p&gt;

&lt;p&gt;没有用static修饰的方法和变量就属于实例方法、实例变量，必须实例化类之后用实例化对象才能调用。在类方法中调用实例变量会报错，在实例方法中调用实例变量则没有问题。&lt;/p&gt;

&lt;p&gt;由于类方法是属于整个类的，并不属于类的哪个对象，所以类方法的方法体中不能有与类的对象有关的内容。即类方法体有如下限制：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;类方法中不能引用对象变量；&lt;/li&gt;
  &lt;li&gt;类方法中不能调用类的对象方法；&lt;/li&gt;
  &lt;li&gt;在类方法中不能使用super、this关键字。&lt;/li&gt;
  &lt;li&gt;类方法不能被覆盖。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;如果违反这些限制，就会导致程序编译错误。&lt;/p&gt;

&lt;p&gt;与类方法相比，对象方法几乎没有什么限制：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;对象方法中可以引用对象变量，也可以引用类变量；&lt;/li&gt;
  &lt;li&gt;对象方法中可以调用类方法；&lt;/li&gt;
  &lt;li&gt;对象方法中可以使用super、this关键字。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;13、Collection与Collections的区别&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;java.util.Collection 是一个集合接口。它提供了对集合对象进行基本操作的通用接口方法。Collection接口在Java 类库中有很多具体的实现。Collection接口的意义是为各种具体的集合提供了最大化的统一操作方式。&lt;/p&gt;

&lt;p&gt;Collection &lt;br /&gt;
├List &lt;br /&gt;
│├LinkedList &lt;br /&gt;
│├ArrayList &lt;br /&gt;
│└Vector &lt;br /&gt;
│　└Stack &lt;br /&gt;
└Set&lt;br /&gt;
│　└HashSet&lt;/p&gt;

&lt;p&gt;└Queue&lt;/p&gt;

&lt;p&gt;java.util.Collections 是一个包装类。它包含有各种有关集合操作的静态多态方法。此类不能实例化，因为内部的构造函数被私有化了就像一个工具类，服务于Java的Collection框架。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;14、super()与this()&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;1）调用super()必须写在子类构造方法的第一行，否则编译不通过。每个子类构造方法的第一条语句，都是隐含地调用super()，如果父类没有这种形式的构造函数，那么在编译的时候就会报错。&lt;/p&gt;

&lt;p&gt;2）super()和this()类似,区别是，super从子类中调用父类的构造方法，this()在同一类内调用其它方法。&lt;/p&gt;

&lt;p&gt;3）super()和this()均需放在构造方法内第一行，既然两个都要放在第一行，那么两个就不可能同时存在一个构造函数里。&lt;/p&gt;

&lt;p&gt;4）尽管可以用this调用一个构造器，但却不能调用两个。&lt;/p&gt;

&lt;p&gt;5）this()和super()都指的是对象，所以，均不可以在static环境中使用。包括：static变量,static方法，static语句块。&lt;/p&gt;

&lt;p&gt;6）从本质上讲，this是一个指向本对象的指针, 然而super是一个Java关键字。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class Main17{
    public Main17(){
        super();
        System.out.println(&quot;1&quot;);
    }
    public Main17(int a){
        this();
        System.out.println(a);
    }
    public Main17(int a, String s){
        this(a);
        System.out.println(s+a);
    }
    public static void main(String[] args) {
        Main17 main17 = new Main17(2,&quot;end:&quot;);
    }
}
result：
1
2
end:2
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;15、Java中的float与double精度&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;float的精度最多8位，double的精度最多17位。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public static void main(String[] args) {
		
		double a = 1.0;
		double b = 1.0;
		System.out.println(a == b);//这样的代码是拿不到offer的
		double t = 30.000000000000000;
		double c = 30.000000000000003;//double最多17位
		double d = 30.0000000000000003;
		System.out.println(t == c);//false
		System.out.println(t == d);//true
		System.out.println(Double.compare(t, d));//0 数学上相等
		System.out.println(c &amp;lt;= 30);//false
		System.out.println(d &amp;lt;= 30);//true  d总位数超过了17，则会将小数点多余的3去掉即等于30.000000000000000
		
		float e = 4.0000003f;//float最多8位
		float f = 4.00000003f;
		System.out.println(e &amp;lt;= 4);//false
		System.out.println(f &amp;lt;= 4);//true f总位数超过了8，则会将小数点多余的3去掉即等于4.0000000
	}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Thu, 11 May 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/java/2017/05/11/Java%E7%9F%A5%E8%AF%86%E7%82%B9%E5%A4%A7%E6%89%AB%E7%9B%B2.html</link>
        <guid isPermaLink="true">http://localhost:4000/java/2017/05/11/Java%E7%9F%A5%E8%AF%86%E7%82%B9%E5%A4%A7%E6%89%AB%E7%9B%B2.html</guid>
        
        <category>java</category>
        
        <category>知识点</category>
        
        
        <category>Java</category>
        
      </item>
    
      <item>
        <title>HDFS与MapReduce</title>
        <description>&lt;h1 id=&quot;hdfs-hadoop-distributed-file-system&quot;&gt;&lt;strong&gt;HDFS (Hadoop Distributed File System)&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;数据块&quot;&gt;&lt;strong&gt;数据块&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;HDFS将文件分成一个个块，除了最后一个块的大小不一样，其余所有的块的大小都是一样的（128MB）。&lt;/p&gt;

&lt;h2 id=&quot;数据复制&quot;&gt;&lt;strong&gt;数据复制&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Q：“一次写入，多次读取”，数据写入后，是否在所有结点中的dataNode中复制了一遍？&lt;/p&gt;

&lt;p&gt;A：对的，这个是可配置的，可复制一遍或多遍。&lt;/p&gt;

&lt;h2 id=&quot;数据副本的存放策略&quot;&gt;&lt;strong&gt;数据副本的存放策略&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;既然数据块在HDFS中有多个副本备份，那么数据副本应该在HDFS中怎么存放呢？&lt;/p&gt;

&lt;p&gt;数据副本的存放需要考虑到数据的可靠性、可用性和网络带宽的利用率。&lt;/p&gt;

&lt;p&gt;一个简单且没有有优化的策略是，将数据副本块放在不同的机架（一个机架上有很多不同的节点即DataNode）上，数据副本均匀放在集群中，有助于负载均衡，但需要将一个数据副本看写入到不同的机架上就务必会增加写的代价。&lt;/p&gt;

&lt;p&gt;HDFS默认的副本系数为3，Hadoop的3个数据副本的存放策略：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第一块：&lt;/strong&gt;在本机器下的HDFS目录下存储一个数据块；&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第二块：&lt;/strong&gt;不同的机架上的某个DataNode上存储一个数据块；&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第三块：&lt;/strong&gt;在该机器的同一个机架下的某台机器（也就是节点DataNode）上存储最后一个数据块。&lt;/p&gt;

&lt;h2 id=&quot;负载均衡-balancer&quot;&gt;&lt;strong&gt;负载均衡 Balancer&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;需要考虑到网络带宽使用率，机器磁盘利用率等。&lt;/p&gt;

&lt;p&gt;负载均衡程序balancer作为一个独立的进程与NameNode进程分开执行&lt;/p&gt;

&lt;p&gt;具体过程：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;负载均衡服务Rebalancing Server从NameNode中获取所有的DataNode情况（包括DataNode的磁盘使用情况等）&lt;/li&gt;
  &lt;li&gt;Rebalancing Server计算哪些机器需要将数据移动，哪些机器可以接收移动的数据，哪一台机器的数据块可以移动到另一台机器中去&lt;/li&gt;
  &lt;li&gt;Rebalancing Server执行移动数据块操作，移动成功后删除原来的数据块&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;hdfs的masterslave主从架构&quot;&gt;&lt;strong&gt;HDFS的Master/Slave主从架构&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;NameNode—Master：&lt;/strong&gt;管理HDFS的命名空间和和文件数据块&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;DataNode—Slave：&lt;/strong&gt;数据存储节点&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SecondaryNameNode—辅助的NameNode：&lt;/strong&gt;为了降低单个的NameNode的宕机对系统造成影响，SecondaryNameNode会备份NameNode的相关数据&lt;/p&gt;

&lt;h1 id=&quot;mapreducemap映射reduce化简&quot;&gt;&lt;strong&gt;MapReduce（Map映射+Reduce化简）&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;mapreduce过程&quot;&gt;&lt;strong&gt;MapReduce过程&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;map()负责将任务分散成多个子任务（按照键值对的形式，比如讲一篇文章分成多个map，每个map的key是字符串的偏移量，value是文件中一句字符串），将这些键值对作为输入，通过map()函数的处理（将每个map的value中的字符串分割为一个个单词），产生一个个中间map结果（将一个个单词作为map的key，value初始化为1），并将这些键值对结果写入本地磁盘。&lt;/p&gt;

&lt;p&gt;MapReduce框架会自动将这些中间数据按照key值进行聚集，将key值相同的数据统一交给一个reduce()函数处理。&lt;/p&gt;

&lt;p&gt;reduce()函数负责将分解后的多个任务的处理中间结果进行汇总（把key值相同的value值相加，得到一篇文章中不同单词出现的次数），产生最终结果的键值对（key为单词，value为单词出现的总次数）写入HDFS中。&lt;/p&gt;

&lt;h2 id=&quot;mapreduce的masterslave主从架构&quot;&gt;&lt;strong&gt;MapReduce的Master/Slave主从架构&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;ResourcesManager—Master：&lt;/strong&gt;控制整个集群的计算资源分配&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NodeManager—Slave：&lt;/strong&gt;实际的计算节点&lt;/p&gt;
</description>
        <pubDate>Wed, 21 Dec 2016 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/datamining/2016/12/21/HDFS%E4%B8%8EMapReduce.html</link>
        <guid isPermaLink="true">http://localhost:4000/datamining/2016/12/21/HDFS%E4%B8%8EMapReduce.html</guid>
        
        <category>HDFS</category>
        
        <category>MapReduce</category>
        
        
        <category>Datamining</category>
        
      </item>
    
      <item>
        <title>《清醒思考的艺术：你最好让别人去犯的52种思维错误》读书笔记</title>
        <description>&lt;p&gt;这段时间在看产品的书，有PM大牛推荐了这本书《清醒思考的艺术：你最好让别人去犯的52种思维错误》，在做产品的时候如果能避免这些思维错误，在生活中刻意的去训练这些思维艺术，我想那么看待问题可能会多一些视角，解决问题也就多了一种方式。下面是我认为比较常见的思维错误，记录下来以便以后多看看，同时也分享给大家。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1、幸存偏误&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;由于生活中我们更容易看到媒体上的成功案例，而看不到背后千千万万的失败，你会系统性的高估成功的希望。我们应该多看看曾经大有希望如今却葬身商场的项目，虽然会有点打击，却对你有好处。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2、是原因还是结果&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;女模特为化妆品做广告，不是你买了这款化妆品就能变得向女模特一样漂亮（结果），而是之所以选这个女模特来做广告是因为她天生丽质才被选出来拍化妆品广告（原因）；游泳健身教练身材健硕，并不是你去游泳健身就能练就同样的身材（结果），而是那些教练本身身材就健硕所以才来做游泳健身教练（原因）。&lt;/p&gt;

&lt;p&gt;在现实生活中，我们往往把一件事的结果当做这件事发生的原因，这样的思维误差对洞悉产品是不是好产品来说是致命的。&lt;/p&gt;

&lt;p&gt;当别人说这样做能把产品做好，请你认真思考，这样做的举措是产品好的原因还是结果。如果是原因，那么你应该毫不犹豫的采纳，但如果是结果，请洞悉其原因。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3、过度自信效应&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;每个人对自己的预估都会比实际偏高，连悲观的人也是。而且男人一般比女人要更高估自己。
所以，对所有的预测都持怀疑态度，尤其是当这些预测是由那些所谓的专家作出的。在筹划一件事情的时候从悲观的角度出发，作最坏的打算。这样才能更现实的判断当前的形势。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4、从众心理&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这是人类进化过程中的一个性格弱点，我们会自然地觉得大家都选择的就不会太差。但在做决定的时候请记住英国作家毛姆的话：就算有5000万个人声称某件蠢事是对的，这件蠢事也不对因此成为明智之举。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5、沉没成本&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们对一件事情付出的越多就越难放弃。就人性来说，沉没成本越大，继续做某事的理由就越多。做某件事情往往有很多好的、合理的理由支持你继续走下去，但如果只是因为舍不得已经付出的沉没成本就不是好理由了。理性的决定意味着忽视沉没成本。你已经投资了什么不重要，重要的是现在的形势以及你对未来的评估。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;6、互惠偏误&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;互惠这一理念在人类脑海里已经存活了一亿多年了。如果一个人对我好，那我会在另一个方面也对他好，不然心有愧欠。上世纪克里希那教徒在火车站免费给行人送鲜花，当行人在下一个路口扔进垃圾桶里的时候克里希那教徒再上前请求募捐，这样行人往往出于愧欠而募捐。所以下次在遇到免费的好事，那么最好是拒绝，别让自己陷互惠偏误的魔咒之中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;7、确认偏误&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;人们更容易相信自己愿意相信的东西，而自动忽略那些对自身信念进行攻击的事情，比如听一个人讲话，看一本书，你往往会更愿意相信或更容易接受那些你早就认可的东西，而自动排斥那些你不认可的东西，所以以后接触别人的时候要尽可能去聆听所有，思考所有，别错过那些会让你变得更美好的东西。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;8、权威偏误&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;人们面对问题时会倾向于臣服权威（这个其实看那个一听领导人讲话就哭的某国就很形象了，哈哈）。面对权威人们会将独立思考调低一级，非理性地对待问题。
所以面对权威请尝试挑战，辩证地看待权威，这样会更加自由。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;9、对比效应&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;你可能会愿意多走10分钟的路去买便宜10块钱的水果，但你却不愿意多走10分钟的路去买原价989现价979的西服。一种从100块钱降价到70块钱的产品会显得比一直卖70块钱的产品更便宜。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;10、现成偏误&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们会依据现成的例子来想象世界，这是思维错误的常见之一，外界现实中的某种东西不会因为我们容易想到而出现得更频繁。&lt;/p&gt;

&lt;p&gt;所以，在产品定位和市场分析的时候，产品经理不应该只参考某一类人的反馈，而应该多与跟自己想法不同的人交流，打破固有思维。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;11、确认偏误的变体－“在好转前会先恶化”&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如果有人告诉你某件事“在好转前会先恶化”，那你会发现接下来无论发生的事你都会感谢这个人：如果事情却是继续恶化，就证明他的预测是正确的；如果事情变化，那你也会把好转归功于这个人。所以当有人告诉你事情“在好转前会先恶化”，那么你应该小心。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;12、故事偏误&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;有两则故事：一、国王死了，然后王后也死了。二、国王死了，随后王后伤心死去。毋庸置疑，这第两则故事会让听者印象更加深刻。&lt;/p&gt;

&lt;p&gt;所以做一个有故事的产品比一个没有故事的产品要更容易成功。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;13、事后诸葛亮偏误&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;现在我们对马云创造的阿里帝国赞叹不已，觉得马云的成功是必然的，但在马云刚开始创业的时候却没人愿意相信他能成功。我们总是对已经成功或失败的事情表现的很睿智，分析的头头是道，这是一种常见的思维误差。不要忽略世界的不可预见性。&lt;/p&gt;

&lt;p&gt;所以，在分析成功或失败产品的原因时，保持一份谦逊，你没有你想象中那么有预见性。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;14、控制错觉&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;当你想得到一个大的数字的时候，你会用力掷色子；当你想得到一个小数字的时候，你会尽可能掷得温柔。但理性的人知道，掷色子得到的点数的概率是一样的，但人们会有控制错觉，错误的认为自己能控制某件事情的走向。&lt;/p&gt;

&lt;p&gt;那么在产品设计上可以使用“安慰按钮”，比如淘宝上的催单按钮，让用户觉得他能控制一些东西，把用户体验做的更好。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;15、激励误差&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;鼠灾，法国政府颁发法令：人们每交出一只死老鼠就能得到一定的报酬。然而人们不是去杀老鼠，反而大量养殖老鼠。&lt;/p&gt;

&lt;p&gt;这说明：一、一旦有激励或改变激励的方式，人们会迅速而剧烈的改变自己的行为；二、人们只是对激励（得到一定的报酬）做出反应，而不是对激励背后的目的（杀死老鼠）做出反应。
所以，在设计产品激励时，应该注意这种激励误差，将激励和目的结合起来。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;16、回归均值&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;当一件事情发展到最差或最好的时候，会倾向于回归平均水平。&lt;/p&gt;

&lt;p&gt;所以，当你做了一系列举措之后，产品的表现变好或变差，别着急定义这些举措，想想回归均值。&lt;/p&gt;

&lt;p&gt;但请注意概率事件：将一枚硬币连抛50次都是人头朝上，如果要你用100块钱来堵下一次会是人头还是数字，大部分人会压数字，虽然人头同样是可能的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;17、选择悖论&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;选择范围太大会导致无所适从，做出更差的决定同时也更可能导致不满。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;18、讨喜偏误&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;某人越讨喜，我们就越倾向于从这个人那儿买东西或者帮助他。&lt;/p&gt;

&lt;p&gt;我们会觉得一个人讨喜，如果他：1、外表有吸引力；2、在出身、个性和兴趣上与我们相似；3、他觉得我们讨人喜欢。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;19、规避损失&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;损失要比同等的收益对我们的影响更大。&lt;/p&gt;

&lt;p&gt;“请每年接受体检，这样你可以及时发现可能的癌症。”，“如果你不每年接受体检，那么你在冒可能的癌症和不能及时得到治疗的风险”，第二句远比第一句要来的有效果。&lt;/p&gt;

&lt;p&gt;所以告诉别人如果不这么做的损失比告诉别人这么做能得到的收益更加能说服别人。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;20、关联谬误&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;克劳斯致力研究第三世界课题，在西非红十字会工作了两年，以下哪种可能性最大：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;克劳斯在一家银行工作；&lt;/li&gt;
  &lt;li&gt;克劳斯在一家银行工作，在那里负责第三世界基金会。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;很多人会选择2，但理性思考下，即是银行家又在其中的第三世界基金会工作只是银行工作人员的一小部分，所以1的可能性相比最大。关联谬误的思维陷阱会让我们更相信“和谐的”或“可信的”故事，如果将克劳斯的故事描绘的更感人，那么我们犯这一思维错误的危险就越大。&lt;/p&gt;

&lt;p&gt;诺贝尔获奖者卡尼曼认为思维分为两种：一种是直觉、机械、直接的思维；另一种是有意识、理性、缓慢、有逻辑的思维。但往往在有意识的思维开始之前，直觉思维就已经给出了结论。
就比如911事件发生后，聪明的保险公司推出“恐怖主义保险”，尽管其他类的保险显然已经包括了受到恐怖袭击的情况，而去美国的人买保险还是更倾向买“恐怖主义保险”。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;21、框架效应&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;99%无脂的和1%有脂的肉，大部分人会选择99%无脂的，尽管这两种肉是一样的。同一种意思用不同的方式表达出来，听者产生的反应就大不一样。&lt;/p&gt;

&lt;p&gt;美化是框架效应特别喜欢采用的方式：股价下跌称为“回调”；问题不再是“问题”，而是“机会”。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;22、行动偏误&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;人们在&lt;strong&gt;遇到新情形或不明情形时&lt;/strong&gt;，会产生行动偏误，也就是人们会更倾向于做点什么而不是停下来思考。&lt;/p&gt;

&lt;p&gt;比如，点球的时候，球有1/3的概率射向球门中央，有1/3的概率射向球门左边，有1/3的概率射向球门右边，但守门员往往会扑左边或者右边，而很少待在中间－尽管有1/3的球会射向那里。这种行动偏误是人性潜在的一种偏误，想象下我们的祖先在森林边缘出现一个看上去像是一支剑齿虎的影子，他们不会像罗丹的“思想者”那样坐到一块石头上去进行分类思考，这到底是一只剑齿虎还是一只猫，他们会拔腿就跑。&lt;/p&gt;

&lt;p&gt;所以，我们在不明情况下会产生做点什么的冲动，随便什么（管它有没有帮助），因为这样我们会好受一点，即使事情没有什么好转。但理性地来说，如果情况不明，不要采取任何行动，直到你能更好地分析形势。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;23、不作为偏误&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这种偏误总是出现在&lt;strong&gt;无论放弃还是行动都会带来损害的地方&lt;/strong&gt;，在这种情况下大多数人都会选择放弃，因为这样引起的损害主观看来更无害。不作为偏误大多出现在：今天的行为可以防止未来的损害，但防止损害对我们的激励并不强。&lt;/p&gt;

&lt;p&gt;比如：公司管理层会认为不研发新产品不如研发错误产品严重，尽管两者都会使公司破产；不申报收入不比伪造纳税资料严重。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;24、联想偏误&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一朝被蛇咬，十年怕井绳。被蛇咬后，看到井绳就能联想到蛇。&lt;/p&gt;

&lt;p&gt;开到蓝色的易拉罐就会联系到百事可乐，看到红色色调的网站就会想是京东或天猫。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;25、及时行乐偏误&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;你宁愿在一年后得到100万还是在一年零一个月之后得到110万呢？大部分人会选择后者，因为一年都等了，再等一个月也无所谓；但你宁愿今天得到100万还是在一个月后的到110万呢？大部分人会选择前者。这种现象科学里称为双曲贴现：一个决定离现在越近，我们的“情感利息”就越多。&lt;/p&gt;

&lt;p&gt;随着年纪的增长，建立的自我控制越多，我们就越容易成功地延迟满足，但人性里及时行乐的诱惑依旧不可小觑。&lt;/p&gt;

</description>
        <pubDate>Sat, 17 Dec 2016 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/life/2016/12/17/%E6%B8%85%E9%86%92%E6%80%9D%E8%80%83%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BD%A0%E6%9C%80%E5%A5%BD%E8%AE%A9%E5%88%AB%E4%BA%BA%E5%8E%BB%E7%8A%AF%E7%9A%8452%E7%A7%8D%E6%80%9D%E7%BB%B4%E9%94%99%E8%AF%AF-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0.html</link>
        <guid isPermaLink="true">http://localhost:4000/life/2016/12/17/%E6%B8%85%E9%86%92%E6%80%9D%E8%80%83%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BD%A0%E6%9C%80%E5%A5%BD%E8%AE%A9%E5%88%AB%E4%BA%BA%E5%8E%BB%E7%8A%AF%E7%9A%8452%E7%A7%8D%E6%80%9D%E7%BB%B4%E9%94%99%E8%AF%AF-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0.html</guid>
        
        <category>清醒思考</category>
        
        <category>思维错误</category>
        
        <category>读书笔记</category>
        
        
        <category>Life</category>
        
      </item>
    
      <item>
        <title>架构大数据系列读书笔记</title>
        <description>&lt;h1 id=&quot;大数据概述&quot;&gt;&lt;strong&gt;大数据概述&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;Hadoop大数据处理平台，Spark大数据通用计算平台，用于图像和视频识别的深度学习。&lt;/p&gt;

&lt;h2 id=&quot;大数据发展时间线索&quot;&gt;&lt;strong&gt;大数据发展时间线索&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;2003年：业内学者开始围绕着半结构化数据或非结构化数据的处理进行探索&lt;/li&gt;
  &lt;li&gt;2005年：Hadoop诞生&lt;/li&gt;
  &lt;li&gt;2006-2009：并行计算和分布式系统成为主流，大数据技术的发展进入成熟期&lt;/li&gt;
  &lt;li&gt;2010：智能手机的应用日益广泛，随之而来的数据的碎片化、分布式、流媒体等特征更加明显，移动数据量急速增长。&lt;/li&gt;
  &lt;li&gt;2012：美国Splunk大数据处理公司上市，也是第一家上市的大数据处理公司
同年，阿里巴巴推出数据分享平台“聚石塔”，通过分享和挖掘海量电商数据，为国家和中小企业提供价值&lt;/li&gt;
  &lt;li&gt;2013：大数据元年，几乎所有的大型互联网企业都将业务范围延伸至大数据产业&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;云计算，物联网，移动互联网，知识工作自动化，先进机器人等都需要大数据作为基础
何以定义“大数据”，大数据需要满足：数据量足够大；数据的种类多样；数据的增长、处理速度快；数据蕴藏价值大，这四个基本特征。&lt;/p&gt;

&lt;p&gt;大数据的处理要求是在线的。&lt;/p&gt;

&lt;p&gt;大数据的处理流程：在合适工具的辅助下，对广泛异构的数据源进行抽取和集成，结果按照一定的标准进行统一存储，并利用合适的数据分析技术对存储的数据进行分析，从中提取有益的知识并利用恰当的方式将结果展示给终端用户。&lt;/p&gt;

&lt;p&gt;数据抽取与分析—&amp;gt;数据分析—&amp;gt;数据可视化&lt;/p&gt;

&lt;h1 id=&quot;数据中心及云计算&quot;&gt;&lt;strong&gt;数据中心及云计算&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;数据中心&quot;&gt;&lt;strong&gt;数据中心&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;数据中心包含大规模计算、存储的硬件资源以及通信宽带资源，与硬件服务器等关联比较大；云计算平台是负责管理、调度和监控这些资源。数据中心是云计算的实现平台。&lt;/p&gt;

&lt;h2 id=&quot;云计算&quot;&gt;&lt;strong&gt;云计算&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;云计算将底层的物理资源经过虚拟化转变为多个虚拟机，以资源池多重租赁的方式提供服务，从而提高资源的效用。&lt;/p&gt;

&lt;p&gt;传统的分布式任务处理模式是按照高负载配置的服务器集群，也就是给用户分配的服务器都是按照高负载情况的配置，但一旦遇到底负载的情况，那么会造成资源的浪费和闲置，为解决这一资源浪费的问题，提出了如今的按需分配的云计算模式，云计算将服务器资源虚拟化，用户可以像传统的水电等系统一样按需获取服务器资源，并自主设置服务器配置。在云计算模式下，用户无需关心资源池的地点、使用性能等相关信息，用户自需要通过网络访问，按需定制自己的服务器资源即可，具体的服务资源的调度、管理和维护等工作由云内部实现。&lt;/p&gt;

&lt;h2 id=&quot;云计算服务类型&quot;&gt;&lt;strong&gt;云计算服务类型&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;基础设施及服务（Infrastructure as a Service,IaaS），平台即服务（Platform as a Service,PaaS），软件即服务（Software as a Service,SaaS）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;IaaS&lt;/strong&gt;，提供的服务内容是基础设施，通过虚拟化技术将物力资源虚拟化，为用户提供计算、存储、网络以及其它资源方面的服务，以便用户能够部署操作系统和运行软件。如亚马逊的弹性云（Amazon, EC2）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PaaS&lt;/strong&gt;，构建在IaaS上的服务，在这种服务中，用户不必控制底层的网络、存储、操作系统等技术问题，直接部署自己需要的软件运行环境和配置，如Google App Engine和Microsoft Azure。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SaaS&lt;/strong&gt;，是基于前两层服务所开发的软件应用，不同的用户以简单客户端的方式调用该层服务，比如之前两家公司的产品：视频云。&lt;/p&gt;

&lt;h2 id=&quot;虚拟机与容器&quot;&gt;&lt;strong&gt;虚拟机与容器&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;虚拟化技术分为两种：以虚拟机为产物的虚拟化方案和以容器为产品的轻量级虚拟化方案。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;虚拟机&lt;/strong&gt;：典型的是VMware，把一台物理机虚拟成多台虚拟子机，直接运行在硬件之上，管理物理机或虚拟子机的硬件资源。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;容器&lt;/strong&gt;：典型的是Docker，直接运行在操作系统上，为每个进程分配不同的系统资源，进程与进程之间独立，而硬件资源由操作系统自身管理。容器是在操作系统层面上实现虚拟化，直接复用本地主机的操作系统。&lt;/p&gt;

&lt;h1 id=&quot;hadoop与mapreduce&quot;&gt;&lt;strong&gt;Hadoop与MapReduce&lt;/strong&gt;&lt;/h1&gt;

&lt;h2 id=&quot;hadoop&quot;&gt;&lt;strong&gt;Hadoop&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;底层文件系统HDFS，结构化存储系统HBase，任务调度系统MapReduce。&lt;/p&gt;

&lt;p&gt;Hadoop为用户提供了系统底层细节透明的分布式基础架构，是一套行业大数据标准开源软件，在分布式环境下提供了海量数据的处理能力。&lt;/p&gt;

&lt;p&gt;Hadoop分布式文件系统HDFS，它存储Hadoop集群（数百台或数千台的服务器）中所有存储节点的文件。
HDFS的几个特点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一次写入多次读取；&lt;/li&gt;
  &lt;li&gt;批量处理而不是用户交互式处理，因而更重视数据吞吐量而不是数据访问的反应速度；&lt;/li&gt;
  &lt;li&gt;处理逻辑接近数据，而不是数据接近处理逻辑；&lt;/li&gt;
  &lt;li&gt;通过使用多个普通个人计算机集群分布和处理数据来节约成本；&lt;/li&gt;
  &lt;li&gt;通过分布数据和数据处理的逻辑到多个节点上进行并行处理来提高效率。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;HDFS的三个重要组成部分：NameNode，DataNode，Client。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NameNode&lt;/strong&gt;是HDFS的管理者，主要负责管理文件系统的命名空间、集群配置信息和存储块的复制，NameNode会将文件系统的元数据（Metadata）存储在内存中，元数据包括文件信息、每个文件对应的文件块的信息和每个文件块在DataNode中的信息。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;DataNode&lt;/strong&gt;是文件存储的基本单元，它将文件块保存在本地文件系统中，同时保存文件块的元数据，周期性的将所有存在的文件块信息发送给NameNode。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Client&lt;/strong&gt;就是要获取HDFS中的文件的应用程序。&lt;/p&gt;

&lt;p&gt;文件写入操作：Client向NameNode发起文件写入请求—&amp;gt;NameNode根据文件的大小和文件块的配置情况，向Client返回它所管理的DataNode的信息—&amp;gt;Client将文件划分为多个文件块，根据所得到的DataNode的地址信息，按顺序写入每一个DataNode块中。&lt;/p&gt;

&lt;p&gt;文件读取操作：Client向NameNode发起文件读取的请求—&amp;gt;NameNode返回文件存储的DataNode的信息—&amp;gt;Client读取文件信息。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;HBase——Hadoop Database&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;HBase利用HDFS作为其文件存储系统，利用Hadoop MapReduce来处理HBase中的海量数据，利用ZooKeeper作为协同服务。&lt;/p&gt;

&lt;h2 id=&quot;mapreduce&quot;&gt;&lt;strong&gt;MapReduce&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Map（映射）＋Reduce（化简）&lt;/p&gt;

&lt;p&gt;在输入数据的逻辑纪录上应用Map操作得出一个中间key/value对集合，然后在所有具有相同key值的value值上应用Reduce操作来合并中间的数据，得到最终结果。&lt;/p&gt;

&lt;p&gt;将对大量顺序式数据元素或纪录进行扫描并做相应的处理获取中间结果信息的过程称为Map操作；对中间结果进行收集整理和产生最终结果并输出的过程称为Reduce操作。&lt;/p&gt;

&lt;p&gt;学习Hadoop的产品，由Hortonworks发布的一个虚拟机环境——Sandbox，它是一种个人可移植的Hadoop环境，附带大量交互式Hadoop教程。网址：http://zh.hortonworks.com/products/hortonworks-sandbox/&lt;/p&gt;

&lt;h1 id=&quot;spark大数据统一计算平台&quot;&gt;&lt;strong&gt;Spark—大数据统一计算平台&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;Spark是基于MapReduce算法实现的分布式计算，在拥有Hadoop MapReduce所有优点的基础上，其任务的中间结果可以保存在内存中，不再读写HDFS，从而效率和速度都比Hadoop快，所以Spark在处理迭代算法（如机器学习、图挖掘算法）和交互式数据挖掘算法等方面具有更大的优势。&lt;/p&gt;

&lt;h1 id=&quot;storm流计算系统&quot;&gt;&lt;strong&gt;Storm流计算系统&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;Hadoop无法处理实时性要求很高的任务，对实时交互的需求催生了一大批实时计算系统，如Storm流计算系统。&lt;/p&gt;

&lt;p&gt;传统的数据处理流程为先收集数据存放在数据库中，等到由数据需求的时候再从数据库中进行查询或计算，这种处理方式是非实时的；而流计算可以很好地对大规模流动数据在不断变化的过程中实时地进行分析，捕捉到可能有用的信息并反馈给下一个计算节点，在流计算系统中，数据是流式的，计算与服务也是流式不间断的，整个过程是连续的且响应也是实时的，可达到秒级别以内。&lt;/p&gt;

&lt;h1 id=&quot;sqlnosql与newsql&quot;&gt;&lt;strong&gt;SQL、NoSQL与NewSQL&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;由于传统的关系型数据库表结构的扩展性差，对海量数据的高效率存储和访问的支持度不高以及弱一致性需求导致出现了非关系型数据库。NoSQL可以写成Not Only SQL，是对不同于传统的关联式数据库的数据库管理系统的统称。传统的关系型数据库是基于行的数据库，而NoSQL是基于列的数据库。http://nosql-database.org 列举了市面上所有的NoSQL数据库。&lt;/p&gt;

&lt;h2 id=&quot;cap定理&quot;&gt;&lt;strong&gt;CAP定理&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;也称布鲁尔定理，它指出对于一个分布式计算系统来说，不可能同时满足以下三点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;一致性：所有节点访问同一份最新的数据副本，也就是说一份数据是单点存储，并不像在分布式系统中多点存储；&lt;/li&gt;
  &lt;li&gt;可用性：对数据更新具备高可用性，每个请求不管成功与否都有响应；&lt;/li&gt;
  &lt;li&gt;分区容错性。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;系统如果不能满足数据一致性，说明发生了分区的情况，这时必须在一致性和可用性之间做出选择。&lt;/p&gt;

&lt;p&gt;传统的数据库保证事务的一致性，但在非关系型数据库中为了高度的可用性放弃了一致性，以最终一致性代替，最终一致性表示过程松（即并不要求每时每刻都保证数据的一致性），结果紧（即最终结果必须保持一致性）&lt;/p&gt;

&lt;h2 id=&quot;newsql&quot;&gt;&lt;strong&gt;NewSQL&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;这类数据库不仅具有NoSQL对海量数据的存储管理能力，还保持了传统数据库对SQL的友好。比较流行的NewSQL数据库有：Google Spanner。&lt;/p&gt;

&lt;h1 id=&quot;数据挖掘&quot;&gt;&lt;strong&gt;数据挖掘&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;数据挖掘的任务：&lt;/strong&gt;预测与描述&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;数据挖掘的主要功能：&lt;/strong&gt;预测建模，关联分析，聚类分析&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;传统数据挖掘解决方案：&lt;/strong&gt;MATLAB；java语言开发的数据挖掘常用软件Weka；R语言&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;分布式数据挖掘解决方案：&lt;/strong&gt;基于Hadoop的Mahout；基于Spark的MLBase&lt;/p&gt;

&lt;h1 id=&quot;深度学习&quot;&gt;&lt;strong&gt;深度学习&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;人脑是通过视皮层来识别物体，视皮层的功能是对感知信号进行特征提取和计算。&lt;/p&gt;

&lt;p&gt;深度学习能够通过组合底层特征形成更抽象的高层特征，从而实现自动选择特征，通过模拟人脑多层次的分析方式来提高学习的准确性。&lt;/p&gt;

&lt;p&gt;深度学习的结构有三种：生成性深度结构（技术点：深度置信网络）；区分性深度结构（技术点：卷积神经网络）；混合型结构（就是前两种都有，这种结构的学习过程为生成性过程和区分性过程，用生成性过程的结果用于区分性任务）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;从机器学习到深度学习&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在机器学习中，比如前面的数据挖掘，无论哪种算法都需要人工的干预，比如数据预处理，只要有人工干预就无法实现知识产生的自动化，不过是将人的想法用代码实现而已。但深度学习能实现知识发现的自动化。
深度学习的应用：Google Brain；百度 Paddle；腾讯Mariana&lt;/p&gt;

</description>
        <pubDate>Sat, 03 Dec 2016 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/datamining/2016/12/03/%E6%9E%B6%E6%9E%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E5%88%97%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0.html</link>
        <guid isPermaLink="true">http://localhost:4000/datamining/2016/12/03/%E6%9E%B6%E6%9E%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E5%88%97%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0.html</guid>
        
        <category>大数据</category>
        
        <category>读书笔记</category>
        
        
        <category>Datamining</category>
        
      </item>
    
      <item>
        <title>数据挖掘十大经典算法</title>
        <description>&lt;p&gt;这个学期有一门课程为《数据挖掘》，老师要求每个同学对数据挖掘中的十大经典算法进行具体应用，老师提供数据集，分别使用这十种数据挖掘算法构建模型，这里主要对这十种数据挖掘算法进行简单介绍。&lt;/p&gt;

&lt;p&gt;1、&lt;strong&gt;C4.5&lt;/strong&gt;是一系列用在机器学习和数据挖掘的分类问题中的算法。它的目标是监督学习：给定一个数据集，其中的每一个元组都能用一组属性值来描述，每一个元组属于一个互斥的类别中的某一类。C4.5的目标是通过学习，找到一个从属性值到类别的映射关系，并且这个映射能用于对新的类别未知的实体进行分类。&lt;/p&gt;

&lt;p&gt;C4.5由J.Ross Quinlan在ID3的基础上提出的。ID3算法用来构造决策树。决策树是一种类似流程图的树结构，其中每个内部节点（非树叶节点）表示在一个属性上的测试，每个分枝代表一个测试输出，而每个树叶节点存放一个类标号。一旦建立好了决策树，对于一个未给定类标号的元组，跟踪一条有根节点到叶节点的路径，该叶节点就存放着该元组的预测。决策树的优势在于不需要任何领域知识或参数设置，适合于探测性的知识发现。&lt;/p&gt;

&lt;p&gt;从ID3算法中衍生出了C4.5和CART两种算法，这两种算法在数据挖掘中都非常重要。下图就是一棵典型的C4.5算法对数据集产生的决策树。&lt;/p&gt;

&lt;p&gt;2、&lt;strong&gt;CART分类回归树&lt;/strong&gt;(CART,Classification And Regression Tree)也属于一种决策树，分类回归树是一棵二叉树，且每个非叶子节点都有两个孩子，所以对于第一棵子树其叶子节点数比非叶子节点数多1。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C4.5与CART的区别&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;C4.5算法是在ID3算法的基础上采用信息增益率的方法选择测试属性。 ID3算法和C4.5算法虽然在对训练样本集的学习中可以尽可能多地挖掘信息，但其生成的决策树分支较大，规模较大。为了简化决策树的规模，提高生成决策树的效率，又出现了根据GINI系数来选择测试属性的决策树算法CART。&lt;/p&gt;

&lt;p&gt;CART算法采用一种二分递归分割的技术，与基于信息熵的算法不同，CART算法对每次样本集的划分计算GINI系数，GINI系数，GINI系数越小则划分越合理。CART算法总是将当前样本集分割为两个子样本集，使得生成的决策树的每个非叶结点都只有两个分枝。因此CART算法生成的决策树是结构简洁的二叉树。&lt;/p&gt;

&lt;p&gt;3、&lt;strong&gt;K-means&lt;/strong&gt;是最简单的聚类算法之一，简单地说就是把相似的东西分到一组，同 Classification (分类)不同，对于一个 classifier ，通常需要你告诉它“这个东西被分为某某类”这样一些例子，理想情况下，一个 classifier 会从它得到的训练集中进行“学习”，从而具备对未知数据进行分类的能力，这种提供训练数据的过程通常叫做 supervised learning (监督学习)，而在聚类的时候，我们并不关心某一类是什么，我们需要实现的目标只是把相似的东西聚到一起，因此，一个聚类算法通常只需要知道如何计算相似 度就可以开始工作了，K-means算法运用十分广泛，一般在数据分析前期使用，选取适当的k，将数据分类后，然后研究不同聚类下数据的特点。&lt;/p&gt;

&lt;p&gt;K-means 算法接受参数k；然后将事先输入的n个数据对象划分为 k个聚类以便使得所获得的聚类满足：同一聚类中的对象相似度较高；而不同聚类中的对象相似度较小。聚类相似度是利用各聚类中对象的均值所获得一个“中心对象”（引力中心）来进行计算的。&lt;/p&gt;

&lt;p&gt;K-means算法是最为经典的基于划分的聚类方法，是十大经典数据挖掘算法之一。K-means算法的基本思想是：以空间中k个点为中心进行聚类，对最靠近他们的对象归类。通过迭代的方法，逐次更新各聚类中心的值，直至得到最好的聚类结果。&lt;/p&gt;

&lt;p&gt;假设要把样本集分为c个类别，算法描述如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;适当选择c个类的初始中心；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在第k次迭代中，对任意一个样本，求其到c个中心的距离，将该样本归到距离最短的中心所在的类；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;利用均值等方法更新该类的中心值；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;对于所有的c个聚类中心，如果利用（2）（3）的迭代法更新后，值保持不变，则迭代结束，否则继续迭代。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;该算法的最大优势在于简洁和快速。算法的关键在于初始中心的选择和距离公式。&lt;/p&gt;

&lt;p&gt;4、&lt;strong&gt;Apriori&lt;/strong&gt; 算法是一关联规则算法，关联规则的目的在于在一个数据集中找出项之间的关系，也称之为购物蓝分析 (market basketanalysis)。例如，购买鞋的顾客，有10%的可能也会买袜子，60%的买面包的顾客，也会买牛奶。这其中最有名的例子就是”尿布和啤酒”的故事了。&lt;/p&gt;

&lt;p&gt;5、&lt;strong&gt;Naive Baye&lt;/strong&gt;在众多的分类模型中，应用最为广泛的两种分类模型是决策树模型(Decision Tree Model)和朴素贝叶斯模型（Naive Bayesian Model，NBC）。&lt;/p&gt;

&lt;p&gt;朴素贝叶斯模型发源于古典数学理论，有着坚实的数学基础，以及稳定的分类效率。同时，NBC模型所需估计的参数很少，对缺失数据不太敏感，算法也比较简单。&lt;/p&gt;

&lt;p&gt;6、&lt;strong&gt;EM最大期望算法（Expectation-maximization algorithm，又译期望最大化算法）&lt;/strong&gt;在统计中被用于寻找，依赖于不可观察的隐性变量的概率模型中，参数的最大似然估计。&lt;/p&gt;

&lt;p&gt;在统计计算中，最大期望（EM）算法是在概率模型中寻找参数最大似然估计或者最大后验估计的算法，其中概率模型依赖于无法观测的隐藏变量（Latent Variable）。最大期望经常用在机器学习和计算机视觉的数据聚类（Data Clustering）领域。最大期望算法经过两个步骤交替进行计算，&lt;/p&gt;

&lt;p&gt;第一步是计算期望（E），利用对隐藏变量的现有估计值，计算其最大似然估计值；&lt;/p&gt;

&lt;p&gt;第二步是最大化（M），最大化在 E 步上求得的最大似然值来计算参数的值。M 步上找到的参数估计值被用于下一个 E 步计算中，这个过程不断交替进行。&lt;/p&gt;

&lt;p&gt;M是一个在已知部分相关变量的情况下，估计未知变量的迭代技术。EM的算法流程如下：&lt;/p&gt;

&lt;p&gt;初始化分布参数&lt;/p&gt;

&lt;p&gt;重复直到收敛：&lt;/p&gt;

&lt;p&gt;E步骤：估计未知参数的期望值，给出当前的参数估计。&lt;/p&gt;

&lt;p&gt;M步骤：重新估计分布参数，以使得数据的似然性最大，给出未知变量的期望估计。&lt;/p&gt;

&lt;p&gt;7、&lt;strong&gt;Adaboost “Adaptive Boosting”（自适应增强）&lt;/strong&gt;是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器 (强分类器)。其算法本身是通过改变数据分布来实现的，它根据每次训练集之中每个样本的分类是否正确，以及上次的总体分类的准确率，来确定每个样本的权值。将修改过权值的新数据集送给下层分类器进行训练，最后将每次训练得到的分类器融合起来，作为最后的决策分类器。&lt;/p&gt;

&lt;p&gt;8、&lt;strong&gt;K最近邻(k-Nearest  Neighbor，KNN)&lt;/strong&gt;分类算法，是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。该方法的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。&lt;/p&gt;
</description>
        <pubDate>Tue, 15 Nov 2016 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/datamining/2016/11/15/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%8D%81%E5%A4%A7%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95.html</link>
        <guid isPermaLink="true">http://localhost:4000/datamining/2016/11/15/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%8D%81%E5%A4%A7%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95.html</guid>
        
        <category>数据挖掘</category>
        
        <category>算法</category>
        
        
        <category>Datamining</category>
        
      </item>
    
      <item>
        <title>《大数据时代》读书笔记（二）</title>
        <description>&lt;p&gt;大数据时代给许多公司创造了新的竞争力和商业价值。Viktor认为一切皆可“量化”，大数据发展的核心动力来源于人类测量、记录和分析世界的渴望。&lt;/p&gt;

&lt;p&gt;当文字变成数据，文字则不仅可以被人所阅读，机器也可以用之分析。“谷歌翻译”是一个里程碑式的大数据胜利，谷歌拥有大量的搜索记录和数据化的书籍信息，并利用这些数字化的文字来改进它的机器翻译服务，“谷歌翻译”成为谷歌的标志性产品，不仅精确而且包含多样的语言翻译。同样拥有大量数据化书籍的亚马逊却只是把眼光聚集在阅读的书籍的内容上，而不是分析数据化文本上。亚马逊深谙数字化内容的意义，但谷歌触及了数字化内容的价值，两种不同的对大数据的态度决定了两种不同的发展战略。但这任然不可否定亚马逊是一家伟大的大数据公司，它通过对大量顾客的购买数据进行分析，为每个用户提供个性化的购买清单，这种营销策略为亚马逊节省了大量人力成本并且提高了效率。当方位变成数据，我们的出行变得更加便捷。地图导航软件利用大量的地理位置数据为我们的出行提供最佳路径。当社交变成数据，我们就可以轻松预测到人在未来几天的情感甚至行为。通过对事物的数据化，我们可以从一个人在驾驶座上的坐姿来判断他是不是车的主人，可以通过以往飞机销售价格数据来预测未来的机票价格走势，可以通过收集用户在网页上鼠标停顿的位置和时间来判断广告位的安置。大数据时代，数据让我们的生活变得更加便捷和智能。&lt;/p&gt;

&lt;p&gt;接下来，我们应该开始思考在大数据时代，我们处于什么位置？如果想要在大数据时代有所发展，Viktor提出三种角色定位：数据、技术与思维。拥有海量数据，具备数据分析技术，培养数据战略思维。其中技术和思维在大数据时代早期是最有价值的，但最终大部分的价值在于数据本身。&lt;/p&gt;

&lt;p&gt;当然，大数据时代，一些互联网公司利用社交平台、各种APP终端疯狂地收揽我们的个人数据，其中有些私人数据我们不希望与他人共享，那么这其中的风险和责任我们又该如何定义？我还清楚记得淘宝数据泄露事件给大众带来的冲击，我们把我们的账号，密码，银行卡号，身份证号等一系列私密数据交由数据使用者“淘宝”，那么在我们的数据或通过分析数据得出来的预测信息被错误或过度使用和泄露时，数据使用者就应该承担责任，同样中国政府也应该尽快健全法律法规来规范大数据市场，保障数据的安全性。&lt;/p&gt;

&lt;p&gt;作为“不总结就会死”的深度患者，我习惯在看完一本书后，根据自己的理解写下读书笔记，为共享，更为自己以后可以回过头翻阅。读书的目的只有一个，追求思想之自由。我希望人生中我所经历的是所谓的正确还是错误，是“是”抑或是“非”，都能让自己有能力来评判。&lt;/p&gt;
</description>
        <pubDate>Sun, 23 Oct 2016 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/life/2016/10/23/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%97%B6%E4%BB%A3-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E4%BA%8C.html</link>
        <guid isPermaLink="true">http://localhost:4000/life/2016/10/23/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%97%B6%E4%BB%A3-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E4%BA%8C.html</guid>
        
        <category>大数据时代</category>
        
        <category>读书笔记</category>
        
        
        <category>Life</category>
        
      </item>
    
      <item>
        <title>《大数据时代》读书笔记（一）</title>
        <description>&lt;p&gt;抱着对大数据无比敬仰的态度与渴望求知的姿态，终于将这本《大数据时代》拜读完。虽然品读完后收获颇丰，但到真要提笔写读书笔记的时候却不知如何说起，真心担忧我对这本书的理解和对大数据的认知无法真切地表达Viktor对大数据时代的研究，所以索性就写写自己对大数据的思考。&lt;/p&gt;

&lt;p&gt;维克托•迈尔-舍恩伯格，大数据时代的预言家，开大数据系统研究之先河，是位孜孜不倦的数据科学家。他的著作《大数据时代》分别从大数据的概念与特征，价值与角色定位，风险与掌控三个方面讲述了大数据是如何成为生活、工作与思维的大变革。&lt;/p&gt;

&lt;p&gt;我们过去在小数据时代，对数据的分析往往是基于随机抽样，通过对研究对象的随机采样进行分析，来预测研究对象的发展规律或判断研究对象的某些对人类有价值的特征，但这种预测或判断往往苍白无力，随着时间的推移而不断被推翻，因为随机抽样本身就无法做到真正的“随机”，里面无时无刻都包含着人的主观意识。而如今，在计算机存储与分布式计算能力愈加发达，我们已经步入大数据时代，我们开始变得有能力去收集、存储和分析所有的数据。无论是结构化数据还是越来越多的非结构化数据，我们都有能力将一切量化，并变成我们可用的数据。所以在大数据时代，我们不再追求随机样本，而开始分析全部数据，所以我理解的大数据的“大”就不在于其规模，而在于所得到的数据是不是研究对象的“全部”。&lt;/p&gt;

&lt;p&gt;毋庸置疑，在分析全部数据时，我们就必然不再（也无法）强调分析的精确性，开始转而包容数据的混杂性。这在小数据时代简直是无法忍受的，小数据时代追求数据绝对的正确，这样基于数据之上的研究才可能具有可信度。但在大数据时代，我们要求全部数据，那么其中就难以避免错误的数据也会混进数据库，而且我们也没有必要避免，因为错误的数据的不良影响会随着数据量变大而慢慢变小，更重要的是，错误的数据也会带来一个全新的亮点。举个例子，在百度搜索中，我们有时会输入错误的词条却依旧能得到这样一条提醒“您要搜索的是不是***”，这就是因为百度搜索引擎中，收集了全部的数据（当然也就包括这些错误的搜索词条），搜索算法对全部数据进行分析，寻找到错误词条的搜索与某一类结果具有相关性，然后以相关性高低排序给用户返回用户本来想要得到的结果。正确与错误的数据往往没有明确的界定，根本在于从不同的的角度来理解事物之间的相关性。&lt;/p&gt;

&lt;p&gt;在转变思维的最后一点，Viktor指出大数据时代追求的不是因果关系而是相关关系，知道“是什么”就够了，没必要知道“为什么”。但这一点我实在不敢苟同，我认为在中国，因果关系与相关关系同样重要，我们不仅要知道“是什么”更想知道“为什么”。相关性能让我们找到新的价值，而因果关系能让这种价值更容易被大众接受，毕竟我们的思维认知会倾向于去探索一个事物的因果由来，如果我们不知道一个事物发展的原因，我们会倾向于怀疑或保留意见。而从商业的角度讲，顾客的质疑态度对产品是致命的。&lt;/p&gt;
</description>
        <pubDate>Tue, 11 Oct 2016 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/life/2016/10/11/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%97%B6%E4%BB%A3-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E4%B8%80.html</link>
        <guid isPermaLink="true">http://localhost:4000/life/2016/10/11/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%97%B6%E4%BB%A3-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E4%B8%80.html</guid>
        
        <category>大数据时代</category>
        
        <category>读书笔记</category>
        
        
        <category>Life</category>
        
      </item>
    
  </channel>
</rss>
